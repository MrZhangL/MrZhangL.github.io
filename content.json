{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Netty核心组件-ByteBuf","text":"JDK提供的Buffer类实在太难用，例如读写操作切换需要flip()，DirectByteBuffer使用起来不方便。因此Netty自己提供了一套缓冲区的ByteBuf类来方便的进行缓冲区操作，在功能上与NIO的ByteBuffer是相同的。 概述Netty提供的ByteBuf优点有如下： 它可以被用户自定义的缓冲区类型扩展 通过内置的符合缓冲区类型实现了透明的零拷贝 容量可以按需增长 在读和写这两种模式之间切换不需要调用 #flip() 方法 读和写使用了不同的索引 支持方法的链式调用 支持引用计数 支持池化 ByteBuf基础​ ByteBuf是Netty有关缓冲区类的抽象基类，所有的缓冲区类都是继承自该类，该类的大部分方法都是抽象的，ByteBuf对字节数组的操作比NIO的ByteBuffer方便、灵活的多。 读写模式ByteBuf中有如下重要属性(这几个属性没有在ByteBuf中给出而是在AbstractByteBuf中给出，但是ByteBuf中定义了获取这些属性的方法)： readerIndex：读索引 writerIndex：写索引 capacity：字节数组的当前容量 maxCapacity：字节数组的最大容量，当writerIndex超过capacity时，可以自动地扩容，每次为2*capacity，但是不能超过maxCapacity ByteBuf引入了readerIndex和writerIndex来将读操作和写操作分开进行索引，避免了NIO的ByteBuffer在读写切换时需要flip() 四个大小关系很简单：readerIndex &lt;= writerIndex &lt;= capacity &lt;= maxCapacity 。如下所示： 123456+-------------------+------------------+------------------+| discardable bytes | readable bytes | writable bytes || | (CONTENT) | |+-------------------+------------------+------------------+| | | |0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity &lt;= maxCapacity 图中主要有三段数据： Discardable bytes(可废弃数据段)：在写入后被读取了的数据，位于0~readerIndex之间。 readable bytes(可读取的数据段)：读取操作只到了readerIndex，readerIndex~writerIndex之间的数据写入了但没有读取过，所以是可读取的数据。 writable bytes(可写的数据段)：字节数组还没有被写满，在writerIndex~capacity之间的空间还可以再被写入数据。 此外还有两个属性： markReaderIndex：标记读的索引位置 markWriterIndex：标记写的索引位置 这两个mark属性与NIO中的ByteBuffer提供的mark标记一样。 读写操作ByteBuf中定义了很多与读写相关的方法： 123456789101112131415161718192021222324252627282930313233// Byte 1 字节public abstract byte getByte(int index);public abstract short getUnsignedByte(int index);public abstract ByteBuf setByte(int index, int value);public abstract byte readByte();public abstract short readUnsignedByte();public abstract ByteBuf writeByte(int value);// Int 4 字节public abstract int getInt(int index);public abstract int getIntLE(int index);public abstract long getUnsignedInt(int index);public abstract long getUnsignedIntLE(int index);public abstract ByteBuf setInt(int index, int value);public abstract ByteBuf setIntLE(int index, int value);public abstract int readInt();public abstract int readIntLE();public abstract long readUnsignedInt();public abstract long readUnsignedIntLE();public abstract ByteBuf writeInt(int value);public abstract ByteBuf writeIntLE(int value);// Byte 数组public abstract ByteBuf getBytes(int index, ByteBuf dst);public abstract ByteBuf getBytes(int index, ByteBuf dst, int length);public abstract ByteBuf setBytes(int index, ByteBuf src);public abstract ByteBuf setBytes(int index, ByteBuf src, int length);// Stringpublic abstract CharSequence getCharSequence(int index, int length, Charset charset);public abstract int setCharSequence(int index, CharSequence sequence, Charset charset);public abstract CharSequence readCharSequence(int length, Charset charset);public abstract int writeCharSequence(CharSequence sequence, Charset charset); 以上给出了部分典型的方法，可以看出，ByteBuf可以方便地读取/写入各种不同的基本数据类型，并且很多方法返回ByteBuf对象(本身)可以进行链式调用。 以上不同的方法对readerIndex和writerIndex的影响是不同的： #getXXX(index) 方法，读取指定位置的数据，不改变 readerIndex 索引。 #readXXX() 方法，读取 readerIndex 位置的数据，会改成 readerIndex 索引。 #setXXX(index, value) 方法，写入数据到指定位置，不改变 writeIndex 索引。 #writeXXX(value) 方法，写入数据到指定位置，会改变 writeIndex 索引。 释放操作1234public abstract ByteBuf discardReadBytes(); // 释放已读的字节空间public abstract ByteBuf discardSomeReadBytes(); // 释放部分已读的字节空间public abstract ByteBuf clear(); // 清空字节空间。实际是修改 readerIndex=writerIndex=0，标记清空。 discardReadBytes 释放所有的已读的空间，相当于把discardable段的数据都释放掉。 优点：达到重用废弃段的空间内存。 缺点：释放的方式，是通过复制可读段到 ByteBuf 的头部。所以，频繁释放会导致性能下降。 1234567891011121314151617// 释放前BEFORE discardReadBytes() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity===========================================================================// 释放后AFTER discardReadBytes() +------------------+--------------------------------------+ | readable bytes | writable bytes (got more space) | +------------------+--------------------------------------+ | | |readerIndex (0) &lt;= writerIndex (decreased) &lt;= capacity discardSomeReadBytes 释放部分空间，取决于具体子类的实现 clear 清空字节空间。实际是修改 readerIndex = writerIndex = 0 ，标记清空。 优点：通过标记来实现清空，避免置空 ByteBuf ，提升性能。 缺点：数据实际还存在，如果错误修改 writerIndex 时，会导致读到“脏”数据。 1234567891011121314151617// 释放前BEFORE clear() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity=========================================================================== // 释放后AFTER clear() +---------------------------------------------------------+ | writable bytes (got more space) | +---------------------------------------------------------+ | | 0 = readerIndex = writerIndex &lt;= capacity ByteBuf核心子类 按内存类型分： HeapByteBuf(堆内字节缓冲)：字节数组缓冲区位于JVM的堆区。特点是申请和释放效率较高，但是缺点与NIO的堆内缓冲区一样，在进行网络I/O操作时数据不能直接读/写到堆内缓冲区，需要先在内核空间建立一个缓冲区，把网络传输的数据写到内核空间的缓冲区后再拷贝到堆内的缓冲区，读写的性能有损耗。 DirectByteBuf(直接内存字节缓存)：字节数组的缓冲位于JVM的堆外空间(元空间)。特点是I/O读写效率高，因为该缓冲区建立在堆外，并且利用mmap的系统调用使得操作系统可以直接读写该缓冲区的数据，因此不需要进行像堆内字节缓冲那样的拷贝，性能更高。缺点是由于位于堆外内存，释放必须触发Full GC，而Full GC对性能的损耗比较大，需要合理使用。 堆内缓冲与堆外缓冲的细节在NIO中已经说明清楚，Netty的缓冲类也具备相同的特点，在此不详细赘述。 按是否建立对象池分： PooledByteBuf(具有对象池)：该字节数组缓冲区对象位于缓冲对象池内，释放时会被归还到对象池中得以重复利用，这样每次使用ByteBuf时就不需要重新去创建对象，经常创建ByteBuf会触发GC，尤其是DirectByteBuf会触发Full GC，造成性能损耗。 UnpooledByteBuf(不具有对象池)：单纯创建一个新的ByteBuf对象，使用完后就等待GC释放。由于对象池维护与创建比较麻烦，不需要大量创建缓冲区对象的地方推荐使用UnpooledByteBuf 按是否使用Unsafe分类： 由于Java不能够从直接操作底层，JDK提供了sun.misc.Unsafe对于底层的内存与线程直接操作，Unsafe被广泛用于JDK的官方源码中(并发包)，但是官方不推荐开发者使用，因为Unsafe对于内存直接进行操作，申请的内存不受JVM管理，需要手动释放内存，与C++的new/和delete类似，申请的空间如果不手动释放，便会造成内存泄漏。 使用Unsafe：由于Unsafe申请的缓冲区位于JVM内存区域的外部，完全不受JVM管控，即不会对GC造成影响，申请的空间在不使用时可以直接手动释放，因此具有更高的效率。 不使用Unasfe：申请的缓冲区位于JVM内存中(HeapByteBuf在堆内，DirectByteBuf在堆外元空间)，频繁的申请临时对象会造成GC压力，频繁的GC会损耗性能。 关于效率的说明： ​ Java中，几乎所有对象都是由JVM管理的，每次在使用new都会在堆空间创建一个对象后(不完全一定在堆空间，JVM逃逸分析允许局部小对象创建在栈区)，如果该局部对象失去了引用，并不会马上释放这个对象所占用的内存空间，而是等到内存占用到一定事件才会调用GC进行垃圾回收，对象的回收对于程序员而言时不可控的。因此，不使用Unsafe，在高并发的环境下，如果频繁的创建临时的ByteBuf（尤其是DirectByteBuf），会频繁的调用GC（DirectByteBuf调用的是Full GC），这无疑对性能有巨大的损失。而使用Unsafe就像写C/C++一样，可以控制缓冲区的生命周期，不用的时候马上释放而不用去麻烦GC，效率更高。 ​ Unsafe对于普通的开发者不要去使用，因为非常地不安全，一旦出问题就会造成JVM崩溃。Netty为我们封装好了Unsafe的缓冲区，我们不需要考虑Unsafe缓冲区的内存释放，Netty已经通过引用计数和内存泄漏检测来保证缓冲区的内存释放，我们可以放心使用。","link":"/2020/09/01/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-ByteBuf/"},{"title":"函数式编程","text":"函数式编程在现在使用非常广泛，使用函数式编程能使得代码更加简洁。 1 使用lambda表达式&emsp;&emsp;现在有如下需求，给定一个员工类，包含姓名、性别、年龄、工资，想从所有员工中找到性别为男，或者年龄小于30岁，或者工资大于5000的员工，按照以前的方法我们可能会这样做： 12345class Employee{ private String name; private boolean sex; private int age; private int salary; 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) { List&lt;Employee&gt; employees = Arrays.asList( new Employee(&quot;zs&quot;, true, 25, 6000), new Employee(&quot;ls&quot;, true, 35, 9000), new Employee(&quot;ww&quot;, false, 21, 5000), new Employee(&quot;lx&quot;, true, 45, 12000), new Employee(&quot;qs&quot;, false, 33, 7000) ); // 查找年龄小于30的 List&lt;Employee&gt; employeesBelow30 = new ArrayList&lt;&gt;(); for(Employee employee : employees){ if(employee.getAge() &lt; 30){ employeesBelow30.add(employee); } } // 查找性别为男的 List&lt;Employee&gt; employeesMan = new ArrayList&lt;&gt;(); for(Employee employee : employees){ if(employee.getAge() &lt; 30){ employeesMan.add(employee); } } // 查找工资大于5000的 List&lt;Employee&gt; employeesSalaryExceed5000 = new ArrayList&lt;&gt;(); for(Employee employee : employees){ if(employee.getAge() &lt; 30){ employeesSalaryExceed5000.add(employee); } }} &emsp;&emsp;或者我们可以写三个方法：按年龄筛选、按性别筛选、按工资筛选，那我们可能需要提供非常多的方法(例如年龄大于某个值，年龄小于某个值，年龄在某个值到某个值之间) ​ 但是如果我们使用策略模式+lambda表达式，这些问题都能够轻松解决： 12345678910111213141516171819202122232425262728293031323334353637public class Learn1 { public static void main(String[] args) { List&lt;Employee&gt; employees = Arrays.asList( new Employee(&quot;zs&quot;, true, 25, 6000), new Employee(&quot;ls&quot;, true, 35, 9000), new Employee(&quot;ww&quot;, false, 21, 5000), new Employee(&quot;lx&quot;, true, 45, 12000), new Employee(&quot;qs&quot;, false, 33, 7000) ); // 查找年龄小于30的 List&lt;Employee&gt; employeesBelow30 = filter(employees, e -&gt; e.getAge() &lt; 30); // 查找性别为男的 List&lt;Employee&gt; employeesMan = filter(employees, e -&gt; e.isSex()); // 查找工资大于5000的 List&lt;Employee&gt; employeesSalaryExceed5000 = filter(employees, e -&gt; e.getSalary() &gt; 5000); } public static List&lt;Employee&gt; filter(List&lt;Employee&gt; employees, EmployeeOperater&lt;Employee&gt; employeeFilter){ List&lt;Employee&gt; employeesMeetCondition = new ArrayList&lt;&gt;(); for(Employee employee : employees) { if(employeeFilter.filter(employee)){ employeesMeetCondition.add(employee); } } return employeesMeetCondition; }}@FunctionalInterfaceinterface EmployeeOperater&lt;T&gt;{ boolean filter(T t);} &emsp;&emsp;这样一来我们的代码会优雅、简洁很多，我们无需再向上述代码一样每次都去写遍历的代码，也无需为了使用方便去编写太多重复的筛选方法，使用者可以根据自己的查询需求来制定查询策略即可。 &emsp;&emsp;后续使用Stream API还有更简便的方式，无需写接口与filter方法。 Lambda表达式的使用必须配合接口，并且只含有一个抽象方法的接口，格式： 123456@FunctionalInterfacepublic interface 接口名{ public abstract void 函数名(); //只能有一个抽象方法 // ... // 下面可以有默认方法等，只需要保证只有一个抽象方法即可} ​ 如果在接口内定义了多个抽象方法或不定义抽象方法，则不是函数式接口，采用@FunctionalInterface注解可以检查是否为函数式接口，若不是则在编译时会报错。 2 JDK提供的关于lambda表达式的四大函数式接口 Consumer&lt;T&gt; 消费型接口 void accept(T t); Supplier&lt;T&gt; 供给型接口 T get(); Function&lt;T, R&gt; 函数型接口 R apply(T t); Predicate&lt;T&gt; 断言型接口 boolean test(T t); 3 方法引用和构造器引用&emsp;&emsp;在使用lambda表达式时，我们每次都需要去实现接口的方法，这样可能会比较麻烦，JDK提供了方法引用来更加便捷的使用lambda表达式，即直接将已有的方法作为函数式接口的实现，方法引用有如下几种形式： 类名::静态方法名 对象::实例方法名 类名::实例方法名 12345678910111213141516public static void main(String[] args) { // 对象::实例方法名================ List&lt;Integer&gt; list = Arrays.asList(2,3,4,1,5); PrintStream printStream = System.out; Consumer&lt;Integer&gt; consumer = printStream::println; list.forEach(consumer); // 上面三行变为一行 list.forEach(System.out::println); // foreach需要提供Consumer接口的实现 // 类名::静态方法名 Comparator&lt;Integer&gt; comparable = Integer::compare; // T compare(T t1, T t2); // 类名::实例方法名，注意这种形式有一定的要求，在此例中，即第一个参数为方法的调用者，第二个参数为被引用方法的参数。 BiPredicate&lt;String, String&gt; predicate0 = (x, y) -&gt; x.equals(y); BiPredicate&lt;String, String&gt; predicate = String::equals; // boolean test(T t1, T t2);} 构造器引用： 类名::new &emsp;&emsp;构造器引用其实与方法引用类似，一个类可能有多个构造器，编译器会自动选择与接口参数相匹配的构造器方法。 1Supplier&lt;Employee&gt; supplier = Employee::new; // 由于Supplier接口的方法为T get()，所以自动选择的是无参构造器","link":"/2020/05/22/han-shu-shi-bian-cheng/"},{"title":"HashMap","text":"Java中的HashMap的原理就是哈希表，实现主要是通过数组+链表(或红黑树)。 首先初始化一个数组(默认大小为16)，当向其中插入key-value键值对时，会根据key通过散列算法计算哈希值，计算出的哈希值为该元素储存在数组中的位置(因此哈希值必须为合法的索引)。如果该位置上存在了元素(链表)，先检查该链表上是否有key相等的元素，如果没有就将这个元素作为链表节点连接在该位置已存在元素的后面，有的话就覆盖。 ​ ​ 一个key-value元素为一个Entry对象，Entry对象中存储了： ​ (1)该元素的hash值 ​ (2)键值key ​ (3)value ​ (4)下一个Entry对象的引用 ​ JDK1.8中Node类即为Entry类。 数组的初始大小HashMap的数组大小均为2的幂次方，无论你给的容量大小为多少，都会求出大于给定初始容量的最小的2的幂次方作为Hashmap数组的容量。至于为什么要是2的幂次方，等会再介绍，首先来看看HashMap如何来求取大于给定初始容量的最小的2的幂次方的数值。 123456789static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 每次初始化Hashmap数组大小时，都会使用该函数来计算数组的大小，传入的cap为构造函数传入的初始大小。 我们先忽视n=cap-1，我们来看位运算，通过5步位运算，我们可以求得一个int类型数字的最高位所对应的2的幂次方，也就是小于给定n的最大的2的幂次方：3=》2，10=》8. 现在我们假定一个int类型的数转化为2进制为1\\**，\\代表为任意一个数字 进行&gt;&gt;&gt;1：01**** 或|：1\\*** | 01**** = 11**** 进行&gt;&gt;&gt;2：0011** 或|：11**** | 0011** = 1111** 进行&gt;&gt;&gt;4：000011 或|：1111** | 000011 = 111111 我们可以看出无论最高位1后面是什么，我们都能把1的最高位后面都变为1，&gt;&gt;&gt;1与一次或操作能保证从最高位算起前两个均为1，继而&gt;&gt;&gt;2和或保证前4个均为1…，&gt;&gt;&gt;16和或保证前32位都为1，那么int最高位32位，进过这几步后一个int的数必定所有位都为1。 为什么容量要为2的幂次方？ 这是由于jdk在hashmap中求key的hashcode对应的数组index下标时，采用的是&amp;运算。本来我们应该是求hashcode%数组长度l，但是当数组长度l为2的幂次方时，就会有hashcode%l=hashcode&amp;(l-1)。&amp;运算的效率要高于取模运算。 当l为2的幂次方即l=2^n，则l-1的低n位都为1，进行与运算后只会保留hashcode的后n尾，后n位即为hashcode对l取余的值。 插入元素细节在JDK1.7中，HashMap调用put方法是采用头插法将元素加入对应的链表(单向链表)，我们通过调用Hash算法计算出Hashcode值，求出插入的key应该存储在数组中哪个下标对应的链表中，然后遍历查询该链表，如果链表中不存在插入的key，那么就在链表的头部插入该元素。 采用头插法的原因是因为链表是单向链表，如果插入到尾部的复杂度为O(n)，n为链表的长度，如果插入到头部，复杂度为O(1)。 但是其实如果需要向链表中插入新的元素，我们需要遍历链表去进行查找，如果这个key不存在，我们需要遍历所元素到链表的尾部，然后插入；如果这个key存在那么我们只是修改key所在链表节点对应的value即可，不需要再进行遍历，因此头插法和尾插法几乎没有差别。JDK1.7采用的头插法，而JDK1.8则采用尾插法。 JDK1.8在链表插入的逻辑上与JDK1.7类似，只是采用尾插法。但是JDK1.8在链表长度大于8时，会将链表转化为红黑树，红黑树的插入、删除、查找效率均为O(logn)，在JDK1.8中，一颗红黑树同样也是一个双向链表，因为TreeNode也是继承了Node。如果像JDK1.7只采用链表，那么在链表上查询效率为O(n)，在这里n指链表长度，不是HashMap的大小。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// JDK1.8中的putfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 数组还没初始化 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 根据hash值求出在数组上应该存储的位置，数组对应位置上没有元素就直接赋值 tab[i] = newNode(hash, key, value, null); else { // 数组对应位置上有元素 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 如果头结点的key与插入的key相同，就直接修改即可 e = p; else if (p instanceof TreeNode) // 如果这个节点类型是红黑树节点，意味着该位置已经转化为红黑树了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 通过红黑树添加的方法去添加节点或修改节点，key已经存在就返回对应的节点，不存在返回null else { for (int binCount = 0; ; ++binCount) { // 该位置为链表形式，遍历链表 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果遍历到链表尾部了还不存在put的key，就把这个节点插在尾部 // 判断节点数量是否大于8，binCount此时没有加上新加入的节点，TREEIFY_THRESHOLD为8，即binCount&gt;=7，转化时链表长度为binCount+1+1，1个为新插入的节点 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 将该链表转化为红黑树 break; } // 如果链表中存在该key，就直接修改 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key // 如果存在这个key，就修改对应的value即可 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 修改次数+1 if (++size &gt; threshold) resize(); // 超过容量就扩容 afterNodeInsertion(evict); return null;} 红黑树的具体细节参考JDK源码讲解的TreeMap。 扩容细节JDK1.7与JDK1.8扩容的思路类似，只是JDK1.8中扩容时需要考虑红黑树的扩容，在此直接介绍JDK1.8的扩容。 当HashMap的size到达阈值(阈值通常为负载因子*容量capicity)，HashMap的数组就会扩容，扩容主要是解决hash冲突，是的每个数组对应的链表或红黑树的长度变小，提高增删改查效率。 由前面的数组初始化我们可以知道，数组的容量一定为2的幂次方，并且扩容时就是将容量变为原来的2倍。那么，在数组扩容后需要对每个节点重新计算在数组中的位置，不过，由于数组容量是2的幂次方，我们可以看看一个节点在扩容前的位置与扩容后的位置，设扩容前大小为16，扩容后为32。 扩容前：hash&amp;(16-1)=hash&amp;1111 扩容后：hash&amp;(32-1)=hash&amp;11111 我们可以看到，扩容前和扩容后的在数组中索引对应的二进制后四位都相同，只有第五位会存在差异。如果hash值的第五位为0，那么扩容前和扩容后的索引相同，如果hash值的第五位为1，那么扩容后的索引为扩容前的索引+16。判断是否应该+16只需要计算hash&amp;16，如果为0就不变，如果为1就改变。 因此对于任意的扩容，如果扩容前数组的大小为2^n，节点的索引为i，那么扩容后节点的索引只可能为i或i+2^n，若hash&amp;2^n=0，则扩容后节点索引仍然为i；如果hash&amp;2^n=1，则扩容后索引为i+2^n。 利用这一特性，在进行扩容时，对于每一个链表或红黑树，都可以拆解为两个链表，一个链表为索引不变的节点，另一个链表为索引变化的节点，在转移数据时只需要把这两个链表(如果拆解后的链表长度大于8需要转化为红黑树)放置在新的数组中即可，这样具有较高的扩容效率，这也是HashMap数组长度要为2的幂次方的原因之一。 JDK实现的HashMap的负载因子默认为0.75，为什么是0.75呢？ ​ HashMap的负载因子用于当元素总个数大于负载因子*数组长度时，就进行扩容操作。负载因子就是用权衡空间利用率和操作元素效率的： 当负载因子较小时，这样一来每个桶(数组链表)所存放的元素数量相对更少，元素操作速度更快，但是浪费空间，并且如果频繁的插入元素，HashMap的扩容操作会更加频繁，扩容是比较耗时的，会造成效率低下 当负载因子较大时，每个桶存放的元素数量相对更多，元素操作的速度相对更慢，但是空间节省，并且频繁插入元素HashMap的扩容也会少一些 在HashMap的源码中提到，假设key的hashcode随机，每个桶中放入节点的频率满足以0.5为参数的泊松分布，在负载因子为0.75的情况下，每个桶中出现元素个数的概率如下： 12345678910* 0: 0.60653066* 1: 0.30326533* 2: 0.07581633* 3: 0.01263606* 4: 0.00157952* 5: 0.00015795* 6: 0.00001316* 7: 0.00000094* 8: 0.00000006* more: less than 1 in ten million ​ 这意味着当然元素个数大于8的概率非常低，因此负载因子为0.75比较好。当然JDK考虑到了hashcode并不一定完全随机，因此当元素大于8时会转化为红黑树来提高效率。","link":"/2020/06/20/hashmap/"},{"title":"Netty中的ChannelOption配置","text":"最近在学到netty是发现ServerBootstrap/Bootstrap类中有option的配置，发现option是配置在Channel上与socket标准相关的参数，于是总结一下有关该参数的配置。 SO_BACKLOGChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列。 TCP建立连接是需要时间，如果一段时间内有大量的连接请求，计算机能够处理的连接数量有限，那么就会将这些请求放入等待队列。由于TCP建立连接是要进行三次握手的，Linux中维护了两个队列分别为syns queue和accept queue，分别用于储存处于SYN_RCVD(半连接，第一次握手后)和ESTABLISHED(建立连接，第三次握手后)状态的连接。 当进行完第一次握手后，服务端会发起与客户端握手，这是这个连接就会被放入半连接队列中，等到客户端握手成功返回给服务端再次握手成功后，这个连接就会被移到建立连接的队列中，等待应用程序调用accept()来获取连接。 syns queue 队列长度由 /proc/sys/net/ipv4/tcp_max_syn_backlog 指定，默认为2048。 accept queue 队列长度由 /proc/sys/net/core/somaxconn 和使用listen函数时传入的参数，二者取最小值。默认为128。如果accpet queue队列满了，server会拒绝连接并将发送一个ECONNREFUSED错误信息Connection refused到client。 在netty中somaxconn是根据操作系统的配置来进行设置的 默认情况下，BACK_LOG与SOMAXCONN相同，我们可以在netty中进行配置来改小accept队列的最大长度，但是如果我们需要改大accept队列的长度，则需要把/proc/sys/net/core/somaxconn中的参数也改大，因为前面说到accept queue 队列长度由 /proc/sys/net/core/somaxconn 和使用listen函数时传入的参数，二者取最小值。 SO_KEEPALIVE该参数用于设置TCP连接，可以设置为true或false，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。 我们知道正常情况tcp连接关闭的时候，无论是客户端发起关闭还是服务发起关闭都会正常关闭连接，双方都会释放该连接占用的资源：应用释放资源，tcp层也会释放资源（主要是内存资源）。但是有些情况，该不该释放资源，就不知道了，如果服务端与客户端以长连接的方式保持连接，但是服务端已经长时间没有收到客户端发来的数据，造成这种原因包括以下几方面： 客户端确实没有需要发送的数据 客户端进程意外终止运行 客户端所在的服务器宕机，或停电 网络中间设备掐断连接，如防火墙对长时间不活动的连接，进行强制关闭 针对以上4种情况，只有1是正常情况，不应该关闭双方的连接，其它都是异常情况，服务端就应该关闭已经建立的连接，释放服务端的资源。如果不释放，就会存在很多半连接状态的连接，占用服务端大量资源。由于存在1这种正常的情况，服务端就不断随意关闭连接，需要一种手段来解决连接该不该关闭的问题。TCP/IP协议实现中就包含了心跳机制，在服务端程序程序中我们只需要设置SO_KEEPALIVE参数，那么如连接超过指定的时间（见第3节心跳相关的参数）没有收到数据，就会触发TCP层发起心调检测，从这里看可以看出TCP协议自身心跳的目的是检测异常链接，关闭链接，及释放资源。 另外，应用程序也可以自己实现心跳检测来实现关闭异常连接。 暂时使用过这几个参数，后续要到了再加","link":"/2020/05/27/netty-zhong-de-channeloption-pei-zhi/"},{"title":"Redis集群原理","text":"当需数据量巨大时，并发量高时，单个数据库的压力巨大，通常采用数据库分库分表的方式，同样redis提供了集群功能来实现数据分库存储，采用多台服务器来分担压力，避免单机压力过大造成宕机等故障。 1 Hash算法hash算法是利用操作key的hash值来计算该key位于哪个集群节点上，例如现在有N个redis集群，那么我们可以通过公式计算出该key位于的节点为： node=hash(key)%N 这种算法较为简单，通常如果每次都是两倍扩容的话，我们不需要全部数据进行迁移，只需要迁移50%左右的数据。但是该方式难以自由扩容，尤其是遇到在某个节点发生故障时，都会造成数据索引全被打乱，需要进行大量地数据迁移，重新映射数据与计算机节点的关系。 2 一致性Hash分区一致性Hash分区算法采用的是hash环，它对服务器节点也进行了hash并映射在hash环上，hash后对2^32取模，这样四个服务器节点也被映射在Hash环上(分布尽可能均匀)，这样一来，在进行查询或者添加key时，同样对key进行hash然后对2^32取模映射到Hash环上，该key存储在按顺时针方向到达的Hash环上第一个节点。 例如key1通过hash取模被映射在了node1与node2之间，顺时针第一个节点为node2，那么key1就存储在node2上 删除节点 当节点node3被删除后，这样key2,key3,key4,key5都将被迁移都node4去，这样一来会造成node4压力过大。 虚拟节点 上述环形哈希的缺点在于难以将所有的服务器节点均匀地分布在哈希环上造成单个节点压力过大，出现数据倾斜现象，因此就提出了虚拟节点的方式来尽量均匀地在哈希环上分配节点，就是将真实节点计算多个哈希形成多个虚拟节点并放置到哈希环上，定位算法不变，只是多了一步虚拟节点到真实节点映射的过程。 下图为添加虚拟节点后的哈希环： 当节点4挂掉后，key1, key2和key3会打到节点2的虚拟节点上(也就是存在节点2服务器上)，这样就不会造成服务器单点压力过大(每台服务器的虚拟节点可以更多，这样能是的节点在哈希环上分布更均匀)： 3 哈希槽哈希槽是redis采用的集群数据分布的方式，redis中有16384个槽，一个槽对应了一小部分空间(并不是一个key)，槽由所有的redis集群节点所分担。当客户端请求一个key时： 先打在任意一个节点上(下图假设先打在节点A上) 通过CRC16算法来计算key的哈希值 用hash值对16384取余来求取该key存储在哪个集群节点上，由于每个节点都保存了所有的哈希槽都被分配到了哪个节点上，因此直接去访问计算出来的节点即可。例如下图，请求首先打在A节点上，计算出key所处的节点应该为D节点，那么直接将请求转发到节点D上，保证最多两次命中。 增加节点与删除节点 当redis集群需要添加节点时，就会从现有的所有集群节点中各取一部分放入槽放入新的节点中(数据迁移+槽分配表更新)。","link":"/2020/05/24/redis-ji-qun/"},{"title":"Spring与Mybatis整合的原理(一)","text":"在单独使用Mybatis时，还是有些麻烦的，spring自己提供了一套数据库操作的jdbc，但是远不如Mybatis，接下来我们来看看Mybatis是如何无缝与Spring进行整合的。 在单纯使用Mybatis时，我们编写好myabtis的配置文件、mapper.xml文件以及对应mapper接口后，需要获得SqlSession对象调用其getMapper()方法来获取对应的mapper接口的代理对象。 12345678910111213141516171819public static void main(String[] args) throws Exception { //1.读取配置文件 InputStream inputStream = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;); //2.创建SqlSessionFactory工厂 SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); SqlSessionFactory factory = builder.build(inputStream); //3.创建SqlSession对象 SqlSession session = factory.openSession(); //4.使用Sqlsession创建Dao接口的代理对象 IUserDao userDao = session.getMapper(IUserDao.class); //5.使用代理对象执行方法 List&lt;User&gt; users = userDao.findAll(); for(User user:users){ System.out.println(user); } //6.释放资源 session.close(); inputStream.close();} 在这里，一个SqlSession对应一个数据库连接(jdbc连接)，因此我们在获取连接后，取出需要的mapper对象然后对数据库进行操作完成后释放连接即可，同时我们也可以利用SqlSession开启事务、提交事务、回滚事务等。 首先让我们来看看单纯使用Mybatis是如何对数据库进行操作的。 创建SqlSession对象单纯使用Mybatis时，我们从SqlSessionFactory中获取到的SqlSession对象为其实现类DefaultSqlSession对象。而在上面的代码中，我们获取到的factory的实际类型为DefaultSqlSessionFactory，执行其openSession方法主要执行openSessionFromDataSource方法： 123456789101112131415161718192021// class DefaultSqlSessionFactoryprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { // 通过配置信息拿到配置环境 final Environment environment = configuration.getEnvironment(); // 从配置环境中工厂中获取事务工厂 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); // 从数据源中获取事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 获取执行器，Executor是最终操作数据库的 final Executor executor = configuration.newExecutor(tx, execType); // 返回SqlSession return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + e, e); } finally { ErrorContext.instance().reset(); }} 该部分代码用于创建SqlSession执行了以下步骤： 获取到 TransactionFactory 事务工厂对象 通过 TransactionFactory 获取了一个 事务 Transaction 根据 execType（默认是 SIMPLE ） 获取了一个Executor （真正执行数据库操作的对象） 创建并返回 DefaultSqlSession 对象 从上面的代码我们可以看出，一个SqlSession对应一个事务(一一对应)，并且把数据库的执行类对象也传入了SqlSession中，在这里并没有创建连接。 Mapper对象我们在使用mybatis时仅仅需要创建Mapper的接口即可，而不需要创建Mapper对应的实现类，Mybatis在获取到Mapper接口文件时，就能帮我们创建出代理对象，因此通过getMapper获取到的是Mapper接口的代理类对象。 从SqlSession中获取Mapper对象并不意味着Mapper对象属于SqlSession，Mapper对象是通过SqlSession中的configuration对象所创建的(上面在创建SqlSession对象时传入的)，而configuration在创建时调用了MapperRegistry下的getMapper方法 1234567891011121314// class MapperRegistrypublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) { // 根据对应传入Mapper类型获取Mapper的代理工厂 final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;); } try { // 从代理工厂中创建一个Mapper的代理对象 return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e); }} 首先从已经扫描的mapper文件后生成的knownMappers对象中获取到Mapper的代理工厂 从代理工厂中创建一个Mapper的代理对象 代理对象的创建如下： 123456789// class MapperProxyFactoryprotected T newInstance(MapperProxy&lt;T&gt; mapperProxy) { return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);}public T newInstance(SqlSession sqlSession) { final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);} 使用Jdk的动态代理，传入实现了InvocationHandle接口的MapperProxy类，接下来我们再来看看这个代理类是如何执行接口的方法。 Mapper代理对象方法的执行MapperProxy类中的invoke方法及为代理对象执行的方法： 123456789101112131415// MapperProxy@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { // 当方法属于Object的方法，就直接把this(MapperProxy)传入执行，都是Object的子类 return method.invoke(this, args); } else { // 返回一个方法执行器来执行方法 return cachedInvoker(method).invoke(proxy, method, args, sqlSession); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); }} 在这里，如果调用的方法属于Object类，那么就用this直接调用自己方法(默认的Object类方法)。 如果不是Object类中的方法，那么是Mapper接口中定义的方法，那么将会创建一个方法执行器来执行(该方法创建后会被缓存起来) 123456789101112131415161718192021222324252627// MapperProxyprivate MapperMethodInvoker cachedInvoker(Method method) throws Throwable { try { // 如果创建过该方法的执行器可以直接返回，没有创建过则利用下面代码块的方法创建一个方法缓存起来然后返回。 return methodCache.computeIfAbsent(method, m -&gt; { if (m.isDefault()) { // &lt;1&gt;是默认方法default声明，则是用户在接口中自定义了该方法，不进行代理 try { if (privateLookupInMethod == null) { return new DefaultMethodInvoker(getMethodHandleJava8(method)); } else { return new DefaultMethodInvoker(getMethodHandleJava9(method)); } } catch (IllegalAccessException | InstantiationException | InvocationTargetException | NoSuchMethodException e) { throw new RuntimeException(e); } } else { // &lt;2&gt;不是default方法，一般都走这里 return new PlainMethodInvoker(new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); } }); } catch (RuntimeException re) { Throwable cause = re.getCause(); throw cause == null ? re : cause; }} methodCache.computeIfAbsent的第二个参数为一个函数型函数接口，首先看看computeIfAbsent里的代码： 123456789101112131415default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) { Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) { // 从缓存中获取该方法的执行器，如果没有，就利用Function函数接口创建一个，这个接口的apply方法在上面定义 V newValue; if ((newValue = mappingFunction.apply(key)) != null) { put(key, newValue); return newValue; } } return v;} 我们可以看到，该方法返回了一个方法执行器，如果没有创建过该方法的执行器，就利用apply方法创建一个然后缓存起来，因此我们还是回到lambda表达式中的代码块。 Mapper接口中的default方法由用户自己实现，不进行代理，而操作数据库的往往都是没有实现的，一般走&lt;2&gt;，接下来我们来看看新创建的这个类PlainMethodInvoker对象的定义。 12345678910111213private static class PlainMethodInvoker implements MapperMethodInvoker { private final MapperMethod mapperMethod; public PlainMethodInvoker(MapperMethod mapperMethod) { super(); this.mapperMethod = mapperMethod; } @Override public Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable { return mapperMethod.execute(sqlSession, args); }} 从这里可以看到，这个invoke方法就是Mapper代理对象执行的方法，MapperMethod是在创建PlainMethodInvoker时new出来的，excute方法几乎就是执行数据库操作的入口，我们接着看这个方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public Object execute(SqlSession sqlSession, Object[] args) { Object result; switch (command.getType()) { case INSERT: { Object param = method.convertArgsToSqlCommandParam(args); // 利用sqlSession进行数据库insert操作 result = rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param = method.convertArgsToSqlCommandParam(args); // 利用sqlSession进行数据库update操作 result = rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param = method.convertArgsToSqlCommandParam(args); // 利用sqlSession进行数据库delete操作 result = rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: // 利用sqlSession进行数据库select操作 if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) { executeWithResultHandler(sqlSession, args); result = null; } else if (method.returnsMany()) { result = executeForMany(sqlSession, args); } else if (method.returnsMap()) { result = executeForMap(sqlSession, args); } else if (method.returnsCursor()) { result = executeForCursor(sqlSession, args); } else { Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) { result = Optional.ofNullable(result); } } break; case FLUSH: // 利用sqlSession进行数据库flush操作(什么操作暂时不清楚) result = sqlSession.flushStatements(); break; default: throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName()); } if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) { throw new BindingException(&quot;Mapper method '&quot; + command.getName() + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;); } return result;} 到这里，我们就可以证明调用Mapper接口的方法，本质上就是在调用SqlSession的增删改查方法，而SqlSession的增删改查方法，本质上就是在调用Excutor的增删改查方法(前面在创建SqlSession对象中已经说了，SqlSession对象内部有一个Excutor对象)这个我们后续。 总结： SqlSession使用getMapper方法创建了一个Mapper接口的代理对象，并且把自身传递了进去 调用代理对象的方法本质上是调用了SqlSession的增删改查方法。","link":"/2020/05/29/spring-yu-mybatis-zheng-he-de-yuan-li/"},{"title":"Spring与Mybatis整合的原理(二)","text":"上一篇我们讨论到在单纯使用Mybatis的情况下，我们通过SqlSession的getMapper方法来获取Mapper接口的代理对象(每次调用getMapper就会新创建一个代理对象出来)，同时将SqlSession对象传入到Mapper代理对象中，调用代理对象的方法本质就是在调用SqlSession的增删改查方法。并且，每个DefaultSqlSession对象都对应于一个数据库连接(一个数据库事务)，这样我们不禁想到，在Spring整合Mybatis时，我们向Spring容器中注入的是Mapper接口的单例代理对象，在多线程的环境下，Mapper对象被同时调用，那么SqlSession是否是单例的呢(显然不是)？接下来让我们来看看Spring与Mybatis是如何整合的。 如何获得Mapper代理对象1. 注册Mapper扫描的组件在单纯使用Mybatis时获取代理对象非常简单，直接调用SqlSession的getMapper即可，对于Spring-Mybatis而言，使用者无需获取SqlSession对象，更不需要调用getMapper方法来获取Mapper代理对象，只需要添加@Mapper或者@MapperScan注解即可在Spring容器启动时直接向容器中注入Mapper接口的代理对象。我们可以看看@MapperScan注解： 123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class)@Repeatable(MapperScans.class)public @interface MapperScan { 熟悉Spring的同学就会知道，MapperScan注解的引入会使用@Import来向容器中注册MapperScannerRegistrar组件 1public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware MapperScannerRegistrar实现了ImportBeanDefinitionRegistrar接口，实现了该接口的类可以在Spring启动时调用registerBeanDefinitions方法向容器中修改或添加BeanDefinition，Spring在创建Bean对象时就会根据所有的BeanDefinition来创建Bean。 在这个类中向容器中注册Bedefinition的关键语句如下： 12345// 创建一个BeanDefinition的BuilderBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class);// 省略(向Builder中添加一些属性)...// 通过Builder获取BeanDefinition，并将registry.registerBeanDefinition(beanName, builder.getBeanDefinition()); 由于代码比较长，都是向BeanDefinition中添加一些属性因此省略掉了，我们通过上面的两行代码就可以看到向容器中注入MapperScannerConfigurer类的BeanDefinition。 MapperScannerConfigurer是一个重要的类，用于配置Mapper接口扫描，并且进行Mapper接口扫描，其的定义如下： 12public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware { 这个类实现了很多接口,我们主要需要关注的是BeanDefinitionRegistryPostProcessor，在Spring中, 实现了该接口的类会在BeanDefinition都注册完成后调用postProcessBeanDefinitionRegistry方法，可以用于修改Bean的定义信息。因此我们来看看该方法： 1234567891011121314151617181920212223242526272829// class MapperScannerConfigurer@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) { // 初始化一些属性 if (this.processPropertyPlaceHolders) { processPropertyPlaceHolders(); } // 包扫描器，mybatis继承Spring的包扫描器 ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // 初始化一些成员变量 scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass); if (StringUtils.hasText(lazyInitialization)) { scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization)); } scanner.registerFilters(); // 执行扫描 scanner.scan( StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));} Mybatis使用了Spring提供的扫描类，加上了自己需要的一些属性来对MapperScan中列出的包进行扫描，在最后一步执行扫描中完成了Mybatis的FactoryBean注入，该FactoryBean用来生成Mapper的代理对象，我们接下来看看为什么要注入FactoryBean呢？ 2 创建对应的FactoryBean首先，我们先不去看Spring-Mybatis的源码，学过Spring的都知道Spring可以通过FactoryBean的方式来注入组件，当Spring开始创建Bean对象的时，如果遇到FactoryBean接口的实现类，便会调用FactoryBean的getObject()来创建Bean对象，因此Spring容器中注入的实际是getObject()返回的对象的Bean对象。 提到这，我们自然而然可以想到当我们扫描到所有的Mapper接口，我们可以通过FactoryBean的方式来向容器中注入一个Mapper的代理对象，确实，Mybatis与Spring整合就是这么做的，现在让我们来看看源码是如何完成这一操作的。 我们进入scan()方法，主要就是执行了doScan()方法，它的第一先用Spring的包扫描功能扫描的所有的Mapper接口封装为BeanDefinition，然后该方法调用了processBeanDefinitions，将Mapper接口的BeanDefinition偷梁换柱变成FactoryBean： 123456789101112131415161718192021222324// class ClassPathMapperScannerprivate void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) { // 传入的beanDefinitions就是所有Mapper接口的BeanDefinition GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) { definition = (GenericBeanDefinition) holder.getBeanDefinition(); // 获取每个BeanDefinition所对应的Mapper接口的接口名 String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -&gt; &quot;Creating MapperFactoryBean with name '&quot; + holder.getBeanName() + &quot;' and '&quot; + beanClassName + &quot;' mapperInterface&quot;); // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean // 以下两句就是将BeanDefinition的类型修改为MapperFactoryBean并把接口的类型传入了MapperFactoryBean中。 // &lt;1&gt;获取带参数的构造函数，并把Mapper接口的接口名传入(这里是不需要管Bean的类型就可以直接指定) definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // issue #59 // &lt;2&gt;将这个BeanDefinition的类型修改为MapperFactoryBean类型(mapperFactoryBeanClass = MapperFactoryBean.class) definition.setBeanClass(this.mapperFactoryBeanClass); definition.getPropertyValues().add(&quot;addToConfig&quot;, this.addToConfig); // 将代理对象的一些属性设置进去(例如SqlSession的类型等，省略) } 上面代码的核心部分就是&lt;1&gt;&lt;2&gt;两处，将扫描的所有Mapper接口的BeanDefinition都更改为了MapperFactoryBean类型，这样，Spring容器在创建Bean对象时就会调用getObject()方法来返回我们想要的对象(即Mapper接口的代理对象)。我们可以看看MapperFactoryBean的getObject方法： 1234@Overridepublic T getObject() throws Exception { return getSqlSession().getMapper(this.mapperInterface);} 我们终于看到了熟悉的代码，利用SqlSession来获取Mapper接口的代理对象。这样一来我们就知道了Mybatis-Spring在Spring容器初始化时如何注入Mapper接口的代理对象。但是我们仍然有一个疑问：Mapper代理对象在Spring中是单例的，我们看到Mapper代理对象是在Spring容器初始化时通过SqlSession注入的，联系我们前面单纯使用Mybatis时，一个SqlSession对应一个数据库连接，那么岂不是在多线程环境下我们一直都是使用同一个数据库连接，这怎么合理呢？可以肯定的是，Mybatis-Spring在多线程下当然使用的不是同一个数据库连接，接下来我们来看看Mybatis-Spring是怎么做到的吧。 Mybatis-Spring中的SqlSession我们上面看到了Mapper代理对象是通过getSqlSession().getMapper(this.mapperInterface)来获取的，那么我们查看一下getSqlSession()，发现其返回的是SqlSessionTemplate类型，这好像与我们单纯使用Mybatis时的SqlSession类型DefaultSqlSession不一样，SqlSessionTemplate就是Mybatis-Spring获取不同数据库连接的关键所在，我们跟踪到SqlSessionTemplate的构造函数： 1234567891011121314// class SqlSessionTemplatepublic SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) { notNull(sqlSessionFactory, &quot;Property 'sqlSessionFactory' is required&quot;); notNull(executorType, &quot;Property 'executorType' is required&quot;); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; // 创建SqlSession的代理对象 this.sqlSessionProxy = (SqlSession) newProxyInstance(SqlSessionFactory.class.getClassLoader(), new Class[] { SqlSession.class }, new SqlSessionInterceptor());} 看到这里，原来SqlSessionTemplate中有一个SqlSession的代理对象，我们查看SqlSessionTemplate中的selectOne等操作数据库的方法也可以发现其实都是在调用SqlSession代理对象的操作数据库方法。这样我们应该继续跟踪SqlSessionInterceptor的invoke方法： 1234567891011121314151617181920212223242526272829303132333435// class SqlSessionTemplate$SqlSessionInterceptor@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 获取一个新的SqlSession SqlSession sqlSession = getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try { // 利用这个新的SqlSession来执行对应的数据库操作 Object result = method.invoke(sqlSession, args); if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) { // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() sqlSession.commit(true); } return result; } catch (Throwable t) { Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) { // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator .translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) { unwrapped = translated; } } throw unwrapped; } finally { if (sqlSession != null) { // 关闭SqlSession closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); } }} 看过这个方法后就真相大白了，原来：Spring容器中的Mapper代理对象是通过SqlSessionTemplate获取的单例对象，而SqlSessionTemplate内部保存了一个SqlSession的代理对象，当Mapper对象执行数据库操作的方法时，还是与Mybatis原来一样去调用Mapper内部保存的SqlSession对象的对数据库增删改查的方法，只不过在与Spring整合后，Mapper代理对象中的SqlSession类型为SqlSessionTemplate。每次调用SqlSessionTemplate的操作数据库的方法都是调用其内部的SqlSession的代理对象的相同方法，而这个代理对象的方法每次都会先从重新生成一个DefaultSqlSession对象来执行数据库操作。这样一来就做到了SqlSession与Mapper代理对象的解耦，每次调用方法都是不同的SqlSession对象。","link":"/2020/06/02/spring-yu-mybatis-zheng-he-yuan-li-er/"},{"title":"Netty核心组件-NIO","text":"NIO（JDK1.4）模型是一种同步非阻塞IO，主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector（多路复用器）。 1 Buffer1.1 基本使用Buffer的本质就是一个存放数据内存块，可以看成一个容器对象(内部含有数组)，该对象提供了一系列方法，能让我们轻松的使用内存块(数组)，缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态变化情况。 JDK中Buffer的子类如下： 首先，Buffer都具有4个重要属性： 12345// Invariants: mark &lt;= position &lt;= limit &lt;= capacityprivate int mark = -1;private int position = 0;private int limit;private int capacity; Buffer分为读模式和写模式，一次读操作或写操作都可能会导致position后移(可能即为JDK提供了不同的方法，有读操作后position后移的方法，也有读操作后position不后移的方法)： Buffer的使用： 1234567891011121314151617public class LearnBuffer { public static void main(String[] args) { IntBuffer buffer = IntBuffer.allocate(5); // postion=0, capacity=5, limit=5, mark=-1 for (int i = 0; i &lt; buffer.capacity(); i++) { buffer.put(i*2); // 每次put后position属性+1 } buffer.flip(); // 将position重置到0 buffer.position(1); // 将position置为1 buffer.limit(3); // 将limit置为3 while (buffer.hasRemaining()){ System.out.println(buffer.get()); // 每次get()都会导致postion+1 } }} 1.2 HeapBuffer和DirectByteBuffer​ HeapBuffer被称为No-DirectBuffer，这一缓冲区创建在JVM内存的堆区中，受到JVM的内存管理，创建和释放都是由JVM操作的。上面通过allocate方法创建的Buffer就是HeapBuffer。 ​ 利用HeapBuffer读取数据的过程如下： ​ Java程序向操作系统发起read()的系统调用，操作系统让CPU启动DMA来将物理磁盘中的数据读取到内核地址空间中的缓冲区，然后再将缓冲区中的内容拷贝到用户地址空间的Buffer对象中。在这过程中发生了一次从内核地址空间到用户地址空间的拷贝。由于HeapBuffer需要经过一次拷贝，其与BIO的文件操作代价相同，效率相差不多，但下面介绍的DirectByteBuffer效率更高。 ​ 针对如上HeapBuffer的一次拷贝进行优化，DirectByteBuffer是创建在堆外内存区的，即不受JVM的内存管理机制所控制，那么为什么DirectByteBuffer可以减少这一次拷贝呢？ ​ 这要归功于mmap()的系统调用，这种方式的I/O原理就是将用户缓冲区（user buffer）的内存地址和内核缓冲区（kernel buffer）的内存地址做一个映射，也就是说系统将内核地址空间的缓冲区和用户地址空间的缓冲区映射物理内存上的相同位置，这样一来就可避免了从内核空间向地址空间的拷贝消耗。 在HeapBuffer中，内核地址空间的缓冲采用的就是DirectByteBuffer，然后再把DirectBuffer中的数据拷贝到HeapBuffer中。通过跟踪ByteBuffer的源码可以查看到其read()方法调用到了IOUtil的read()方法： 123456789101112131415161718192021static int read(FileDescriptor fd, ByteBuffer dst, long position, NativeDispatcher nd) throws IOException{ if (dst.isReadOnly()) throw new IllegalArgumentException(&quot;Read-only buffer&quot;); if (dst instanceof DirectBuffer) return readIntoNativeBuffer(fd, dst, position, nd); // Substitute a native buffer ByteBuffer bb = Util.getTemporaryDirectBuffer(dst.remaining()); // 获得一个临时的DirectBuffer try { int n = readIntoNativeBuffer(fd, bb, position, nd); // 使用native方法利用DirectBuffer进行读取 bb.flip(); if (n &gt; 0) dst.put(bb); // 将DirectBuffer读取到的数据放入到ByteBuffer中 return n; } finally { Util.offerFirstTemporaryDirectBuffer(bb); }} DirectBuffer可以通过ByteBuffer.allocateDirect(int len)来进行申请。 1ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024); // 申请出来为DirectByteBuffer对象 1.3 DirectBuffer详解说明 Java中申请的DirectBuffer存在的内存区域究竟是内核地址空间还是用户地址空间呢？ ​ DirectBuffer(以DirectByteBuffer为例)其实分为两部分： 12345 Java | native |DirectByteBuffer | malloc'd[ address ] -+-&gt; [ data ] | 一部分为Java的堆内对象，DirectByteBuffer没有byte数组，但是有一个long address的属性，该属性在Buffer类中有，官方注释说明只用于DirectBuffer才有效： 12345public abstract class Buffer { // Used only by direct buffers // NOTE: hoisted here for speed in JNI GetDirectBufferAddress long address; ​ 另一部分为利用c语言的malloc申请的字节数组，该数据就是缓冲区，该缓冲区是用C语言API申请的，属于该进程，位于用户地址空间，只不过操作系统该部分内存有读写的权利，不需要经过内核地址空间的拷贝。 ​ DirectBuffer的主要缓冲区属于堆外内存，其生命周期不完全被JVM管制，因此使用需要谨慎，必须使用Full GC才能进行回收，但是Full GC的性能损耗很大，因此合理使用DirectBuffer才能有更高的效率，Netty封装了DirectBuffer比DirectBuffer更好用。 为什么DirectBuffer要在堆外申请，不能申请在堆内或者直接使用HeapBuffer进行mmap内存映射吗？ ​ JVM并不是不能直接用java HeapBuffer或java byte[]直接做IO读写，但JVM在GC过程中会移动内存，JVM移动内存的操作对操作系统是不可见的，因此必须mark此段内存不能移动，从而影响GC效率，所有采用堆外内存更为合适。 ​ Java利用HeapBuffer进行IO操作时都会使用到临时的DirectByteBuffer缓冲区。 性能说明 ​ 对于文件的读写，使用FileChannel的read或write方法无论传入的是HeapBuffer还是DirectBuffer都是会创建一个临时的DirectBuffer，所以效率是相同的。想要有更高的性能使用MappedByteBuffer就不会进行内核空间到用户空间的拷贝了。 MappedByteBuffer使用： 1234567891011public static void main(String[] args) throws IOException { FileChannel inChannel = FileChannel.open(Paths.get(&quot;pom.xml&quot;), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(&quot;pom2.xml&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); // 读取文件的缓冲空间 MappedByteBuffer mappedByteBuffer = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); outChannel.write(mappedByteBuffer); inChannel.close(); outChannel.close();} ​ 由于JDK没有提供直接将DirectBuffer写到文件中的方法，因此还是需要一次拷贝的。 普通NIO文件拷贝： 1234567891011public static void nioFileCopy() throws IOException { FileChannel inChannel = FileChannel.open(Paths.get(&quot;pom.xml&quot;), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(&quot;pom2.xml&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); ByteBuffer buf = ByteBuffer.allocate((int) inChannel.size()); buf.flip(); outChannel.write(buf); inChannel.close(); outChannel.close();} ​ 相比MappedByyeBuffer多了一次拷贝。 2 ChannelNIO的通道类似于流，但有些区别如下： 通道可以同时进行读写，而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据，也可以写数据到缓冲 JDK提供的Channel类型有很多，常用的有FileChannel(文件读写通道)、DatagramChannel(UDP数据传输通道)、ServerSocketChannel 和 SocketChannel (ServerSocketChanne 类似 ServerSocket , SocketChannel 类似 Socket，TCPS数据传输)。 FileChannel类： 用于对本地文件的读写操作，主要的方法有： 1234public int read(ByteBuffer dst) //从通道读取数据并放到缓冲区中public int write(ByteBuffer src) //把缓冲区的数据写到通道中public long transferFrom(ReadableByteChannel src, long position, long count) //从目标通道中复制数据到当前通道public long transferTo(long position, long count, WritableByteChannel target) //把数据从当前通道复制给目标通道 实例–使用FileChannel实现文本的拷贝 123456789101112131415161718192021222324252627public class LearnChannel { public static void main(String[] args) throws IOException { // 创建文件对象 File file = new File(&quot;/Users/zhanglei/java/IdeaProjects/netty/src/main/java/com/tomcode/nio/LearnChannel.java&quot;); File target = new File(&quot;j.txt&quot;); // 创建流对象 FileInputStream fileInputStream = new FileInputStream(file); FileOutputStream fileOutputStream = new FileOutputStream(target); // 获取channel，channel需要从流对象中获取，流对象中具有channel属性但是为空，当调用getChannel时会创建channel对象 FileChannel inputChannel = fileInputStream.getChannel(); FileChannel outputChannel = fileOutputStream.getChannel(); // 创建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(512); // 把inputchannel中的数据写到buffer中然后把buffer写到outputchannel int len = -1; while((len = inputChannel.read(buffer)) != -1){ buffer.flip(); outputChannel.write(buffer); buffer.clear(); // 必须clear()，否则postion=limit无法再读入数据，每次len=0陷入死循环 } // 流对象关闭channel就会关闭 fileInputStream.close(); fileOutputStream.close(); }} 同样，我们可以使用transferFrom就可以直接完成拷贝而不需要使用缓冲区了(其实底层也是利用了缓冲区)。 1outputChannel.transferFrom(inputStream); 使用Channel和Buffer的注意事项 ByteBuffer 支持类型化的put 和 get, put放入的是什么数据类型，get就应该使用相应的数据类型来取出，否则可能有BufferUnderflow-Exception 异常。(putInt–getInt，putChar–getChar) NIO 还提供了 MappedByteBuffer， 可以让文件直接在内存（堆外的内存）中进行修改，效率很高。 前面我们讲的读写操作，都是通过一个Buffer 完成的，NIO 还支持 通过多个Buffer (即 Buffer 数组) 完成读写操作，即 Scattering 和 Gathering 3 SelectorSelector选择器，作用是用于管理多个Channel，使用Selector实现IO多路复用，通常一个线程有一个Selector，而一个Selector对应多个Channel负责I/O，其工作的主要步骤： (1) 在服务器启动时，创建ServerSocketChannel并利用SelectionKey register(Selector sel, int ops)方法注册到Selector中，每个channel在一个Selector中对应一个的SelectionKey。 (2) 在循环中调用Selector的int select()方法来判断是Selector中是否有Channel需要处理(返回值为需要处理的channel数量)，注意select()方法是阻塞的，想要非阻塞可以调用select(int timeout)或selectNow()。 (3) 每当一个客户端需要连接服务器时，Selector的select方法会返回1，此时表明有channel发生了事件需要处理，那么就通过Selector的selectKeys()方法获取到所有事件的SelectionKey，可以通过SelectionKey判断其对应的是否为ServerSocketChannel，如果是则调用其accept()方法(不会阻塞，因为已经判断出有客户端要连接)。 (4) 通过ServerSocketChannel的accept方法都能获取到一个SocketChannel，将这个SocketChannel注册到Selector中。 (5) 回到(2)的循环，去判断各个channel是否有事件发生，有的话通过SocketChannel和ServerSocketChannel分开处理，ServerSocketChannel有事件就获取SocketChannel注册到Selector，SocketChannel有时间就读写。 实例–使用Selector来实现服务端： server端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class SelectorLearn { public static void main(String[] args) throws IOException { // 创建ServerSocketChannel ServerSocketChannel server = ServerSocketChannel.open(); server.socket().bind(new InetSocketAddress(8888)); // 创建Selector Selector selector = Selector.open(); // 设置Channel为非阻塞的 server.configureBlocking(false); // 将server注册到selector，为ACCEPT操作，ServerSocketChannel才为该方式 server.register(selector, SelectionKey.OP_ACCEPT); while (true) { if(selector.select(1000) == 0){ // 等待获取200ms，没有事件 System.out.println(&quot;1s没有事件&quot;); continue; } System.out.println(&quot;event!&quot;); // 获取并遍历有事件发生的SelectionKey Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while(iterator.hasNext()){ SelectionKey key = iterator.next(); if(key.isAcceptable()){ // 证明是ServerSocketChannel，获取对应的SocketChannel SocketChannel socket = server.accept(); socket.configureBlocking(false); // 向selector注册socket，为读操作事件(因为建立连接不一定马上有数据传输) socket.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(1024)); } if(key.isReadable()){ // 证明是SocketChannel SocketChannel socket = (SocketChannel) key.channel(); ByteBuffer buf = (ByteBuffer) key.attachment(); socket.read(buf); String content = new String(buf.array()); System.out.println(&quot;收到:&quot; + content); } // 处理必须从集合中移除，否则会重复处理 iterator.remove(); } } }} 说明： 一个Selector可以注册多个Channel，也可以注册不同种类的Channel（SocketChannel/ServerSocketChannel），每个Channel在注册到某个Selector上时会生成一个SelectionKey对象，里面保存了Channel，Selector以后选择的就是SelectionKey对象，SelectionKey与Channel一一对应。 当调用了Selector的selectKeys方法后，如果此时ServerSocketChannel有多个连接请求，在调用accept后也只会连接一个，然后再循环时因为还有连接未处理则ServerSocketChannel还是有事件，接着就可以处理下一个连接。那么还未被accept的连接都会存储在操作系统的一个连接队列中等待应用程序处理。 Selector： 1234567selector.select(); //阻塞selector.select(1000); //阻塞1000毫秒，在1000毫秒后返回selector.wakeup(); //唤醒selectorselector.selectNow(); //不阻塞，立马返还selector.selectedKeys(); // 当前有事件发生的SelectionKeyselector.keys(); // selector中注册的所有SelectionKey SelectionKey： 123456789101112int OP_ACCEPT：有新的网络连接可以 accept，值为 16int OP_CONNECT：代表连接已经建立，值为 8int OP_READ：代表读操作，值为 1 int OP_WRITE：代表写操作，值为 4 public abstract Selector selector(); //得到与之关联的 Selector 对象public abstract SelectableChannel channel(); //得到与之关联的通道public final Object attachment(); //得到与之关联的共享数据public abstract SelectionKey interestOps(int ops); //设置或改变监听事件public final boolean isAcceptable(); //是否可以 acceptpublic final boolean isReadable(); //是否可以读public final boolean isWritable(); //是否可以写 ServerSocketChannel： ServerSocketChannel 在服务器端监听新的客户端 Socket 连接 12345public static ServerSocketChannel open(); // 得到一个 ServerSocketChannel 通道public final ServerSocketChannel bind(SocketAddress local); // 设置服务器端端口号public final SelectableChannel configureBlocking(boolean block); // 设置阻塞或非阻塞模式，取值 false 表示采用非阻塞模式public SocketChannel accept(); // 接受一个连接，返回代表这个连接的通道对象public final SelectionKey register(Selector sel, int ops); // 注册一个选择器并设置监听事件 SocketChannel： SocketChannel，网络 IO 通道，具体负责进行读写操作。NIO 把缓冲区的数据写入通道，或者把通道里的数据读到缓冲区。 12345678public static SocketChannel open();//得到一个 SocketChannel 通道public final SelectableChannel configureBlocking(boolean block);//设置阻塞或非阻塞模式，取值 false 表示采用非阻塞模式public boolean connect(SocketAddress remote);//连接服务器public boolean finishConnect();//如果上面的方法连接失败，接下来就要通过该方法完成连接操作public int write(ByteBuffer src);//往通道里写数据public int read(ByteBuffer dst);//从通道里读数据public final SelectionKey register(Selector sel, int ops, Object att);//注册一个选择器并设置监听事件，最后一个参数可以设置共享数据public final void close();//关闭通道","link":"/2020/08/31/NIO/"},{"title":"Netty核心组件-ChannelFuture","text":"Netty的特点就是异步非阻塞的网络框架，在Netty中，几乎所有的IO操作都是异步执行的，我们调用IO操作的方法后，方法会返回一个Future类型的对象(一般为ChannelFuture)，ChannelFuture继承于JDK的Future对象，对Future进行了扩充。 JDK中的Future​ 从JDK1.5开始官方提供了Callable和Future接口，通过这两个接口，可以使得父线程在子线程执行完后得到任务执行的结果。 ​ 当一个操作比较耗时，而后面将要执行的几个任务与这个操作的结果无关，此时我们可以考虑使用异步执行，这与前端js中的ajax是相同的原理。在执行该函数时，我们马上返回一个对象，将耗时的操作放在其他线程执行，这样我们在父线程中就可以进行其他的操作，真正的数据可以等到我们需要它的时候再从函数的返回对象中获取出来。 Callable与RunnableJDK的线程池中可以提交两种类型的接口，即Callable与Runnable。 ​ java.lang.Runnable是JDK早期提供的线程相关的类，当创建一个线程时或者想线程池中提交一个任务时，需要将Runnable接口的对象传递进去，那么在线程分到时间片时就会自动的调用Runnable中唯一的run方法，该方法没有返回值。 123public interface Runnable { public abstract void run();} ​ ​ 而java.util.concurrent.Callable是JDK后续提供的，它也是一个接口，同样向线程池中提交一个任务时，也可传递以个Callable对象(自己创建线程时不能传递Callable对象，因为Thread没有提供Callable的构造函数)，Callable接口有一个方法call()，在线程分配到时间片时，会自动调用call()方法，与Runnbale不同的是，call()方法是有返回值的。 123public interface Callable&lt;V&gt; { V call() throws Exception;} FutureJDK中实现异步操作需要Callable配合Future使用，Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 12345678public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); // 取消任务 boolean isCancelled(); // 判断任务是否取消 boolean isDone(); // 任务是否完成 V get() throws InterruptedException, ExecutionException; // 阻塞获取任务的结果 V get(long timeout, TimeUnit unit) // 带超时的获取任务结果 throws InterruptedException, ExecutionException, TimeoutException;} 那么如何通过Callable与Future来实现异步操作呢？在JDK提供的线程池ExecutorService中我们可以看到submit方法有不同的重载版本 123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); 这意味着我们想线程池中提交一个Callable方法可以得到一个Future对象，在未来的某个地方我们可以调用Future对象的get()方法来获取到该任务返回的结果。 12345678910111213141516171819202122232425@Slf4jpublic class SchedulePool { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()*2); log.debug(&quot;submit other task&quot;); Future&lt;Integer&gt; hello = executorService.submit(() -&gt; { try { sleep(1500); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;hello&quot;); return 2; }); log.debug(&quot;main task start&quot;); Thread.sleep(1000); log.debug(&quot;main task end&quot;); Integer i = hello.get(); log.debug(&quot;{}&quot;,i); executorService.shutdown(); }} 输出： 1234510:35:57.249 com.zl.threadpool.SchedulePool [main] - submit other task10:35:57.284 com.zl.threadpool.SchedulePool [main] - main task start10:35:58.289 com.zl.threadpool.SchedulePool [main] - main task end10:35:58.789 com.zl.threadpool.SchedulePool [pool-1-thread-1] - hello10:35:58.789 com.zl.threadpool.SchedulePool [main] - 2 ​ 从打印结果我们可以看到提交任务后我们马上拿到一个Future对象(此时任务还未执行完返回)，我们接着执行了打印操作，然后通过Future对象的get方法阻塞获取了先前提交任务的返回结果，直到任务完成后才拿到了结果打印。 ​ 本来两个任务需要1s+1.5s=2.5s才能够完成，现在只需要1.5s就能够完成。 ​ 提交Runnable对象就无法拿到返回的结果，不过也会返回一个Future对象，可以用于判断任务是否完成，即调用Future的get方法返回的是null，但是可以通过Future的isDone方法判断run方法是否执行完成。 FutureTask​ 不通过线程池提交任务，想要通过Thread类来实现异步调用后返回结果可以使用FutureTask类，FutureTask类其实也是实现了Runable接口，和Runable创建方法类似，此外，FutureTask还实现了Future接口，可通过FutureTask获取执行结果。 ​ FutureTask的构造函数必须传入Callable对象，因此我们可以从FutureTask中get到Callable的执行结果。 123456789101112131415161718public class CreateThread_FutureTask { public static void main(String[] args) throws ExecutionException, InterruptedException { FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;执行了&quot;); return 1; } }); Thread thread = new Thread(task, &quot;thread1&quot;); thread.start(); Integer integer = task.get(); // 阻塞，等待task任务的返回结果 System.out.println(integer); // 打印1 }} Future的缺点只能用以下方式获取结果： V get()阻塞等待 轮询boolean isDone(); 有限等待V get(long timeout, TimeUnit unit) 执行状态只有两种： boolean isDone(); boolean isCancelled(); 问题： 接口中只有isDone()方法判断一个异步操作是否完成，但是对于完成的定义过于模糊，JDK文档指出正常终止、抛出异常、用户取消都会使isDone()方法返回真。在我们的使用中，我们极有可能是对这三种情况分别处理，而JDK这样的设计不能满足我们的需求。 对于一个异步操作，我们更关心的是这个异步操作触发或者结束后能否再执行一系列动作。比如说，我们浏览网页时点击一个按钮后实现用户登录。在javascript中，处理代码如下： 123$(&quot;#login&quot;).click(function(){ login(); }); Netty中的Future​ 鉴于JDK提供的Future对象的缺点，Netty对JDK的Future进行了扩展，同样也命名为Future，主要方法如下： 123456789101112131415// 异步操作完成且正常终止boolean isSuccess();// 异步操作是否可以取消boolean isCancellable();// 异步操作失败的原因Throwable cause();// 添加一个监听者，异步操作完成时回调，类比javascript的回调函数Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener);Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener);// 阻塞直到异步操作完成Future&lt;V&gt; await() throws InterruptedException;// 同上，但异步操作失败时抛出异常Future&lt;V&gt; sync() throws InterruptedException;// 非阻塞地返回异步结果，如果尚未完成返回nullV getNow(); 从Future对象中可以获取任务执行的状态： 未执行完成时，isDone返回false，其他的自然返回false。而当任务完成后，isDone为true，但是完成的状态可能是成功完成了，也可能是发生了异常，还可能是被取消对应于右边三个状态。 12345678910111213141516* +---------------------------+* | Completed successfully |* +---------------------------+* +----&gt; isDone() = true |* +--------------------------+ | | isSuccess() = true |* | Uncompleted | | +===========================+* +--------------------------+ | | Completed with failure |* | isDone() = false | | +---------------------------+* | isSuccess() = false |----+----&gt; isDone() = true |* | isCancelled() = false | | | cause() = non-null |* | cause() = null | | +===========================+* +--------------------------+ | | Completed by cancellation |* | +---------------------------+* +----&gt; isDone() = true |* | isCancelled() = true |* +---------------------------+ 在JDK中，我们从Future中获取的数据是从Callable接口的call方法返回值获取的，JDK的异步实现方式是Future+Callable。而在Netty中，并没有使用Callable接口，而是自己提供了Promise接口继承Future接口提供数据。 123456789101112public interface Promise&lt;V&gt; extends Future&lt;V&gt; { // 标记异步操作结果为成功，如果已被设置（不管成功还是失败）则抛出异常IllegalStateException Promise&lt;V&gt; setSuccess(V result); // 同上，只是结果已被设置时返回False boolean trySuccess(V result); // 设置失败 Promise&lt;V&gt; setFailure(Throwable cause); boolean tryFailure(Throwable cause); // 设置不可取消 boolean setUncancellable();} 需要注意的是，setSucess与setFailure只能被调用一次，任何一个方法被调用过了都不能再调用了，再次调用会抛出异常，两个方法会通知添加到其内部的Listener执行对应的行为。 GenericFutureListener GenericFutureListener是Future对象的监听者，在Future对象完成任务后，回调其中的operationComplete方法。 123456789public interface GenericFutureListener&lt;F extends Future&lt;?&gt;&gt; extends EventListener { /** * Invoked when the operation associated with the {@link Future} has been completed. * * @param future the source {@link Future} which called this callback */ void operationComplete(F future) throws Exception;} 关于Netty异步调用的部分类结构图如下: ​ AbstractFuture 该抽象类实现了两个get()方法，阻塞等待获取异步执行的结果，下面给出其中一个，另外一个是带超时的get。 123456789101112131415public abstract class AbstractFuture&lt;V&gt; implements Future&lt;V&gt; { @Override public V get() throws InterruptedException, ExecutionException { await(); // 阻塞等待唤醒 Throwable cause = cause(); // 获取是否有异常 if (cause == null) { return getNow(); // 无异常，直接返回结果，有可能还未执行完(被打断的情况) } if (cause instanceof CancellationException) { throw (CancellationException) cause; } throw new ExecutionException(cause); } ChannelFuture ChannelFuture主要添加了两个方法 123456public interface ChannelFuture extends Future&lt;Void&gt; { // 返回关联此Future对象的channel Channel channel(); // 该Future是否有返回数据 boolean isVoid(); DefaultPromise DefaultPromise实现了大多的Promise接口和Future接口的方法： 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic Promise&lt;V&gt; setSuccess(V result) { if (setSuccess0(result)) { // 设置任务执行成功，并将结果放入 notifyListeners(); // 通知监听者任务执行完成，做出相应动作 return this; } throw new IllegalStateException(&quot;complete already: &quot; + this);}@Overridepublic Promise&lt;V&gt; setFailure(Throwable cause) { if (setFailure0(cause)) { // 设置任务执行失败，并将原因放入 notifyListeners(); // 通知监听者任务完成，做出相应的动作 return this; } throw new IllegalStateException(&quot;complete already: &quot; + this, cause);}@Overridepublic boolean isSuccess() { Object result = this.result; // 执行结果 return result != null &amp;&amp; result != UNCANCELLABLE &amp;&amp; !(result instanceof CauseHolder);}@Overridepublic Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) { checkNotNull(listener, &quot;listener&quot;); synchronized (this) { addListener0(listener); // 添加监听者 } if (isDone()) { notifyListeners(); // 如果任务是完成了的，就通知所有的Listener } return this;} 让我们看一下通知监听者的细节： 1234567891011121314151617181920212223private void notifyListeners() { EventExecutor executor = executor(); // 获取executor()执行线程，在构造函数中传入 if (executor.inEventLoop()) { // 判断当前线程是否为executor final InternalThreadLocalMap threadLocals = InternalThreadLocalMap.get(); final int stackDepth = threadLocals.futureListenerStackDepth(); if (stackDepth &lt; MAX_LISTENER_STACK_DEPTH) { threadLocals.setFutureListenerStackDepth(stackDepth + 1); try { notifyListenersNow(); // 通知执行operationComplete } finally { threadLocals.setFutureListenerStackDepth(stackDepth); } return; } } safeExecute(executor, new Runnable() { @Override public void run() { notifyListenersNow(); } });} 首先，获取到该类中保存的executor，即执行任务的线程，该executor一定是eventLoop中的线程。跟着使用executor.inEventLoop()判断当前线程是否是excutor线程，是的的话直接执行通知监听者，不是的话则使用excutor线程执行通知监听者operationComplete方法。 ChannelFuture的使用在服务端我们使用ChannelFuture： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class HServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); set.remove(1); try { bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(&quot;http&quot;, new HttpServerCodec()); pipeline.addLast(&quot;httpA&quot;, new HttpObjectAggregator(5*1024*1024)); pipeline.addLast(&quot;myHandler&quot;, new SimpleChannelInboundHandler&lt;HttpObject&gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception { // 设置响应内容 ByteBuf content = Unpooled.copiedBuffer(&quot;hello，我是服务器&quot;, CharsetUtil.UTF_8); DefaultFullHttpResponse re = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content); re.headers().add(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain;charset=utf-8&quot;) .add(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes()); // 写出响应 ChannelFuture channelFuture = ctx.write(re); // 添加写出后的监听器，写出成功后，即invoke后执行 channelFuture.addListener((future)-&gt;{ if(future.isSuccess()) { System.out.println(&quot;成功&quot;); } else { System.out.println(&quot;失败&quot;); } }); } }); } }); ChannelFuture sync = bootstrap.bind(8888).sync(); sync.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } }} 如上程序实现服务端可以接受Http请求然后回复客户端，调用ctx.write(re)方法不会马上马上把消息写出给客户端，而是放在缓冲中，等到缓冲区满了或者调用invoke()方法后才会写出。在后面添加的监听器需要在invoke真正写出后才会执行。 注意： 如果把ctx.write(re)变成ctx.writeAndFlush(re)，那么执行完ctx.writeAndFlush(re)数据就已经被写出了，那么执行addListener会马上执行回调。","link":"/2020/09/08/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-ChannelFuture/"},{"title":"Netty核心组件-EventLoopGroup","text":"Netty高性能架构–线程模型：Netty之所以性能很高，除了依赖于Nio的特性外，还实现了一套高效的线程模型。 Netty线程模型传统线程模型​ 即阻塞IO模型，一个网络连接对应一个线程。 模型特点： 采用阻塞IO模式获取输入的数据 每个连接都需要独立的线程完成数据的输入，业务处理, 数据返回 模型缺点： 当并发过多，创建大量线程会造成资源的大量占用 连接建立后，很可能一直阻塞在等待读和写的状态 Reactor/Dispatcher模型特点： 基于IO复用模型 ​ 多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。 基于线程池复用线程资源 ​ 不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。 说明： Reactor 模式，通过一个或多个输入同时传递给服务处理器的模式(基于事件驱动) 服务器端程序处理传入的多个请求,并将它们同步分派到相应的处理线程， 因此Reactor模式也叫 Dispatcher模式 Reactor 模式使用IO复用监听事件, 收到事件后，分发给某个线程(进程), 这点就是网络服务器高并发处理关键 (1) 单Reactor单线程 ​ 只有单个线程，该线程里有一个Reactor来负责接收连接，接收到连接后统一还是用这个线程来进行处理 ​ 优点：简单，没有多线程，没有进程通信​ 缺点：性能，无法发挥多核的极致，一个handler卡死，导致当前进程无法使用，IO和CPU不匹配​ 场景：客户端有限，业务处理快，比如redis，因为redis的功能非常简单，就是从内存中获取一个键值对，没有文件IO等复杂操作，单次请求处理时间很短，避免了多线程上下文切换的消耗，性能比多线程更高。 ​ ​ 在我们之前的1.2.3的程序代码中，同样是基于该模型的，Selector负责接收请求，如果有事件发生就会通过这个线程来处理响应的请求。如果是ServerSocketChannel发生事件，调用accept()建立连接，如果是SocketChannel就进行响应的处理。 (2) 单Reactor多线程模型 说明： Reactor 对象通过select 监控客户端请求 事件, 收到事件后，通过dispatch进行分发 如果是请求建立连接，则通过Acceptor的accept方法建立连接，然后创建一个Handler对象来负责完成对应的客户端的后续请求处理 如果不是连接请求，则由reactor分发调用连接对应的handler 来处理 handler 只负责响应事件，不做具体的业务处理, 通过read 读取数据后，会分发给后面的worker线程池的某个线程处理业务 worker 线程池会分配独立线程完成真正的业务，并将结果返回给client 优点：可以充分的利用多核cpu 的处理能力缺点：多线程数据共享和访问比较复杂， reactor 处理所有的事件的监听和响应，在单线程运行， 在高并发场景容易出现性能瓶颈. (3) 主从Reactor多线程 说明： 一个(或多个)Reactor监听客户端的请求，当请求到来时，如果是建立连接的请求，则在本线程的Acceptor完成accept，再将连接分配给子线程Reactor 如果是其他请求，则转到子线程的Reactor中进行分发处理，子线程Reactor分发后再交由线程池处理业务。 Reactor子线程可以有多个，同样主线程Reactor也可以有多个 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。优点：父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。Netty主要使用的就是该模型缺点：编程复杂度较高 Netty线程模型Netty使用的就是主从Reactor多线程模型，在服务器端，定义了两个线程池BossGroup和Worker Group： BossGroup对应了Reactor主线程(可以有多个，但是一般都为1个)，每一个Reactor主线程都循环的进行1.select选择—》2.处理连接请求，建立连接并将连接注册到WorkerGroup中-》3.处理一些任务 Worker Group对应了Worker线程池，每一个线程也都是一个Selector来监听有哪些注册到自己上的客户端有读时间发生，同样循环进行1.select选择-》2.处理所有读写事件并执行对应业务-》3.执行一些其他任务 下面编写一个Netty通讯的程序来配合解释： 服务端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class NettyServer { public static void main(String[] args) throws InterruptedException { // 创建循环事件组，线程池，原理图中的BossGroup，用于监听用户的请求 // 若不指定线程数量，会默认设置为当前机器的逻辑处理器✖2 EventLoopGroup eventExecutors = new NioEventLoopGroup(1); // 创建工作线程组，原理图中的WorkerGroup // 若不指定线程数量，会默认设置为当前机器的逻辑处理器✖2 EventLoopGroup workExecutors = new NioEventLoopGroup(); try{ // 服务端配置 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(eventExecutors, workExecutors) // 将两个Group加入 .channel(NioServerSocketChannel.class) // 指定channel的类型，注意这不是java NIO下的，是Netty提供的 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列的连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ServerHandler()); // 每个注册进来的channel都添加一个处理器，可以添加多个 } }); // 设置子处理器，当接受到读请求是会执行处理器中的方法。当是客户端请求连接时不会走该处理器，而是注册到workExecutors中 // 绑定端口 ChannelFuture sync = bootstrap.bind(8888).sync(); // 将来在接收到关闭事件是关闭通道，closeFuture本身是异步调用，加上sync同步等待返回结果 sync.channel().closeFuture().sync(); } finally { // 关闭线程池 eventExecutors.shutdownGracefully(); workExecutors.shutdownGracefully(); } }}public class ServerHandler extends ChannelInboundHandlerAdapter { /** * 当有读取事件发生会触发该方法 * ChannelHandlerContext为一个上下文对象，内部包含了pipeline、channel等 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(&quot;客户端发送的消息为:&quot; + buf.toString(CharsetUtil.UTF_8)); System.out.println(&quot;客户端的地址为:&quot; + ctx.channel().remoteAddress()); } /** * 当读取完毕后会触发该方法 */ @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(&quot;接收到客户端请求&quot;); ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;客户端你好,(*^▽^*)&quot;, CharsetUtil.UTF_8)); }} 客户端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class NettyClient { public static void main(String[] args) throws InterruptedException { // 创建一个时间循环组 EventLoopGroup eventExecutors = new NioEventLoopGroup(); try { // 客户端创建BootStrap对象来初始化 Bootstrap bootstrap = new Bootstrap(); // 设置相关参数 bootstrap.group(eventExecutors) // 设置时间循环组 .channel(NioSocketChannel.class) // 设置客户端通道的种类 .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ClientHandler()); // 添加一个处理器 } }); ChannelFuture sync = bootstrap.connect(&quot;0.0.0.0&quot;, 8888).sync(); sync.channel().closeFuture(); } finally { // 关闭线程池 eventExecutors.shutdownGracefully(); } }}public class ClientHandler extends ChannelInboundHandlerAdapter { /** * 当通道触发就会触发该方法 */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(&quot;client: &quot; + ctx); ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;这是客户端，(*^▽^*)&quot;, CharsetUtil.UTF_8)); } /** * 当有读取事件发生会触发该方法 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //super.channelRead(ctx, msg); ByteBuf buf = (ByteBuf) msg; System.out.println(&quot;服务器回复:&quot; + buf.toString(CharsetUtil.UTF_8)); System.out.println(ctx.channel().remoteAddress()); }} Netty线程模型说明： 对于服务端，创建了两个线程组，bossGroup与workerGroup： bossGroup对应主从Reactor模型中的的mainReactor，用于接收客户端的连接，我们应该传入参数1，表示只建立一个线程。在Netty中，执行ServerBootsrap的bind方法会绑定端口得到一个SeverSocketChannel对象，之后会把该对象放置在bossGroup一个EventLoop（一般为一个线程）中，注册到该线程的Selector上来监听有没有连接事件，如果有连接请求，就得到SocketChannel注册到workerGroup上，后续的业务交给了workerGroup的线程，总体来说接收请求的过程很简单，单线程也能有较高的吞吐量，不需要采用多线程引入线程切换的开销，并且Selector操作也不是线程安全的。bossGroup可以初始化多个EventLoop（一般为一个线程），但是bind一个端口只会生成一个EventLoop，因此我们一般初始化为1个线程。网上对于bossGroup可以给多个线程的理由是如果我们需要绑定多个端口，就可以初始化多个线程比较合理。 workerGroup 对应 Reactor 模型的 subReactor ，用于进行 SocketChannel 的数据读写。对于 EventLoopGroup ，如果未传递方法参数 nThreads ，表示使用 CPU线程数*2 个 Reactor 。这个也符合我们上面提到的，通常，subReactor 的个数为CPU逻辑处理器个数*2，每个 subReactor 独占一个线程来处理。 在上图虚线框中，有一个用户自定义的业务线程池，虽然Netty提供了workerGroup线程池有多个线程同时工作，但是更多的情况下线程池中的每个线程都是用于多个Channel网络I/O的，而每个channel对应于一个客户端的连接，如果在channel中有读取数据库等I/O操作，会造成channel的阻塞，如果某一个客户端向服务端发送了多个请求，第一个请求没执行完就一直阻塞不会接收到第二个请求，因此在有长时间I/O操作的情况下，我们把这些业务交给一个自定义的线程池更好，执行完业务后，调用channel的write方法Netty会将业务线程切换到workerGroup线程进行网络I/O。 EventLoopGroup与EventLoop EventLoop为一个线程池，通常与一个Selector绑定，但是在Netty中都是将EventLoop作为单个线程，即NioEventLoop，NioEventLoop负责了该线程的各个注册在Selector上channel的请求处理，EventLoop还有其他的实现类，但是基本上都是SingleThreadEventLoop抽象类的子类，其余的几乎不怎么使用，在这里我们只分析NioEventLoop。 EventLoopGroup可以管理了多个EventLoop。 EventLoopGroupEventLoopGroup用于管理多个EventLoop，该接口有以下方法： 12345678910111213141516171819202122232425public interface EventLoopGroup extends EventExecutorGroup { /** * Return the next {@link EventLoop} to use */ @Override EventLoop next(); /** * Register a {@link Channel} with this {@link EventLoop}. The returned {@link ChannelFuture} * will get notified once the registration was complete. */ ChannelFuture register(Channel channel); /** * Register a {@link Channel} with this {@link EventLoop} using a {@link ChannelFuture}. The passed * {@link ChannelFuture} will get notified once the registration was complete and also will get returned. */ ChannelFuture register(ChannelPromise promise); /** * Register a {@link Channel} with this {@link EventLoop}. The passed {@link ChannelFuture} * will get notified once the registration was complete and also will get returned. * * @deprecated Use {@link #register(ChannelPromise)} instead. */ @Deprecated ChannelFuture register(Channel channel, ChannelPromise promise);} 主要就是next方法与register方法： next()：获取一个EventLoop，如果有多个EventLoop，可以定义获取的策略。 register(Channel)：将Channel注册在EventLoopGroup中，即绑定在一个Selector上。 EventLoopGroup的初始化从我们之前的分析，我们在创建NioEventLoopGroup时有：NioEventLoopGroup workerGroup = new NioEventLoopGroup(8)，我们传入的8为线程数量。我们向上找构造函数，AbstractEventExecutorGroup没有定义构造，MultithreadEventExecutorGroup定义了构造： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// class MultithreadEventExecutorGroup/** * Create a new instance. * * @param nThreads the number of threads that will be used by this instance.线程组的线程数 * @param executor the Executor to use, or {@code null} if the default should be used.可以自己传入一个线程池 * @param chooserFactory the {@link EventExecutorChooserFactory} to use. * @param args arguments which will passed to each {@link #newChild(Executor, Object...)} call */protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { if (nThreads &lt;= 0) { throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); } // 如果没有传入线程池，就默认创建一个线程池 if (executor == null) { executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); } // 与线程数量相同的EventLoop children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { // 创建EventLoop对象的数组，NioEventLoop children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { for (int j = 0; j &lt; i; j ++) { children[j].shutdownGracefully(); } for (int j = 0; j &lt; i; j ++) { EventExecutor e = children[j]; try { while (!e.isTerminated()) { e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); } } catch (InterruptedException interrupted) { // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; } } } } } // EventLoop的选择器 chooser = chooserFactory.newChooser(children); // 监听EventLoop关闭事件 final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() { @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception { if (terminatedChildren.incrementAndGet() == children.length) { terminationFuture.setSuccess(null); } } }; for (EventExecutor e: children) { e.terminationFuture().addListener(terminationListener); } Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet);} 由上面代码可以看出EventLoopGroup在初始化时： 1 - 用户可以自定义线程池，如果没有自定义线程池那就创建一个指定线程数的线程池 2 - 创建与指定线程数相同数量的EventExecutor（即EventLoop） 3 - 创建一个EventLoop的选择器，在需要提供EventLoop时选择EventLoopGroup中的一个EventLoop 4 - 添加每个EventLoop关闭事件的监听器 EventLoopGroup的初始化就这些，在这里面主要有EventLoop的初始化，我们放到后面再讲。 EventLoopGroup接口的方法我们再来看看EventLoopGroup接口定义的两类方法： 1234567891011// 该方法在MultithreadEventExecutorGroup中定义@Overridepublic EventExecutor next() { return chooser.next();} // 该方法在MultithreadEventLoopGroup中定义@Overridepublic ChannelFuture register(Channel channel) { return next().register(channel);} 可以看到register的逻辑为通过chooser选择器从EventLoopGroup中选出一个EventLoop来进行注册。下面为一个选择器的类 12345678910111213private static final class GenericEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[Math.abs(idx.getAndIncrement() % executors.length)]; // 直接用递增的id去对EventLoop的数量取余得到下标 }} 上述的选择器就是使用了一个轮询的复杂均衡策略。 后续将继续介绍EventLoop。","link":"/2020/09/09/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-EventLoopGroup/"},{"title":"缓存与分布式锁","text":"在项目中，为加快某个接口的访问速度，增大吞吐量，如果我们检查出该接口访问速度慢是因为数据库操作比较耗时的情况下，一个重要的方式就是将数据放入缓存，缓存是基于内存的，操作的速度远快于Mysql等关系型数据库。 哪些数据适合放入缓存中： 对及时性、数据一致性要求不高的数据 访问量大但是更新频率不高的数据 例如在电商系统中，商品的分类信息、商品列表等获取都是非常耗时的，但是这些数据都是不常更新的数据，适合加入缓存。 下面给出了一个查询商品分类的接口： controller层： 12345@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); // 查询三级分类 return R.ok().put(&quot;data&quot;, entities);} service层： 1234567891011121314151617181920212223242526@Overridepublic List&lt;CategoryEntity&gt; listWithTree() { List&lt;CategoryEntity&gt; list = baseMapper.selectList(null); // baseMapper为父类注入的，一次性查出所有的分类数据 List&lt;CategoryEntity&gt; roots = list.stream().filter(m -&gt; m.getParentCid().equals(0L)).collect(Collectors.toList()); // 查询所有的一级分类 roots.stream().forEach( (m)-&gt;m.setChildren(list.stream().filter(s-&gt;s.getParentCid().equals(m.getCatId())) .sorted((m1, m2)-&gt; (m1.getSort()==null? 0:m1.getSort()) - (m2.getSort()==null? 0:m2.getSort())) .map((s)-&gt; { setChildren(list, s); return s; }) .collect(Collectors.toList()))); // 采用深度优先遍历构建分类树 return roots;}private void setChildren(List&lt;CategoryEntity&gt; nodes, CategoryEntity node) { node.setChildren(nodes.stream().filter(m-&gt;m.getParentCid().equals(node.getCatId())) .sorted((m1, m2)-&gt; (m1.getSort()==null? 0:m1.getSort()) - (m2.getSort()==null? 0:m2.getSort())) .map((s)-&gt; { setChildren(nodes, s); return s; }) .collect(Collectors.toList()));} Service层构建分类树是比较耗时的，而且对于商品的分类，一般来说是修改比较少的，这些数据适合放入缓存中来加快访问速度。 使用缓存读取数据 在查询数据时，我们首先去缓存中查找数据，如果需要查询的数据存在，就可以直接查处数据了，如果不存在(第一次查询或缓存过期)，那么我们就去数据库中查询该数据然后将结果放入缓存中，这样第二次来查该数据时缓存中就会存在该数据了。 本地缓存在单机应用下，我们可以采用本地缓存的方式来在内存中存储数据，例如我们可以自定义HashMap来实现缓存的功能，也能够通过Mybatis开启二级缓存功能来对数据进行缓存，但不推荐使用Mybatis的二级缓存，Mybatis的缓存有效范围是基于namespace的，可以自己定义namespace，当在一个namespace下执行查询操作就直接从namespace的缓存中查找，如果在一个namespace下执行了增删改的操作就会清除缓存，因此开销比较大，而且如果一个操作涉及了多个namespace就不安全，不如直接使用HashMap来的高效灵活，只是要注意缓存的更新。 但是在集群或分布式环境下，本地缓存就不再适用，因为本地缓存是每台机器所独自拥有的。如果两台机器(进程)都有对应的本地缓存，但是一台机器把数据库的数据修改了，那么只会更新本台机器的本地缓存，另外一台机器还在使用旧的缓存，这样数据一致性太差。 我们可以看到，如果有三台商品服务的集群，每个商品服务都缓存了当前商品分类的数据。现在对商品的分类进行了修改，修改请求被负载均衡到了商品服务的1号机器，由1号机器向数据库发出修改的请求，然后再把修改后的结果放入1号机器的缓存中，但是并不能修改2号与3号机器的缓存。 当新的查询请求过来，被负载均衡到2号和3号机器，那么会直接查询到缓存中的旧数据然后返回。以后只有负载均衡到1号机器上或者等到缓存过期才能查出最新数据，在缓存过期前被负载均衡到到2号和3号机器上的请求都只能查到旧的数据。 分布式缓存为了解决本地缓存存在的数据一致性问题，我们应该集中管理缓存，将所有的缓存都放入到缓存中间件中，每个业务服务器查询缓存都到缓存中间件的服务器中进行查询，这样一来，某个业务服务器修改了缓存，其他的所有业务服务器都能够获取到最新的数据。 可以作为缓存中间件的开源产品有很多，目前最为常用的就是Redis，下面我们采用redis作为缓存中间件来进行分布式缓存。 使用Redis改造查询分类树在controller层中： 123456789101112131415161718192021@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { // 缓存中不存在 List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); // 将数据放入缓存中，过期时间为2天 return R.ok().put(&quot;data&quot;, entities); } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities);} 采用spring提供的RedisTemplate对redis缓存进行操作，我们完成了采用redis作为缓存中间件来解决本地缓存存在的问题，但是分布式缓存不仅仅这么简单，上面的代码虽然解决了数据一致性的问题，系统吞吐量也挺高，但其中隐藏了缓存击穿、缓存穿透与缓存雪崩等问题。 缓存穿透、击穿与雪崩缓存穿透 缓存穿透是指查询一个不存在的数据，如果缓存和数据库中都不存在某个数据，如果我们从数据库中查出了null值，但是我们不将null放入缓存中，这将导致每次请求都会去查询数据库中不存在的那个数据，如果并发量太大，将会压垮数据库，造成缓存穿透。因此，我们需要将null存入缓存中。 缓存击穿 缓存击穿是指某个缓存数据过期了，但是此时的访问并发量非常大，这时候会并发查询数据库，这样一来会压垮数据库，造成缓存击穿。解决缓存击穿的方案就是采用分布式锁，如果多个线程同时查询数据库，只放行一个请求去查询数据库，查询后放入缓存，其他的线程就能够从缓存中查询了，类似于单例模式。 缓存雪崩 缓存击穿是指缓存中间件中缓存了非常多的数据，由于每个缓存数据都设置了过期时间，这些数据都同时过期，这时需要高并发的去查询数据库，同样也会压垮数据库。解决缓存雪崩的一个方法就是将数据的过期时间设置为在原来的基础上加上随机数，这样可以降低同时过期的概率，但是不能完全解决缓存雪崩的问题。 缓存穿透的问题很好解决，下面我们来讨论一下分布式锁解决缓存击穿问题。 分布式锁Java中的Synchronized或ReentrantLock等JUC并发包都是本地锁，其作用范围是单个Java进程，也就是说，JDK提供的锁只能锁住当前的Java进程，防止单个进程中对共享资源进行同时操作而产生的安全问题。这种方式对于解决缓存击穿的问题也是足够的，因为这些本地锁保证了一个进程只向服务器发送一个查询对应表的请求，请求数量较少，不会压垮数据库。 但是更好的方式是采用分布式锁，分布式锁可以保证所有线程只有一个线程能够操作缓存和数据库(这里只是指某一个请求，不影响其他请求)。分布式锁目前主流可以使用Redis或zookeeper实现，两者实现分布式锁的原理有所区别，Redis的性能更高，而zookeeper的可靠性更高，我们这里还是采用redis来实现分布式锁。 redis实现分布式锁redis实现分布式锁的原理并不复杂，只需要利用一个setnx的命令即可，在redis中setnx命令作用是向redis中存入一个key-value，如果这个key不存在，那么就可以设置成功返回true，如果这个key存在了，那么就不能设置失败返回false。 因此利用redis实现分布式锁的思路是：在分布式环境下访问共享资源时，各个线程利用setnx命令向redis中存入同一个key(value不太重要)，如果能够设置成功，说明获取到了分布式锁，一个线程设置成功后，其他线程必定会设置失败返回false(因为redis操作内存数据是单线程的)，返回false的线程需要等到获取到锁的线程释放锁之后才能获得锁。 业务改造： 1234567891011121314151617181920212223242526272829303132333435@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { while (!opsForValue.setIfAbsent(&quot;category-lock&quot;, &quot;true&quot;)) { // 上锁 Thread.sleep(200); } try { // 再查询一次 category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); return R.ok().put(&quot;data&quot;, entities); } } finally { // 已经有了缓存，释放锁 if(opsForValue.get(&quot;category-lock&quot;) != null) { // 此方法不安全，判断和删锁不是原子操作 redisTemplate.delete(&quot;category-lock&quot;); } } } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities));} 上述代码初步实现了一个分布式锁，与单例模式类似，采用double-check的方式来进行数据库的查询以及缓存数据的添加，在完成业务后释放锁让其他线程能够获取到锁继续执行代码。未获取到所的线程简单采用短暂睡眠+自旋的方式进行重复尝试。 这份代码并不完善，还需要进一步改进来提高锁的可靠性。 redis分布式锁的改进(1) 宕机后锁无法释放 上述分布式锁的代码存在很多不可靠的因素，这些因素多是由于机器故障造成的，试想一下，某个线程在向redis中设置了key获取到了分布式锁后，还没有释放锁结果机器宕机了，那么将会造成这把分布式锁永远无法释放，没有线程可以访问到缓存的这个数据，进而没有线程能够跳出自旋去查询数据。这种情况虽然发生的概率不是很高，但是一旦发生是致命的。 一个改进的方法就是给锁加上过期时间，如果一台机器宕机了，那么这个锁过了时间就会自动的失效，并且，我们需要将设置key与设置过期时间作为原子操作，如果不是原子操作，那么机器在设置了key之后就宕机了，没有设置过期时间，那么也会存在锁无法释放的问题。redis想要实现两个命令的原子操作只需要传送lua脚本即可，在RedisTemplate中封装了setnx与expire的原子操作，直接使用即可。 (2) 业务执行时间过长 虽然我们设置了锁的过期时间能够解决锁无法释放的问题，但引入了一个新的问题，那就是业务执行过长会导致本来还不应该释放锁但是锁已经自动失效了，一旦业务还未完成就释放锁，其他线程就能够进进行加锁，当最开始的线程执行完毕释放锁时，释放的就是其他线程所加的锁，这样一来就非常的混乱。解决这一问题的方法就是给每个线程的锁设置一个唯一的uuid作为value存在redis中，在释放锁的时候判断是否是自己加的锁，是自己加的才释放。 uuid的方法只是解决了不释放别人的锁，仍然没有解决的业务执行时间过长而锁提前失效的问题，我们可以简单的把锁失效的时间变长，因为一般不会允许某个业务执行时间太长，但是更安全的做法是自动给锁续期，我们需要新开一个守护线程来检测业务是否还在进行，如果还在，自动给锁进行续期。 下面的代码没有给锁进行自动续期，采用锁过期时间设置稍长的方式： 1234567891011121314151617181920212223242526272829303132333435363738@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { String uuid = UUID.randomUUID().toString(); while (!opsForValue.setIfAbsent(&quot;category-lock&quot;, uuid, Duration.ofSeconds(15))) { // 上锁 Thread.sleep(200); } try { // 再查询一次 category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); return R.ok().put(&quot;data&quot;, entities); } } finally { // 已经有了缓存，释放锁 /*if(uuid.equals(opsForValue.get(&quot;category-lock&quot;))) { // 此方法不安全，判断和删锁不是原子操作 redisTemplate.delete(&quot;category-lock&quot;); }*/ // 采用lua脚本保证原子性 String script = &quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end&quot;; redisTemplate.execute(new DefaultRedisScript&lt;&gt;(script, Long.class), Arrays.asList(&quot;category-lock&quot;), uuid); } } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities).put(&quot;port&quot;, environment.getProperty(&quot;local.server.port&quot;));} 采用redisson封装的分布式锁redisson是利用java编写的一个基于redis的开源的分布式锁框架，redisson利用AQS对分布式锁进行了高度的封装，使得我们在用分布式锁时就像在使用jdk的JUC包一样，redisson提供RedissonLock来实现分布式锁，它的使用与ReentrantLock类似： 12345678910111213141516171819202122232425262728293031@RequestMapping(&quot;/list/tree/redisson&quot;)public R listRedisson() { &lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { RLock lock = redisson.getLock(&quot;category-lock&quot;); // 获得锁对象，需要传入锁的名称，根据名称来判断是不是同一把锁 lock.lock(); try { // 再查询一次 category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); return R.ok().put(&quot;data&quot;, entities); } } finally { lock.unlock(); } } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities);} Reddison实现的分布式锁与之前讲的原理类似，它底层会自动给锁进行续期。","link":"/2020/07/01/huan-cun-yu-fen-bu-shi-suo/"},{"title":"类加载器","text":"类加载器是 Java 语言的动态性的重要组件，也是 Java 语言流行的重要原因之一。它使得 Java 类可以被动态加载到 Java 虚拟机中并执行。 1 作用 类加载器在JVM启动时进行加载，负责从文件或网络中加载.class文件。 类加载器只负责符合规范的class文件，至于该文件是否能够运行，由执行引擎来决定。 类的信息加载后，类的元数据(包含常量池、属性表、方法表、类变量等)存放于内存空间中的方法区，生成的Class对象实例存储在堆区，除了类的信息外，方法区还会保存一些。 2 过程类加载过程：加载-验证-准备-解析-初始化 加载阶段： 通过类的全限定类名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为运行时数据结构(class的元数据，包含常量池、属性表、方法表、类变量等)存储在方法区。 在内存中生成一个java.lang.Class对象，作为方法区这个类的各种数据访问的入口，**Class对象存在于堆区，其中的很多属性存在于方法区**。 验证阶段： 确保字节码文件符号虚拟机的规范要求，保证类正确被加载，不危害虚拟机的安全。 四种验证方式：文件格式验证(例如文件开头都是CA FE BA BE)，元数据验证，字节码验证，符号引用验证。 准备阶段： 为类变量(即static修饰的变量)分配内存并为变量设置默认初始值，对象为null，数值基本类型为0。 这里分配内存不包括final修饰的变量，常量在编译时期就已经分配了。 这里不会为类实例变量(即类成员，不同static修饰)分配内存初始化，类变量(static)会分配在方法区，而实例变量(无static)会随着对象一起分配到堆中。 注意： 1private static int a = 1; 即使是如上的代码，在准备阶段a只会赋值为0，只有到后面的类初始化阶段才会被赋值为1。 解析阶段： 将常量池内的符号引用转换为直接引用的过程，即将符号转化为实际对象的地址。 事实上，解析操作往往会伴随着JVM在执行完初始化之后再执行。 符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java 虚拟机规范》的Class文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的CONSTANT Class info、 CONSTANT Fieldref info、CONSTANT Methodref info等 。 初始化阶段： 初始化阶段是调用类构造器方法&lt;clinit&gt;()的过程，注意必须要有static变量或者static代码才会有该方法，用于初始化类的静态变量。 static{}代码块就是&lt;clinit&gt;()的一部分，该类构造器方法&lt;clinit&gt;()不是类的构造方法(函数)，此方法不需要人为定义。 注意：类被加载不一定会初始化 3 类加载器分类JVM的类加载器主要分为引导类加载器和自定义类加载器，一般不同的类加载器负责不同的类加载的路径。 引导类加载器为Bootstrap Class Loader，该类是由c/c++语言编写的，用于启动。而其他的都属于自定义类加载器，包括Extension Class Loarder、System Class Loarder以及用户自定义的一些类加载器，注意，自定义类加载器都继承于抽象类Classloader，而各个类加载器之间没有继承关系。即System Class Loarder不是Extension Class Loarder子类，下图仅仅表示某种类加载器是由哪个类加载器加载的。 用户自定义的类是由系统类加载器(AppClassLoader)加载的，而java的核心类库是由引导类加载器加载的。 上图不反应继承关系，下图是ClassLoader类的继承关系。 Bootstrap类加载器 （1）这个类加载使用C/C+ +语言实现的，嵌套在JVM内部。 （2）它用来加载Java的核心库(JAVA_ HOME/jre/ lib/rt.jar、resources. jar或sun . boot.class .path路径下的内容) ,用于提供JVM自身需要的类。 （3）并不继承自java. lang. ClassLoader，没有父加载器。加载扩展类和应用程序类加载器，并指定为他们的父类加载器。 （4）出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类 Extension类加载器 （1）Java语言编写，由sun . misc. Launcher$ExtClassLoader实现。 （2）派生于ClassLoader类 （3）父类加载器为启动类加载器 （4）从java. ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/lib/ext子目录(扩展目录)下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。 应用程序类加载器(系统类加载器，AppClassLoader类) （1）java语言编写，由sun . misc. Launcher$AppClassLoader实现 （2）派生于ClassLoader类 （3）父加载器为扩展类加载器（不是父类的意思） （4）它负责加载环境变量classpath或系统属性java.class.path 指定路径“下的类库该类加载是程序中默认的类加载器，一般来说，Java应用的类(我们写在classpath下的类)都是由它来完成加载 （5）通过ClassLoader# getSystemClassLoader ()方法可以获取到该类加载器 用户自定义的加载类 继承ClassLoader抽象类，重写findClass方法。可能种种原因，例如由于我们需要加载的类不在classpath下、也不在Bootstrap和Extension类加载器所加载的路径下，我们需要自定义类加载器来加载类。 4 类被加载的条件类加载的条件： 当类被主动使用时，类会被加载进内存，主动使用包括： ​ （1）创建类的实例 ​ （2）访问某个类或接口的静态变量，或者对该静态变量赋值 ​ （3）调用类的静态方法 ​ （4）反射(比如: Class. forName (“com. atguigu. Test”) ) ​ （5）初始化一一个类的子类 ​ （6）Java虚拟机启动时被标明为启动类的类 ​ （7）JDK 7开始提供的动态语言支持:java. lang. invoke . MethodHandle实例的解析结果REF_ getStatic、REF_ putStatic、REF_ invokeStatic句柄 对应的类没有初始化，则初始化 除了以上的主动使用，其余都为被动使用，被动使用不会引起类的加载初始化。 类加载的时机： 不管使用什么样的类加载器，类都是在第一次被用到时，动态加载到JVM的。这句话有两层含义： Java程序在运行时并不一定被完整加载，只有当发现该类还没有加载时，才去本地或远程查找类的.class文件并验证和加载（赖加载）； 当程序创建了第一个对类的静态成员的引用（如类的静态变量、静态方法、构造方法——构造方法也是静态的）时，才会加载该类。Java的这个特性叫做：动态加载。 例如： 12345678910111213141516public class ClD { public static void main(String[] args) throws ClassNotFoundException { System.out.println(&quot;asd&quot;); A a = new A(); // 执行这句话时，首先判断类A是否加载，未加载则先加载 A a2 = new A(); // 类A已经加载过了，无需再加载 }}public class A { static { System.out.println(&quot;A&quot;); }} 5 类加载的规则：双亲委派机制（1）如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行; （2）如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达项层的启动类加载器; （3）如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。 这一逻辑我们可以在ClassLoader中的源码中看到： ClassLoader类中的loadClass是类加载的核心代码 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException{ synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded // 该类是否被加载过，加载过了直接返回 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { // 判断是否有父加载器 c = parent.loadClass(name, false); // 委托父加载器加载 } else { c = findBootstrapClassOrNull(name); // 无父加载器，代表父加载器为Bootstrap加载器，委托Bootstrap加载器加载 } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // 父加载器不能加载该类，由自己加载 // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; }} 例如，我们在自己项目中自定义了一个java.lang.String，当我们new String对象时，我们创建的是java原生API的String类型还是自定义的String类型呢？根据双亲委派模型，此时加载的还是java原生API而并没有加载自定义的java.lang.String(注意包名也相同)，其原因是原生API的java.lang.String是被引导类加载器加载的，而用户自己定义的类是由系统类加载器加载的，所以java.lang.String在父加载器中已经加载了，子加载器无需再进行加载。 双亲委派机制的优势： 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。 其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。 6 自定义类加载器在ClassLoader类文件注释中给了一个最简单的自定义类加载器的示例，按照示例，只需要获取class文件的byte[]数组然后通过ClassLoader中的defineClass方法即可获取Class对象，重写findClass方法即可，ClassLoader中已经实现了双亲委派机制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class TomcodeClassLoader extends ClassLoader { // 验证 public static void main(String[] args) throws ClassNotFoundException { TomcodeClassLoader classLoader = new TomcodeClassLoader(); Class&lt;?&gt; aClass = classLoader.loadClass(&quot;classloader.A&quot;); System.out.println(aClass.getClassLoader()); } private static final String PRE_FIX = &quot;/Volumes/data/&quot;; // 要加载的类所在的目录 public TomcodeClassLoader() { super(); } @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { try { byte[] b = loadClassData(name); return defineClass(name, b, 0, b.length); } catch (IOException e) { e.printStackTrace(); return null; } } private byte[] loadClassData(String name) throws IOException { String[] split = name.split(&quot;\\\\.&quot;); StringBuilder sb = new StringBuilder(PRE_FIX); for(int i = 0; i &lt; split.length-1; i++) { sb.append(split[i]); sb.append('/'); } String fullpath = sb.append(split[split.length - 1] + &quot;.class&quot;).toString(); FileInputStream is = null; ByteArrayOutputStream bo = null; try { is = new FileInputStream(fullpath); byte[] b = new byte[1024]; bo = new ByteArrayOutputStream(); int len = -1; while ((len = is.read(b)) != -1) { bo.write(b, 0, len); } return bo.toByteArray(); } finally { if(is != null) { is.close(); } if(bo != null) { bo.close(); } } }} 首先，我们将类A的文件放在当前类路径，在指定的/Volumes/data/下放入classloader/A.class，由于双亲委派机制，类A会由AppClassLoader加载 1sun.misc.Launcher$AppClassLoader@18b4aac2 当我们删除当前类路径下的类A文件，则类A由自定义的TomcodeClassLoader加载 1classloader.TomcodeClassLoader@1d44bcfa 7 类加载器的命名空间 每个类加载器都有自己的命名空间，类加载器的命名空间是由自身以及所有父加载器所加载出来的全类名组成。 由于双亲委派机制，父子加载器之间不会出现相同的全类名，但是同等级的类加载器之间可以出现相同的全类名，并且互相是感受不到的，也就是说Class对象不同。 子加载器加载的类可以感知到父加载器所加载的类，反之则不行。例如自定义一个类，我们是不能在String类中使用的，因为String类是由Bootstrap加载器加载的，而自定义类是AppClassLoader加载的。我们可以在自定义类中使用String类。 1234567891011121314151617181920212223242526272829303132public class ClD { public static void main(String[] args) throws Exception { TomcodeClassLoader classLoader = new TomcodeClassLoader(); Class&lt;?&gt; aClass = classLoader.loadClass(&quot;classloader.B&quot;); TomcodeClassLoader classLoader2 = new TomcodeClassLoader(); Class&lt;?&gt; bClass1 = classLoader2.loadClass(&quot;classloader.B&quot;); System.out.println(aClass.getClassLoader()); System.out.println(bClass1.getClassLoader()); System.out.println(aClass == bClass1); Object o = aClass.newInstance(); Object o1 = bClass1.newInstance(); bClass1.getMethod(&quot;setB&quot;, Object.class).invoke(o1, o); }}public class B { private B b; public B() { } public void setB(Object b) { this.b = (B) b; }} 输出： 123456789101112classloader.TomcodeClassLoader@1d44bcfaclassloader.TomcodeClassLoader@6f94fa3efalseException in thread &quot;main&quot; java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at classloader.ClD.main(ClD.java:23)Caused by: java.lang.ClassCastException: classloader.B cannot be cast to classloader.B at classloader.B.setB(B.java:11) ... 5 more 首先，两个Class对象都是由TomcodeClassLoader进行加载的，但是不是同一个ClassLoader对象，两个TomcodeClassLoader是同等级的，因此两个加载出来的Class对象是不同的 其次，两个Class对象是无法互相感知到，从结果可以看出，两个不同Class对象创建的实例不能进行强转 8 打破双亲委派机制打破双亲委派机制的一个重要场景就是数据库连接驱动，数据库连接驱动采用的SPI机制来加载数据库驱动。SPI简单来说使用过配置文件的方式来动态加载接口的实现类，拿到配置文件中的实现类，通过反射加载类，具体暂不展开阐述，SPI就可以用来打破双亲委派机制。首先我们来看看获取数据库连接的代码： 1234public static void main(String[] args) throws ClassNotFoundException, SQLException { Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;); Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/newmall&quot;);} 代码非常简单，但是一句Class.forName(“com.mysql.cj.jdbc.Driver”);就打破了双亲委派机制，加载了Mysql驱动。 Class.forName(“com.mysql.cj.jdbc.Driver”)加载Mysql驱动，则将执行该类的静态代码块： 1234567static { try { java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can't register driver!&quot;); }} 该静态代码块使用了DriverManager，则加载该类，注意DriverManager是java.sql下的，由Bootsrap加载器所加载，DriverManager中的静态代码块执行，在静态代码块中加载了Mysql的驱动。 注意，此时DriverManager是由Bootsrap加载器加载，这意味着，DriverManager中只能使用由Bootsrap加载器加载的类，而我们知道，数据库驱动属于第三方提供的，肯定不是由Bootsrap加载器加载，因此此时需要打破双亲委派机制，采用的就是SPI机制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);} private static void loadInitialDrivers() { String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // SPI加载驱动类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } } } 我们可以看到在loadInitialDrivers方法中使用SPI加载META-INF/services中配置文件中配置的Driver接口的实现类，我们看ServiceLoader.load方法： 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { ClassLoader cl = Thread.currentThread().getContextClassLoader(); // 获取当前线程的ClassLoader return ServiceLoader.load(service, cl);} 这里是打破双亲委派机制的关键，我们从当前线程中获取到了ClassLoader对象，这个ClassLoader对象不是加载加载DriverManager的Bootstrap ClassLoader，而是AppClassLoader，我们使用AppClassLoader便可以加载第三方提供的驱动jar包。 而Java提供了Class.forName(String name, boolean initialize, ClassLoader loader)方法，可以指定加载该类的类加载器，便可以在DriverManager内加载第三方Mysql驱动了，打破了双亲委派机制。","link":"/2020/07/24/lei-jia-zai-qi/"}],"tags":[{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"JAVA","slug":"JAVA","link":"/tags/JAVA/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"redis","slug":"redis","link":"/tags/redis/"}],"categories":[{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"JAVA","slug":"JAVA","link":"/categories/JAVA/"},{"name":"Redis","slug":"Redis","link":"/categories/Redis/"},{"name":"SSM","slug":"SSM","link":"/categories/SSM/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"}]}