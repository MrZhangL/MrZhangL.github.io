{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Java并发-ThreadLocal","text":"ThreadLocal在Java中应用非常之多，ThreadLocal用于保存与线程绑定的对象，即一个对象通过ThreadLocal与线程进行绑定后，我们在任意的方法中，都能获取到线程所绑定的对象。 一个ThreadLocal的用例当我们需要添加转账业务时，将会在Service加入如下代码： 12345678910111213141516171819202122232425262728public boolean transferMoney(Account source, Account target, float money) { Connection connection = null; try { connection = dataSource.getConnection(); // 从连接池里获取一个连接 connection.setAutoCommit(false); //关闭自动提交，开启事务 // 查找用户 Account s1 = accountDao.findById(source.id); Account t1 = accountDao.findById(target.id); // 更新用户 s1.setMoney(s1.getMoney() - money); t1.setMoney(t1.getMoney() + money); // 提交更新 accountDao.updataAccount(s1); // int i = 3/0; accountDao.updataAccount(t1); // 提交事务 connection.commit(); } catch (Exception e) { try { connection.rollback(); } catch (SQLException e) { e.printStackTrace(); } } finally { if(connection != null) connection.closeConnection(); } return true;} Dao层代码： 123456@Overridepublic void updataAccount(Account account) throws SQLException { queryRunner.update(&quot;update `account` set `name` = ?, money = ? where id = ?&quot;, account.getName(), account.getMoney(), account.getId()); // 没有传入connection，会自己从dataSource里取一个连接，执行完自动归还} 转账操作将由多个dao层方法完成，如果中间在执行了几条后出现异常，则后面的将不再执行，因此需要进行事务控制，而面对之前设计的代码，我们都是通过QureyRunner从连接池中任意取一条来执行方法，因此面临的问题是执行第10行和第12行时取的是不同的连接，不同的连接没办法做到事务控制，因此我们需要做出改进。 通过以上代码执行可能是以下情况(同时发送多笔转账操作)： (1) 线程1从连接池中取出连接1访问数据库后执行了accountDao.updataAccount(s1)操作并归还连接，图示中执行1-2-3 (2) 此时跳转到线程2也执行了转账或其他操作(以转账为例)，从连接池中取出来连接1，图示中执行4 (3) 此时又跳回到线程1，执行accountDao.updataAccount(t1)，从连接池中取出了3，两次连接不同，无法进行事务控制 (4) 在Sevice层取出用于事务控制的连接于Dao层的连接也不同，提交或回滚事务对于两个update操作没有任何影响。 解决办法 首先，在这里我们可以通过传参的方式，将开启事务的connection传入到对应的dao层操作中，使用传入的connection对象即可保证进行事务控制、更新两个用户的操作都是属于同一个数据库连接，这样就可以完成事务的控制。但是传参的方式不太好，对业务的侵入比较大，提高的代码的耦合程度。 在这里，还有另一种解决方案，我们可以利用ThreadLocal来解决这一问题，Java的ThreadLocal可以让线程绑定一个对象，当我们需要这个变量时，我们可以在任何地方取出当前线程对应的变量。 ThreadLocal类： 将对象与线程对应，key-value的形式 每个线程Thread对象中都有一个ThreadLocal的内部类ThreadLocalMap的对象，里面储存了该线程所对应的对象 通过ThreadLocal类对象调用set与get方法都是对当前线程对应的对象进行操作 下面使用ThreadLocal来定义从数据库连接池中获取连接的工具类ConnectionUtils： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Component(value = &quot;connectionUtils&quot;) // 注入到Spring容器当中public class ConnectionUtils { private ThreadLocal&lt;Connection&gt; connectionThreadLocal = new ThreadLocal&lt;Connection&gt;(); @Resource(name = &quot;dataSource&quot;) private DataSource dataSource; public void setConnectionThreadLocal(ThreadLocal&lt;Connection&gt; connectionThreadLocal) { this.connectionThreadLocal = connectionThreadLocal; } public void setDataSource(DataSource dataSource){ this.dataSource = dataSource; } // 获取一个数据库连接： // 1. 如果当前线程未获取过连接或者已经归还，则从连接池中获取一个连接 // 2. 如果当前线程获取过连接且未归还，则直接返回该连接 public Connection getLocalConnection(){ Connection connection = connectionThreadLocal.get(); try { if (connection == null || connection.isClosed()) { connection = dataSource.getConnection(); connectionThreadLocal.set(connection); } } catch (SQLException e){ e.printStackTrace(); } return connection; } //归还连接并且解绑 public void CloseConnection(){ Connection connection = connectionThreadLocal.get(); try { if (connection != null) { connectionThreadLocal.remove(); connection.close(); } } catch (SQLException e) { e.printStackTrace(); } }} 我们再对事务进行封装： 123456789101112131415161718192021222324252627282930313233343536//事务管理工具类@Component(&quot;transactionUtils&quot;)public class TransactionUtils { @Resource(name = &quot;connectionUtils&quot;) ConnectionUtils connectionUtils; // 开启事务 public void start(){ try { connectionUtils.getLocalConnection().setAutoCommit(false); //关闭自动提交，开启事务 } catch (SQLException e) { e.printStackTrace(); } } // 提交事务 public void commit(){ try { connectionUtils.getLocalConnection().commit(); } catch (SQLException e) { e.printStackTrace(); } } // 回滚事务 public void rollback(){ try { connectionUtils.getLocalConnection().rollback(); } catch (SQLException e) { e.printStackTrace(); } } // 归还连接 public void close(){ connectionUtils.CloseConnection(); }} 则我们可以将转账操作的service层与dao层改进为： service层： 12345678910111213141516171819202122232425public boolean transferMoney(Account source, Account target, float money) { try { //1.开启事务 tsManager.start(); //2.执行操作 //2.1 查找用户 Account s1 = accountDao.findById(source.id); Account t1 = accountDao.findById(target.id); //2.2 更新用户 s1.setMoney(s1.getMoney() - money); t1.setMoney(t1.getMoney() + money); //2.3 提交更新 accountDao.updataAccount(s1); //int i = 3/0; accountDao.updataAccount(t1); //3.提交事务 tsManager.commit(); } catch (Exception e) { tsManager.rollback(); throw new RuntimeException(e); } finally { tsManager.close(); } return true;} dao层： 123456@Overridepublic void updataAccount(Account account) throws SQLException { queryRunner.update(connectionUtils.getLocalConnection(),&quot;update `account` set `name` = ?, money = ? where id = ?&quot;, account.getName(), account.getMoney(), account.getId()); // 传入了指定的connection，使用该connection执行sql，操作完不会自动归还连接} 这样改造以后，当我们执行一次transferMoney，每次使用的数据库连接都是在tsManager.start()中从数据库连接池中取出来的连接，直到事务提交或回滚，然后调用tsManager.close()向连接池归还连接。 ThreadLocal的核心原理ThreadLocal是依托于每个Thread对象中都有一个ThreadMap类对象，即为一个哈希表的对象，该哈希表的key为ThreadLocal对象，Value为我们要存储的与线程绑定的对象。我们每次调用ThreadLocal的get()/set()/remove()等方法时都是先通过当前线程找到ThreadLocalMap对象，然后通过ThreadLocal对象作为key找到对应的key-value对。 我们来看一下get()方法： 12345678910111213public T get() { Thread t = Thread.currentThread(); // 获取当前的线程 ThreadLocalMap map = getMap(t); // 获取对应线程的ThreadLocalMap if (map != null) { // ThreadLocalMap是懒加载的 ThreadLocalMap.Entry e = map.getEntry(this); // 获取对应的Entry if (e != null) { @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; // 返回绑定的对象 } } return setInitialValue(); // 没有设置过值，则初始化key-value，value为null} ThreadLocalMap并不是一个Map对象，与JDK中的HashMap不同： 由于ThreadLocalMap中的key都为ThreadLocal对象，因此JDK中对ThreadLocal对象中都保存了一个threadLocalHashCode的int变量，该变量就是用于在哈希表中查找的哈希值。 threadLocalHashCode是在new这个ThreadLocal对象时生成的，ThreadLocal中有一个静态成员变量AtomicInteger nextHashCode，每次生成一个ThreadLocal对象，都会为其配置nextHashCode作为hash值，然后再自增1。这样每个ThreadLocal对象都有不同的hash值。 ThreadLocalMap采用的是开放地址的方法来解决hash冲突，而JDK的HashMap采用的是链地址的方法来解决hash冲突 下面是ThreadLocalMap中查找key-value对的方法： 123456789private Entry getEntry(ThreadLocal&lt;?&gt; key) { int i = key.threadLocalHashCode &amp; (table.length - 1); // 通过hash值对槽的长度取模 Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) // 对应slot槽上存在entry，且存储的entry对应的ThreadLocal与当前传入的ThreadLocal是同一个对象则代表找到了 return e; else return getEntryAfterMiss(key, i, e); // hash后对应的位置上没有找到对应的entry} getEntryAfterMiss是开放地址法继续从后续slot中查找元素。 12345678910111213141516private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) { Entry[] tab = table; int len = tab.length; while (e != null) { // 从i开始向后搜索slot，直到为null或者找到了对应的key ThreadLocal&lt;?&gt; k = e.get(); // 获取entry对应的key，即ThreadLocal对象 if (k == key) // 如果entry中存的TreadLocal与传入需要查找的ThreadLocal相等，则代表找到了 return e; if (k == null) expungeStaleEntry(i); // 在查找过程中，发现entry对应的key为null了，这是我们后续会讨论到的内存泄漏处理 else i = nextIndex(i, len); // 本次的slot不是要找的，继续寻找下一个slot e = tab[i]; } return null;} 同样set()/remove()方法也是类似。 ThreadLocal中的内存泄漏在我们使用ThreadLocal过程中，例如上面的ConnectionUtil中，如果ThreadLocal对象并不需要是一个持久变量，即如果ConnectionUtil被释放了，会导致其类中的ThreadLocal的引用被删除，那么此时的这个ThreadLocal需要被GC时，但是如果我们没有对每个线程都调用ThreadLocal的remove方法，那么就会有某个线程中的ThreadLocalMap的entry保留了该ThreadLocal的引用，使得该ThreadLocal对象无法被GC，并且一直保留到该线程结束，造成了内存泄漏。JDK通过弱引用的方式来解决这种内存泄漏的情况。 弱引用 Java中存在四种引用类型，强引用、软引用、弱引用、虚引用。 弱引用指向的对象，当进行垃圾回收时，如果该对象只有弱引用而没有强引用指向其时，就会没清除。ThreadLocal就是利用弱引用来防止内存泄漏，在ThreadLocalMap中，Entry对象继承了WeakReference： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; }} 也就是说，在new一个Entry对象时，该entry中保存的key(即ThreadLocal对象)为一个弱引用。那么当外部的强引用消失时，尽管ThreadLocalMap中还保留了ThreadLocal的引用，但是该引用是弱引用，GC会认为ThreadLocal对象为垃圾而将其清除。这样一来就会出现哈希slot中的entry对应的key为null的情况。 尽管ThreadLocal对象被清理了，但是Entry对应的value不是弱引用，这样一来也会造成内存泄漏，首先，value不能是弱引用，因为我们就是将value存入ThreadLocalMap中好让我们在该线程执行到任何地方时我们都能够取出来，如果为弱引用极有可能在我们不想释放的时候就已经被释放了。我们之前在分析get()方法时，就在查找对应entry时碰到了key为null的情况，如果碰到了这种情况，则是代表内存泄漏了，会将对应value队形进行释放。同样在set()/remove()方法中，查找时一旦发现key为null的entry就会清理其value来尽量避免内存泄漏。 ThreadLocal的安全使用方法则是每次set()后在之后不使用的情况下需要手动调用remove()方法，这样便不会造成内存泄漏了。","link":"/2020/09/30/Java%E5%B9%B6%E5%8F%91-ThreadLocal/"},{"title":"Nacos源码-Nacos服务端源码启动","text":"这些天准备阅读Nacos的源码，首先来搭建nacos源码的运行 下载Nacos源码去github的nacos主页下载1.3.1版本的nacos源码 1git clone --branch 1.3.1 https://github.com/alibaba/nacos.git 或者到release下面直接下载对应的压缩包 使用IDEA导入项目我们直接使用IDEA打开下载下来的文件夹，则可以看到Nacos的项目目录 启动Nacos进入nacos项目的console模块，是nacos的控制台模块，该项目是一个Springboot项目，启动该模块即可启动nacos所有的功能。 在启动前，给Nacos类的main添加JVM参数 1-Dnacos.standalone=true 启动main即可启动nacos，在浏览器中键入localhost:8848/nacos来到Nacos的登录页面，默认情况下登录的用户名和密码都是nacos，登录后可以看到如下界面： Nacos集群启动配置Mysql Nacos版本：1.3.1 Mysql版本：8.0.19 首先将项目最外层的pom.xml的mysql版本从8.0.16改为8.0.19 创建数据库： 在distribution模块下的conf目录中找到nacos-mysql.sql，在本地数据库执行生成数据库表 配置数据源： 在console模块下的application.properties的配置文件中添加： 12345spring.datasource.platform=mysqldb.num=1 # 数据库编号，可以配置多个数据库db.url.0=jdbc:mysql://192.168.100.164:3306/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=truedb.user=rootdb.password=123456 这样配置后，Nacos将使用mysql数据库来进行数据的持久化。 更改配置文件： 找到distribution模块的conf目录，添加cluster.conf文件或者把cluster.conf.example改为cluster.conf，该文件是配置Nacos集群各个集群的ip地址，编辑内容为如下： 1234#2020-10-29T17:04:22.196192.168.100.164:8848192.168.100.164:8849192.168.100.164:8850 添加启动参数： 在nacos的console模块下的启动类上添加启动参数，即Nacos类： 1-Dnacos.home=/Volumes/data/Java/sourcecode/nacos-1.3.1/distribution 配置该参数的目的是在项目启动时，会去找到该目录下刚刚编写的conf文件。","link":"/2020/10/29/Nacos%E6%BA%90%E7%A0%81-Nacos%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%BA%90%E7%A0%81%E5%90%AF%E5%8A%A8/"},{"title":"Netty核心组件-ByteBuf","text":"JDK提供的Buffer类实在太难用，例如读写操作切换需要flip()，DirectByteBuffer使用起来不方便。因此Netty自己提供了一套缓冲区的ByteBuf类来方便的进行缓冲区操作，在功能上与NIO的ByteBuffer是相同的。 概述Netty提供的ByteBuf优点有如下： 它可以被用户自定义的缓冲区类型扩展 通过内置的符合缓冲区类型实现了透明的零拷贝 容量可以按需增长 在读和写这两种模式之间切换不需要调用 #flip() 方法 读和写使用了不同的索引 支持方法的链式调用 支持引用计数 支持池化 ByteBuf基础​ ByteBuf是Netty有关缓冲区类的抽象基类，所有的缓冲区类都是继承自该类，该类的大部分方法都是抽象的，ByteBuf对字节数组的操作比NIO的ByteBuffer方便、灵活的多。 读写模式ByteBuf中有如下重要属性(这几个属性没有在ByteBuf中给出而是在AbstractByteBuf中给出，但是ByteBuf中定义了获取这些属性的方法)： readerIndex：读索引 writerIndex：写索引 capacity：字节数组的当前容量 maxCapacity：字节数组的最大容量，当writerIndex超过capacity时，可以自动地扩容，每次为2*capacity，但是不能超过maxCapacity ByteBuf引入了readerIndex和writerIndex来将读操作和写操作分开进行索引，避免了NIO的ByteBuffer在读写切换时需要flip() 四个大小关系很简单：readerIndex &lt;= writerIndex &lt;= capacity &lt;= maxCapacity 。如下所示： 123456+-------------------+------------------+------------------+| discardable bytes | readable bytes | writable bytes || | (CONTENT) | |+-------------------+------------------+------------------+| | | |0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity &lt;= maxCapacity 图中主要有三段数据： Discardable bytes(可废弃数据段)：在写入后被读取了的数据，位于0~readerIndex之间。 readable bytes(可读取的数据段)：读取操作只到了readerIndex，readerIndex~writerIndex之间的数据写入了但没有读取过，所以是可读取的数据。 writable bytes(可写的数据段)：字节数组还没有被写满，在writerIndex~capacity之间的空间还可以再被写入数据。 此外还有两个属性： markReaderIndex：标记读的索引位置 markWriterIndex：标记写的索引位置 这两个mark属性与NIO中的ByteBuffer提供的mark标记一样。 读写操作ByteBuf中定义了很多与读写相关的方法： 123456789101112131415161718192021222324252627282930313233// Byte 1 字节public abstract byte getByte(int index);public abstract short getUnsignedByte(int index);public abstract ByteBuf setByte(int index, int value);public abstract byte readByte();public abstract short readUnsignedByte();public abstract ByteBuf writeByte(int value);// Int 4 字节public abstract int getInt(int index);public abstract int getIntLE(int index);public abstract long getUnsignedInt(int index);public abstract long getUnsignedIntLE(int index);public abstract ByteBuf setInt(int index, int value);public abstract ByteBuf setIntLE(int index, int value);public abstract int readInt();public abstract int readIntLE();public abstract long readUnsignedInt();public abstract long readUnsignedIntLE();public abstract ByteBuf writeInt(int value);public abstract ByteBuf writeIntLE(int value);// Byte 数组public abstract ByteBuf getBytes(int index, ByteBuf dst);public abstract ByteBuf getBytes(int index, ByteBuf dst, int length);public abstract ByteBuf setBytes(int index, ByteBuf src);public abstract ByteBuf setBytes(int index, ByteBuf src, int length);// Stringpublic abstract CharSequence getCharSequence(int index, int length, Charset charset);public abstract int setCharSequence(int index, CharSequence sequence, Charset charset);public abstract CharSequence readCharSequence(int length, Charset charset);public abstract int writeCharSequence(CharSequence sequence, Charset charset); 以上给出了部分典型的方法，可以看出，ByteBuf可以方便地读取/写入各种不同的基本数据类型，并且很多方法返回ByteBuf对象(本身)可以进行链式调用。 以上不同的方法对readerIndex和writerIndex的影响是不同的： #getXXX(index) 方法，读取指定位置的数据，不改变 readerIndex 索引。 #readXXX() 方法，读取 readerIndex 位置的数据，会改成 readerIndex 索引。 #setXXX(index, value) 方法，写入数据到指定位置，不改变 writeIndex 索引。 #writeXXX(value) 方法，写入数据到指定位置，会改变 writeIndex 索引。 释放操作1234public abstract ByteBuf discardReadBytes(); // 释放已读的字节空间public abstract ByteBuf discardSomeReadBytes(); // 释放部分已读的字节空间public abstract ByteBuf clear(); // 清空字节空间。实际是修改 readerIndex=writerIndex=0，标记清空。 discardReadBytes 释放所有的已读的空间，相当于把discardable段的数据都释放掉。 优点：达到重用废弃段的空间内存。 缺点：释放的方式，是通过复制可读段到 ByteBuf 的头部。所以，频繁释放会导致性能下降。 1234567891011121314151617// 释放前BEFORE discardReadBytes() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity===========================================================================// 释放后AFTER discardReadBytes() +------------------+--------------------------------------+ | readable bytes | writable bytes (got more space) | +------------------+--------------------------------------+ | | |readerIndex (0) &lt;= writerIndex (decreased) &lt;= capacity discardSomeReadBytes 释放部分空间，取决于具体子类的实现 clear 清空字节空间。实际是修改 readerIndex = writerIndex = 0 ，标记清空。 优点：通过标记来实现清空，避免置空 ByteBuf ，提升性能。 缺点：数据实际还存在，如果错误修改 writerIndex 时，会导致读到“脏”数据。 1234567891011121314151617// 释放前BEFORE clear() +-------------------+------------------+------------------+ | discardable bytes | readable bytes | writable bytes | +-------------------+------------------+------------------+ | | | | 0 &lt;= readerIndex &lt;= writerIndex &lt;= capacity=========================================================================== // 释放后AFTER clear() +---------------------------------------------------------+ | writable bytes (got more space) | +---------------------------------------------------------+ | | 0 = readerIndex = writerIndex &lt;= capacity ByteBuf核心子类 按内存类型分： HeapByteBuf(堆内字节缓冲)：字节数组缓冲区位于JVM的堆区。特点是申请和释放效率较高，但是缺点与NIO的堆内缓冲区一样，在进行网络I/O操作时数据不能直接读/写到堆内缓冲区，需要先在内核空间建立一个缓冲区，把网络传输的数据写到内核空间的缓冲区后再拷贝到堆内的缓冲区，读写的性能有损耗。 DirectByteBuf(直接内存字节缓存)：字节数组的缓冲位于JVM的堆外空间(元空间)。特点是I/O读写效率高，因为该缓冲区建立在堆外，并且利用mmap的系统调用使得操作系统可以直接读写该缓冲区的数据，因此不需要进行像堆内字节缓冲那样的拷贝，性能更高。缺点是由于位于堆外内存，释放必须触发Full GC，而Full GC对性能的损耗比较大，需要合理使用。 堆内缓冲与堆外缓冲的细节在NIO中已经说明清楚，Netty的缓冲类也具备相同的特点，在此不详细赘述。 按是否建立对象池分： PooledByteBuf(具有对象池)：该字节数组缓冲区对象位于缓冲对象池内，释放时会被归还到对象池中得以重复利用，这样每次使用ByteBuf时就不需要重新去创建对象，经常创建ByteBuf会触发GC，尤其是DirectByteBuf会触发Full GC，造成性能损耗。 UnpooledByteBuf(不具有对象池)：单纯创建一个新的ByteBuf对象，使用完后就等待GC释放。由于对象池维护与创建比较麻烦，不需要大量创建缓冲区对象的地方推荐使用UnpooledByteBuf 按是否使用Unsafe分类： 由于Java不能够从直接操作底层，JDK提供了sun.misc.Unsafe对于底层的内存与线程直接操作，Unsafe被广泛用于JDK的官方源码中(并发包)，但是官方不推荐开发者使用，因为Unsafe对于内存直接进行操作，申请的内存不受JVM管理，需要手动释放内存，与C++的new/和delete类似，申请的空间如果不手动释放，便会造成内存泄漏。 使用Unsafe：由于Unsafe申请的缓冲区位于JVM内存区域的外部，完全不受JVM管控，即不会对GC造成影响，申请的空间在不使用时可以直接手动释放，因此具有更高的效率。 不使用Unasfe：申请的缓冲区位于JVM内存中(HeapByteBuf在堆内，DirectByteBuf在堆外元空间)，频繁的申请临时对象会造成GC压力，频繁的GC会损耗性能。 关于效率的说明： ​ Java中，几乎所有对象都是由JVM管理的，每次在使用new都会在堆空间创建一个对象后(不完全一定在堆空间，JVM逃逸分析允许局部小对象创建在栈区)，如果该局部对象失去了引用，并不会马上释放这个对象所占用的内存空间，而是等到内存占用到一定事件才会调用GC进行垃圾回收，对象的回收对于程序员而言时不可控的。因此，不使用Unsafe，在高并发的环境下，如果频繁的创建临时的ByteBuf（尤其是DirectByteBuf），会频繁的调用GC（DirectByteBuf调用的是Full GC），这无疑对性能有巨大的损失。而使用Unsafe就像写C/C++一样，可以控制缓冲区的生命周期，不用的时候马上释放而不用去麻烦GC，效率更高。 ​ Unsafe对于普通的开发者不要去使用，因为非常地不安全，一旦出问题就会造成JVM崩溃。Netty为我们封装好了Unsafe的缓冲区，我们不需要考虑Unsafe缓冲区的内存释放，Netty已经通过引用计数和内存泄漏检测来保证缓冲区的内存释放，我们可以放心使用。","link":"/2020/09/01/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-ByteBuf/"},{"title":"docker常用命令","text":"总结一些docker的常用命令。 docker run启动docker run [option] 镜像名 [向启动容器中传入的命令] -i 表示以“交互模式”运行容器 -t 表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即 分配一个伪终端。 –name 为创建的容器命名。--name=&quot;nginx-lb&quot; -v 表示目录映射关系(前者是宿主机目录，后者是映射到宿主机上的目录，即 宿主机目录:容器中目录)，可以使 用多个-v 做多个目录或文件映射。注意:最好做目录映射，在宿主机上做修改，然后共享到容器上。 -v /data/mysql:/mysql /data/redis:/redis -d 在run后面加上-d参数,则会创建一个守护式容器在后台运行(这样创建容器后不会自动登录容器，即后台运行。如果只加-i -t 两个参数，创建后就会自动进去容器)。 -p 表示端口映射，宿主机端口:容器内的映射端口。可以使用多个-p 做多个端口映射。-p 26888:80 26889:8080 -P 随机端口映射，一般在dockerfile中有暴露端口 -e 为容器设置环境变量 –net 表示使用的网络配置，可以自动以网络配置。--net bridge是默认加上的 –network=host 表示将主机的网络环境映射到容器中，容器的网络与主机相同 -m :设置容器使用内存最大值；-m 512M or -m 4G –cpuset=”0-2” or –cpuset=”0,1,2”: 绑定容器到指定CPU运行； -c,–cpu-shares=0 # CPU 共享权值（相对权重） 例如： 12345678docker run -p 26881:3306 // 主机端口26881映射到容器的3306端口 -v /project/p1/mysql/data:/mysql/data // 主机的/project/p1/mysql/data与容器的/mysql/data共享卷 --name &quot;mysql&quot; // 容器名称mysql --cpuset=&quot;0-2&quot; // 给该容器分配CPU0,1,2 -m 10G // 该容器最大的使用内存10G -d // 后台启动 mysql:8.0.19 // 启动mysql:8.0.19镜像 1docker run -v ~/application/docker/volumn/java-centos:/docker/volumn --name &quot;java-centos&quot; -i -t centos:7 1docker run -p -v ~/application/docker/volumn/jdk1.8-centos:/docker/volumn --name &quot;jdk1.8-centos&quot; -i -t centos:7 进入docker容器docker attach sudo docker attach [容器id] docker exec sudo docker exec -it [容器id] /bin/bash 将容器变为镜像docker commit -m=&quot;描述&quot; -a=&quot;作者&quot; [容器Id] [镜像名]:[标签名] Docker网络docker网络原理默认情况下，docker各个容器之间采用桥接模式 docker主机查看网络配置： 容器1的网络配置： 容器2的网络配置： 启动两个docker容器后主机的网络配置： 默认情况下网络关系如下： 主机可以直接ping通两个容器 两个容器也可以直接ping通主机 两个容器之间直接能ping通 docker network ls：查看当前所有的docker网卡 docker network inspect [网卡ID]：查看某个网卡的详细信息 docker容器之间的通信在默认的docker0网络配置下，dokcer容器之间可以通过ip来ping通，但是无法通过容器名来进行ping通，一种方式使用过在启动时--link [容器名]来指定该容器需要通信的容器名。 12docker run --name centos01 java-centos:7docker run --name centos02 --link centos01 java-centos:7 这样启动后，centos02可以ping通centos01，但是centos01不能ping通centos02，--link会存在很多坑，它是直接往容器的host目录下写一个DNS来实现通过容器名访问其他容器的，而且这样非常不方便，官方已经不推荐使用。 想要通过容器名来ping通，最好的方式就是通过自定义网络来实现，通过docker network ls可以看到： 默认的都是采用bridge的网络，即docker0。 我们可以自定义一个网络： docker network create --driver [驱动方式] --subnect [内网ip网络划分] --gateway [内网网卡] [网络名称] 1234docker network create --driver bridge --subnet 196.168.0.0/16 --gateway 196.168.0.1 mynet// --driver bridge表示桥接的方式，不指定的话默认也是桥接，一般都用桥接// --subnet 196.168.0.0/16 表示内网地址为196.168.x.x，16表示子网划分，后面16位都是内网支持的，因此可以分配65535个ip// --gateway 196.168.0.1 表示网关的ip地址，即路由器地址 我们使用自定义的网络来启动容器 12docker run --name=&quot;centos02&quot; -it --net mynet jdk:1.8docker run --name=&quot;centos01&quot; -it --net mynet jdk:1.8 此时两个容器之间就可以直接通过容器名来ping通了 不同网络配置下的容器相互通信 加入现在centos01容器是在docker0的网络配置下启动的，而centos02容器是在mynet的网络配置下启动的，那么此时无论的是通过ping ip还是ping 容器名都是无法ping通的，向要centos01与centos02能够ping通只需要将centos01加入到mynet下即可： 1docker network connect mynet centos01 这样一来在mynet下就给centos01分配了一个ip地址，即一个容器有多个ip地址，那么centos01与mynet下的所有容器都互通了","link":"/2020/10/20/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"title":"函数式编程","text":"函数式编程在现在使用非常广泛，使用函数式编程能使得代码更加简洁。 1 使用lambda表达式&emsp;&emsp;现在有如下需求，给定一个员工类，包含姓名、性别、年龄、工资，想从所有员工中找到性别为男，或者年龄小于30岁，或者工资大于5000的员工，按照以前的方法我们可能会这样做： 12345class Employee{ private String name; private boolean sex; private int age; private int salary; 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) { List&lt;Employee&gt; employees = Arrays.asList( new Employee(&quot;zs&quot;, true, 25, 6000), new Employee(&quot;ls&quot;, true, 35, 9000), new Employee(&quot;ww&quot;, false, 21, 5000), new Employee(&quot;lx&quot;, true, 45, 12000), new Employee(&quot;qs&quot;, false, 33, 7000) ); // 查找年龄小于30的 List&lt;Employee&gt; employeesBelow30 = new ArrayList&lt;&gt;(); for(Employee employee : employees){ if(employee.getAge() &lt; 30){ employeesBelow30.add(employee); } } // 查找性别为男的 List&lt;Employee&gt; employeesMan = new ArrayList&lt;&gt;(); for(Employee employee : employees){ if(employee.getAge() &lt; 30){ employeesMan.add(employee); } } // 查找工资大于5000的 List&lt;Employee&gt; employeesSalaryExceed5000 = new ArrayList&lt;&gt;(); for(Employee employee : employees){ if(employee.getAge() &lt; 30){ employeesSalaryExceed5000.add(employee); } }} &emsp;&emsp;或者我们可以写三个方法：按年龄筛选、按性别筛选、按工资筛选，那我们可能需要提供非常多的方法(例如年龄大于某个值，年龄小于某个值，年龄在某个值到某个值之间) ​ 但是如果我们使用策略模式+lambda表达式，这些问题都能够轻松解决： 12345678910111213141516171819202122232425262728293031323334353637public class Learn1 { public static void main(String[] args) { List&lt;Employee&gt; employees = Arrays.asList( new Employee(&quot;zs&quot;, true, 25, 6000), new Employee(&quot;ls&quot;, true, 35, 9000), new Employee(&quot;ww&quot;, false, 21, 5000), new Employee(&quot;lx&quot;, true, 45, 12000), new Employee(&quot;qs&quot;, false, 33, 7000) ); // 查找年龄小于30的 List&lt;Employee&gt; employeesBelow30 = filter(employees, e -&gt; e.getAge() &lt; 30); // 查找性别为男的 List&lt;Employee&gt; employeesMan = filter(employees, e -&gt; e.isSex()); // 查找工资大于5000的 List&lt;Employee&gt; employeesSalaryExceed5000 = filter(employees, e -&gt; e.getSalary() &gt; 5000); } public static List&lt;Employee&gt; filter(List&lt;Employee&gt; employees, EmployeeOperater&lt;Employee&gt; employeeFilter){ List&lt;Employee&gt; employeesMeetCondition = new ArrayList&lt;&gt;(); for(Employee employee : employees) { if(employeeFilter.filter(employee)){ employeesMeetCondition.add(employee); } } return employeesMeetCondition; }}@FunctionalInterfaceinterface EmployeeOperater&lt;T&gt;{ boolean filter(T t);} &emsp;&emsp;这样一来我们的代码会优雅、简洁很多，我们无需再向上述代码一样每次都去写遍历的代码，也无需为了使用方便去编写太多重复的筛选方法，使用者可以根据自己的查询需求来制定查询策略即可。 &emsp;&emsp;后续使用Stream API还有更简便的方式，无需写接口与filter方法。 Lambda表达式的使用必须配合接口，并且只含有一个抽象方法的接口，格式： 123456@FunctionalInterfacepublic interface 接口名{ public abstract void 函数名(); //只能有一个抽象方法 // ... // 下面可以有默认方法等，只需要保证只有一个抽象方法即可} ​ 如果在接口内定义了多个抽象方法或不定义抽象方法，则不是函数式接口，采用@FunctionalInterface注解可以检查是否为函数式接口，若不是则在编译时会报错。 2 JDK提供的关于lambda表达式的四大函数式接口 Consumer&lt;T&gt; 消费型接口 void accept(T t); Supplier&lt;T&gt; 供给型接口 T get(); Function&lt;T, R&gt; 函数型接口 R apply(T t); Predicate&lt;T&gt; 断言型接口 boolean test(T t); 3 方法引用和构造器引用&emsp;&emsp;在使用lambda表达式时，我们每次都需要去实现接口的方法，这样可能会比较麻烦，JDK提供了方法引用来更加便捷的使用lambda表达式，即直接将已有的方法作为函数式接口的实现，方法引用有如下几种形式： 类名::静态方法名 对象::实例方法名 类名::实例方法名 12345678910111213141516public static void main(String[] args) { // 对象::实例方法名================ List&lt;Integer&gt; list = Arrays.asList(2,3,4,1,5); PrintStream printStream = System.out; Consumer&lt;Integer&gt; consumer = printStream::println; list.forEach(consumer); // 上面三行变为一行 list.forEach(System.out::println); // foreach需要提供Consumer接口的实现 // 类名::静态方法名 Comparator&lt;Integer&gt; comparable = Integer::compare; // T compare(T t1, T t2); // 类名::实例方法名，注意这种形式有一定的要求，在此例中，即第一个参数为方法的调用者，第二个参数为被引用方法的参数。 BiPredicate&lt;String, String&gt; predicate0 = (x, y) -&gt; x.equals(y); BiPredicate&lt;String, String&gt; predicate = String::equals; // boolean test(T t1, T t2);} 构造器引用： 类名::new &emsp;&emsp;构造器引用其实与方法引用类似，一个类可能有多个构造器，编译器会自动选择与接口参数相匹配的构造器方法。 1Supplier&lt;Employee&gt; supplier = Employee::new; // 由于Supplier接口的方法为T get()，所以自动选择的是无参构造器","link":"/2020/05/22/han-shu-shi-bian-cheng/"},{"title":"HashMap","text":"Java中的HashMap的原理就是哈希表，实现主要是通过数组+链表(或红黑树)。 首先初始化一个数组(默认大小为16)，当向其中插入key-value键值对时，会根据key通过散列算法计算哈希值，计算出的哈希值为该元素储存在数组中的位置(因此哈希值必须为合法的索引)。如果该位置上存在了元素(链表)，先检查该链表上是否有key相等的元素，如果没有就将这个元素作为链表节点连接在该位置已存在元素的后面，有的话就覆盖。 ​ ​ 一个key-value元素为一个Entry对象，Entry对象中存储了： ​ (1)该元素的hash值 ​ (2)键值key ​ (3)value ​ (4)下一个Entry对象的引用 ​ JDK1.8中Node类即为Entry类。 数组的初始大小HashMap的数组大小均为2的幂次方，无论你给的容量大小为多少，都会求出大于给定初始容量的最小的2的幂次方作为Hashmap数组的容量。至于为什么要是2的幂次方，等会再介绍，首先来看看HashMap如何来求取大于给定初始容量的最小的2的幂次方的数值。 123456789static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 每次初始化Hashmap数组大小时，都会使用该函数来计算数组的大小，传入的cap为构造函数传入的初始大小。 我们先忽视n=cap-1，我们来看位运算，通过5步位运算，我们可以求得一个int类型数字的最高位所对应的2的幂次方，也就是小于给定n的最大的2的幂次方：3=》2，10=》8. 现在我们假定一个int类型的数转化为2进制为1\\**，\\代表为任意一个数字 进行&gt;&gt;&gt;1：01**** 或|：1\\*** | 01**** = 11**** 进行&gt;&gt;&gt;2：0011** 或|：11**** | 0011** = 1111** 进行&gt;&gt;&gt;4：000011 或|：1111** | 000011 = 111111 我们可以看出无论最高位1后面是什么，我们都能把1的最高位后面都变为1，&gt;&gt;&gt;1与一次或操作能保证从最高位算起前两个均为1，继而&gt;&gt;&gt;2和或保证前4个均为1…，&gt;&gt;&gt;16和或保证前32位都为1，那么int最高位32位，进过这几步后一个int的数必定所有位都为1。 为什么容量要为2的幂次方？ 这是由于jdk在hashmap中求key的hashcode对应的数组index下标时，采用的是&amp;运算。本来我们应该是求hashcode%数组长度l，但是当数组长度l为2的幂次方时，就会有hashcode%l=hashcode&amp;(l-1)。&amp;运算的效率要高于取模运算。 当l为2的幂次方即l=2^n，则l-1的低n位都为1，进行与运算后只会保留hashcode的后n尾，后n位即为hashcode对l取余的值。 插入元素细节在JDK1.7中，HashMap调用put方法是采用头插法将元素加入对应的链表(单向链表)，我们通过调用Hash算法计算出Hashcode值，求出插入的key应该存储在数组中哪个下标对应的链表中，然后遍历查询该链表，如果链表中不存在插入的key，那么就在链表的头部插入该元素。 采用头插法的原因是因为链表是单向链表，如果插入到尾部的复杂度为O(n)，n为链表的长度，如果插入到头部，复杂度为O(1)。 但是其实如果需要向链表中插入新的元素，我们需要遍历链表去进行查找，如果这个key不存在，我们需要遍历所元素到链表的尾部，然后插入；如果这个key存在那么我们只是修改key所在链表节点对应的value即可，不需要再进行遍历，因此头插法和尾插法几乎没有差别。JDK1.7采用的头插法，而JDK1.8则采用尾插法。 JDK1.8在链表插入的逻辑上与JDK1.7类似，只是采用尾插法。但是JDK1.8在链表长度大于8时，会将链表转化为红黑树，红黑树的插入、删除、查找效率均为O(logn)，在JDK1.8中，一颗红黑树同样也是一个双向链表，因为TreeNode也是继承了Node。如果像JDK1.7只采用链表，那么在链表上查询效率为O(n)，在这里n指链表长度，不是HashMap的大小。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// JDK1.8中的putfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 数组还没初始化 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) // 根据hash值求出在数组上应该存储的位置，数组对应位置上没有元素就直接赋值 tab[i] = newNode(hash, key, value, null); else { // 数组对应位置上有元素 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // 如果头结点的key与插入的key相同，就直接修改即可 e = p; else if (p instanceof TreeNode) // 如果这个节点类型是红黑树节点，意味着该位置已经转化为红黑树了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 通过红黑树添加的方法去添加节点或修改节点，key已经存在就返回对应的节点，不存在返回null else { for (int binCount = 0; ; ++binCount) { // 该位置为链表形式，遍历链表 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果遍历到链表尾部了还不存在put的key，就把这个节点插在尾部 // 判断节点数量是否大于8，binCount此时没有加上新加入的节点，TREEIFY_THRESHOLD为8，即binCount&gt;=7，转化时链表长度为binCount+1+1，1个为新插入的节点 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 将该链表转化为红黑树 break; } // 如果链表中存在该key，就直接修改 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key // 如果存在这个key，就修改对应的value即可 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 修改次数+1 if (++size &gt; threshold) resize(); // 超过容量就扩容 afterNodeInsertion(evict); return null;} 红黑树的具体细节参考JDK源码讲解的TreeMap。 扩容细节JDK1.7与JDK1.8扩容的思路类似，只是JDK1.8中扩容时需要考虑红黑树的扩容，在此直接介绍JDK1.8的扩容。 当HashMap的size到达阈值(阈值通常为负载因子*容量capicity)，HashMap的数组就会扩容，扩容主要是解决hash冲突，是的每个数组对应的链表或红黑树的长度变小，提高增删改查效率。 由前面的数组初始化我们可以知道，数组的容量一定为2的幂次方，并且扩容时就是将容量变为原来的2倍。那么，在数组扩容后需要对每个节点重新计算在数组中的位置，不过，由于数组容量是2的幂次方，我们可以看看一个节点在扩容前的位置与扩容后的位置，设扩容前大小为16，扩容后为32。 扩容前：hash&amp;(16-1)=hash&amp;1111 扩容后：hash&amp;(32-1)=hash&amp;11111 我们可以看到，扩容前和扩容后的在数组中索引对应的二进制后四位都相同，只有第五位会存在差异。如果hash值的第五位为0，那么扩容前和扩容后的索引相同，如果hash值的第五位为1，那么扩容后的索引为扩容前的索引+16。判断是否应该+16只需要计算hash&amp;16，如果为0就不变，如果为1就改变。 因此对于任意的扩容，如果扩容前数组的大小为2^n，节点的索引为i，那么扩容后节点的索引只可能为i或i+2^n，若hash&amp;2^n=0，则扩容后节点索引仍然为i；如果hash&amp;2^n=1，则扩容后索引为i+2^n。 利用这一特性，在进行扩容时，对于每一个链表或红黑树，都可以拆解为两个链表，一个链表为索引不变的节点，另一个链表为索引变化的节点，在转移数据时只需要把这两个链表(如果拆解后的链表长度大于8需要转化为红黑树)放置在新的数组中即可，这样具有较高的扩容效率，这也是HashMap数组长度要为2的幂次方的原因之一。 JDK实现的HashMap的负载因子默认为0.75，为什么是0.75呢？ ​ HashMap的负载因子用于当元素总个数大于负载因子*数组长度时，就进行扩容操作。负载因子就是用权衡空间利用率和操作元素效率的： 当负载因子较小时，这样一来每个桶(数组链表)所存放的元素数量相对更少，元素操作速度更快，但是浪费空间，并且如果频繁的插入元素，HashMap的扩容操作会更加频繁，扩容是比较耗时的，会造成效率低下 当负载因子较大时，每个桶存放的元素数量相对更多，元素操作的速度相对更慢，但是空间节省，并且频繁插入元素HashMap的扩容也会少一些 在HashMap的源码中提到，假设key的hashcode随机，每个桶中放入节点的频率满足以0.5为参数的泊松分布，在负载因子为0.75的情况下，每个桶中出现元素个数的概率如下： 12345678910* 0: 0.60653066* 1: 0.30326533* 2: 0.07581633* 3: 0.01263606* 4: 0.00157952* 5: 0.00015795* 6: 0.00001316* 7: 0.00000094* 8: 0.00000006* more: less than 1 in ten million ​ 这意味着当然元素个数大于8的概率非常低，因此负载因子为0.75比较好。当然JDK考虑到了hashcode并不一定完全随机，因此当元素大于8时会转化为红黑树来提高效率。","link":"/2020/06/20/hashmap/"},{"title":"Netty中的ChannelOption配置","text":"最近在学到netty是发现ServerBootstrap/Bootstrap类中有option的配置，发现option是配置在Channel上与socket标准相关的参数，于是总结一下有关该参数的配置。 SO_BACKLOGChannelOption.SO_BACKLOG对应的是tcp/ip协议listen函数中的backlog参数，函数listen(int socketfd,int backlog)用来初始化服务端可连接队列。 TCP建立连接是需要时间，如果一段时间内有大量的连接请求，计算机能够处理的连接数量有限，那么就会将这些请求放入等待队列。由于TCP建立连接是要进行三次握手的，Linux中维护了两个队列分别为syns queue和accept queue，分别用于储存处于SYN_RCVD(半连接，第一次握手后)和ESTABLISHED(建立连接，第三次握手后)状态的连接。 当进行完第一次握手后，服务端会发起与客户端握手，这是这个连接就会被放入半连接队列中，等到客户端握手成功返回给服务端再次握手成功后，这个连接就会被移到建立连接的队列中，等待应用程序调用accept()来获取连接。 syns queue 队列长度由 /proc/sys/net/ipv4/tcp_max_syn_backlog 指定，默认为2048。 accept queue 队列长度由 /proc/sys/net/core/somaxconn 和使用listen函数时传入的参数，二者取最小值。默认为128。如果accpet queue队列满了，server会拒绝连接并将发送一个ECONNREFUSED错误信息Connection refused到client。 在netty中somaxconn是根据操作系统的配置来进行设置的 默认情况下，BACK_LOG与SOMAXCONN相同，我们可以在netty中进行配置来改小accept队列的最大长度，但是如果我们需要改大accept队列的长度，则需要把/proc/sys/net/core/somaxconn中的参数也改大，因为前面说到accept queue 队列长度由 /proc/sys/net/core/somaxconn 和使用listen函数时传入的参数，二者取最小值。 SO_KEEPALIVE该参数用于设置TCP连接，可以设置为true或false，当设置该选项以后，连接会测试链接的状态，这个选项用于可能长时间没有数据交流的连接。当设置该选项以后，如果在两小时内没有数据的通信时，TCP会自动发送一个活动探测数据报文。 我们知道正常情况tcp连接关闭的时候，无论是客户端发起关闭还是服务发起关闭都会正常关闭连接，双方都会释放该连接占用的资源：应用释放资源，tcp层也会释放资源（主要是内存资源）。但是有些情况，该不该释放资源，就不知道了，如果服务端与客户端以长连接的方式保持连接，但是服务端已经长时间没有收到客户端发来的数据，造成这种原因包括以下几方面： 客户端确实没有需要发送的数据 客户端进程意外终止运行 客户端所在的服务器宕机，或停电 网络中间设备掐断连接，如防火墙对长时间不活动的连接，进行强制关闭 针对以上4种情况，只有1是正常情况，不应该关闭双方的连接，其它都是异常情况，服务端就应该关闭已经建立的连接，释放服务端的资源。如果不释放，就会存在很多半连接状态的连接，占用服务端大量资源。由于存在1这种正常的情况，服务端就不断随意关闭连接，需要一种手段来解决连接该不该关闭的问题。TCP/IP协议实现中就包含了心跳机制，在服务端程序程序中我们只需要设置SO_KEEPALIVE参数，那么如连接超过指定的时间（见第3节心跳相关的参数）没有收到数据，就会触发TCP层发起心调检测，从这里看可以看出TCP协议自身心跳的目的是检测异常链接，关闭链接，及释放资源。 另外，应用程序也可以自己实现心跳检测来实现关闭异常连接。 暂时使用过这几个参数，后续要到了再加","link":"/2020/05/27/netty-zhong-de-channeloption-pei-zhi/"},{"title":"Spring与Mybatis整合的原理(一)","text":"在单独使用Mybatis时，还是有些麻烦的，spring自己提供了一套数据库操作的jdbc，但是远不如Mybatis，接下来我们来看看Mybatis是如何无缝与Spring进行整合的。 在单纯使用Mybatis时，我们编写好myabtis的配置文件、mapper.xml文件以及对应mapper接口后，需要获得SqlSession对象调用其getMapper()方法来获取对应的mapper接口的代理对象。 12345678910111213141516171819public static void main(String[] args) throws Exception { //1.读取配置文件 InputStream inputStream = Resources.getResourceAsStream(&quot;SqlMapConfig.xml&quot;); //2.创建SqlSessionFactory工厂 SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); SqlSessionFactory factory = builder.build(inputStream); //3.创建SqlSession对象 SqlSession session = factory.openSession(); //4.使用Sqlsession创建Dao接口的代理对象 IUserDao userDao = session.getMapper(IUserDao.class); //5.使用代理对象执行方法 List&lt;User&gt; users = userDao.findAll(); for(User user:users){ System.out.println(user); } //6.释放资源 session.close(); inputStream.close();} 在这里，一个SqlSession对应一个数据库连接(jdbc连接)，因此我们在获取连接后，取出需要的mapper对象然后对数据库进行操作完成后释放连接即可，同时我们也可以利用SqlSession开启事务、提交事务、回滚事务等。 首先让我们来看看单纯使用Mybatis是如何对数据库进行操作的。 创建SqlSession对象单纯使用Mybatis时，我们从SqlSessionFactory中获取到的SqlSession对象为其实现类DefaultSqlSession对象。而在上面的代码中，我们获取到的factory的实际类型为DefaultSqlSessionFactory，执行其openSession方法主要执行openSessionFromDataSource方法： 123456789101112131415161718192021// class DefaultSqlSessionFactoryprivate SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) { Transaction tx = null; try { // 通过配置信息拿到配置环境 final Environment environment = configuration.getEnvironment(); // 从配置环境中工厂中获取事务工厂 final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); // 从数据源中获取事务 tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 获取执行器，Executor是最终操作数据库的 final Executor executor = configuration.newExecutor(tx, execType); // 返回SqlSession return new DefaultSqlSession(configuration, executor, autoCommit); } catch (Exception e) { closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + e, e); } finally { ErrorContext.instance().reset(); }} 该部分代码用于创建SqlSession执行了以下步骤： 获取到 TransactionFactory 事务工厂对象 通过 TransactionFactory 获取了一个 事务 Transaction 根据 execType（默认是 SIMPLE ） 获取了一个Executor （真正执行数据库操作的对象） 创建并返回 DefaultSqlSession 对象 从上面的代码我们可以看出，一个SqlSession对应一个事务(一一对应)，并且把数据库的执行类对象也传入了SqlSession中，在这里并没有创建连接。 Mapper对象我们在使用mybatis时仅仅需要创建Mapper的接口即可，而不需要创建Mapper对应的实现类，Mybatis在获取到Mapper接口文件时，就能帮我们创建出代理对象，因此通过getMapper获取到的是Mapper接口的代理类对象。 从SqlSession中获取Mapper对象并不意味着Mapper对象属于SqlSession，Mapper对象是通过SqlSession中的configuration对象所创建的(上面在创建SqlSession对象时传入的)，而configuration在创建时调用了MapperRegistry下的getMapper方法 1234567891011121314// class MapperRegistrypublic &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) { // 根据对应传入Mapper类型获取Mapper的代理工厂 final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) { throw new BindingException(&quot;Type &quot; + type + &quot; is not known to the MapperRegistry.&quot;); } try { // 从代理工厂中创建一个Mapper的代理对象 return mapperProxyFactory.newInstance(sqlSession); } catch (Exception e) { throw new BindingException(&quot;Error getting mapper instance. Cause: &quot; + e, e); }} 首先从已经扫描的mapper文件后生成的knownMappers对象中获取到Mapper的代理工厂 从代理工厂中创建一个Mapper的代理对象 代理对象的创建如下： 123456789// class MapperProxyFactoryprotected T newInstance(MapperProxy&lt;T&gt; mapperProxy) { return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);}public T newInstance(SqlSession sqlSession) { final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);} 使用Jdk的动态代理，传入实现了InvocationHandle接口的MapperProxy类，接下来我们再来看看这个代理类是如何执行接口的方法。 Mapper代理对象方法的执行MapperProxy类中的invoke方法及为代理对象执行的方法： 123456789101112131415// MapperProxy@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable { try { if (Object.class.equals(method.getDeclaringClass())) { // 当方法属于Object的方法，就直接把this(MapperProxy)传入执行，都是Object的子类 return method.invoke(this, args); } else { // 返回一个方法执行器来执行方法 return cachedInvoker(method).invoke(proxy, method, args, sqlSession); } } catch (Throwable t) { throw ExceptionUtil.unwrapThrowable(t); }} 在这里，如果调用的方法属于Object类，那么就用this直接调用自己方法(默认的Object类方法)。 如果不是Object类中的方法，那么是Mapper接口中定义的方法，那么将会创建一个方法执行器来执行(该方法创建后会被缓存起来) 123456789101112131415161718192021222324252627// MapperProxyprivate MapperMethodInvoker cachedInvoker(Method method) throws Throwable { try { // 如果创建过该方法的执行器可以直接返回，没有创建过则利用下面代码块的方法创建一个方法缓存起来然后返回。 return methodCache.computeIfAbsent(method, m -&gt; { if (m.isDefault()) { // &lt;1&gt;是默认方法default声明，则是用户在接口中自定义了该方法，不进行代理 try { if (privateLookupInMethod == null) { return new DefaultMethodInvoker(getMethodHandleJava8(method)); } else { return new DefaultMethodInvoker(getMethodHandleJava9(method)); } } catch (IllegalAccessException | InstantiationException | InvocationTargetException | NoSuchMethodException e) { throw new RuntimeException(e); } } else { // &lt;2&gt;不是default方法，一般都走这里 return new PlainMethodInvoker(new MapperMethod(mapperInterface, method, sqlSession.getConfiguration())); } }); } catch (RuntimeException re) { Throwable cause = re.getCause(); throw cause == null ? re : cause; }} methodCache.computeIfAbsent的第二个参数为一个函数型函数接口，首先看看computeIfAbsent里的代码： 123456789101112131415default V computeIfAbsent(K key, Function&lt;? super K, ? extends V&gt; mappingFunction) { Objects.requireNonNull(mappingFunction); V v; if ((v = get(key)) == null) { // 从缓存中获取该方法的执行器，如果没有，就利用Function函数接口创建一个，这个接口的apply方法在上面定义 V newValue; if ((newValue = mappingFunction.apply(key)) != null) { put(key, newValue); return newValue; } } return v;} 我们可以看到，该方法返回了一个方法执行器，如果没有创建过该方法的执行器，就利用apply方法创建一个然后缓存起来，因此我们还是回到lambda表达式中的代码块。 Mapper接口中的default方法由用户自己实现，不进行代理，而操作数据库的往往都是没有实现的，一般走&lt;2&gt;，接下来我们来看看新创建的这个类PlainMethodInvoker对象的定义。 12345678910111213private static class PlainMethodInvoker implements MapperMethodInvoker { private final MapperMethod mapperMethod; public PlainMethodInvoker(MapperMethod mapperMethod) { super(); this.mapperMethod = mapperMethod; } @Override public Object invoke(Object proxy, Method method, Object[] args, SqlSession sqlSession) throws Throwable { return mapperMethod.execute(sqlSession, args); }} 从这里可以看到，这个invoke方法就是Mapper代理对象执行的方法，MapperMethod是在创建PlainMethodInvoker时new出来的，excute方法几乎就是执行数据库操作的入口，我们接着看这个方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public Object execute(SqlSession sqlSession, Object[] args) { Object result; switch (command.getType()) { case INSERT: { Object param = method.convertArgsToSqlCommandParam(args); // 利用sqlSession进行数据库insert操作 result = rowCountResult(sqlSession.insert(command.getName(), param)); break; } case UPDATE: { Object param = method.convertArgsToSqlCommandParam(args); // 利用sqlSession进行数据库update操作 result = rowCountResult(sqlSession.update(command.getName(), param)); break; } case DELETE: { Object param = method.convertArgsToSqlCommandParam(args); // 利用sqlSession进行数据库delete操作 result = rowCountResult(sqlSession.delete(command.getName(), param)); break; } case SELECT: // 利用sqlSession进行数据库select操作 if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) { executeWithResultHandler(sqlSession, args); result = null; } else if (method.returnsMany()) { result = executeForMany(sqlSession, args); } else if (method.returnsMap()) { result = executeForMap(sqlSession, args); } else if (method.returnsCursor()) { result = executeForCursor(sqlSession, args); } else { Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) { result = Optional.ofNullable(result); } } break; case FLUSH: // 利用sqlSession进行数据库flush操作(什么操作暂时不清楚) result = sqlSession.flushStatements(); break; default: throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName()); } if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) { throw new BindingException(&quot;Mapper method '&quot; + command.getName() + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;); } return result;} 到这里，我们就可以证明调用Mapper接口的方法，本质上就是在调用SqlSession的增删改查方法，而SqlSession的增删改查方法，本质上就是在调用Excutor的增删改查方法(前面在创建SqlSession对象中已经说了，SqlSession对象内部有一个Excutor对象)这个我们后续。 总结： SqlSession使用getMapper方法创建了一个Mapper接口的代理对象，并且把自身传递了进去 调用代理对象的方法本质上是调用了SqlSession的增删改查方法。","link":"/2020/05/29/spring-yu-mybatis-zheng-he-de-yuan-li/"},{"title":"Spring与Mybatis整合的原理(二)","text":"上一篇我们讨论到在单纯使用Mybatis的情况下，我们通过SqlSession的getMapper方法来获取Mapper接口的代理对象(每次调用getMapper就会新创建一个代理对象出来)，同时将SqlSession对象传入到Mapper代理对象中，调用代理对象的方法本质就是在调用SqlSession的增删改查方法。并且，每个DefaultSqlSession对象都对应于一个数据库连接(一个数据库事务)，这样我们不禁想到，在Spring整合Mybatis时，我们向Spring容器中注入的是Mapper接口的单例代理对象，在多线程的环境下，Mapper对象被同时调用，那么SqlSession是否是单例的呢(显然不是)？接下来让我们来看看Spring与Mybatis是如何整合的。 如何获得Mapper代理对象1. 注册Mapper扫描的组件在单纯使用Mybatis时获取代理对象非常简单，直接调用SqlSession的getMapper即可，对于Spring-Mybatis而言，使用者无需获取SqlSession对象，更不需要调用getMapper方法来获取Mapper代理对象，只需要添加@Mapper或者@MapperScan注解即可在Spring容器启动时直接向容器中注入Mapper接口的代理对象。我们可以看看@MapperScan注解： 123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class)@Repeatable(MapperScans.class)public @interface MapperScan { 熟悉Spring的同学就会知道，MapperScan注解的引入会使用@Import来向容器中注册MapperScannerRegistrar组件 123456789101112public class MapperScannerRegistrar implements ImportBeanDefinitionRegistrar, ResourceLoaderAware { @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) { // importingClassMetadata是Import标注的类元信息，就MapperScan的元信息 AnnotationAttributes mapperScanAttrs = AnnotationAttributes .fromMap(importingClassMetadata.getAnnotationAttributes(MapperScan.class.getName())); // 获取到MapperScan注解的属性 if (mapperScanAttrs != null) { registerBeanDefinitions(importingClassMetadata, mapperScanAttrs, registry, generateBaseBeanName(importingClassMetadata, 0)); } }} MapperScannerRegistrar实现了ImportBeanDefinitionRegistrar接口，实现了该接口的类可以在Spring启动时调用registerBeanDefinitions方法向容器中修改或添加BeanDefinition，Spring在创建Bean对象时就会根据所有的BeanDefinition来创建Bean。 在这个类中向容器中注册Bedefinition的关键语句如下： 12345// 创建一个BeanDefinition的BuilderBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(MapperScannerConfigurer.class);// 省略(向Builder中添加一些属性)...// 通过Builder获取BeanDefinition，并将registry.registerBeanDefinition(beanName, builder.getBeanDefinition()); 由于代码比较长，都是向BeanDefinition中添加一些属性因此省略掉了，我们通过上面的两行代码就可以看到向容器中注入MapperScannerConfigurer类的BeanDefinition。 MapperScannerConfigurer是一个重要的类，用于配置Mapper接口扫描，并且进行Mapper接口扫描，其的定义如下： 12public class MapperScannerConfigurer implements BeanDefinitionRegistryPostProcessor, InitializingBean, ApplicationContextAware, BeanNameAware { 这个类实现了很多接口,我们主要需要关注的是BeanDefinitionRegistryPostProcessor，在Spring中, 实现了该接口的类会在BeanDefinition都注册完成后调用postProcessBeanDefinitionRegistry方法，可以用于修改Bean的定义信息。因此我们来看看该方法： 1234567891011121314151617181920212223242526272829// class MapperScannerConfigurer@Overridepublic void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) { // 初始化一些属性 if (this.processPropertyPlaceHolders) { processPropertyPlaceHolders(); } // 包扫描器，mybatis继承Spring的包扫描器 ClassPathMapperScanner scanner = new ClassPathMapperScanner(registry); // 初始化一些成员变量 scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.setMapperFactoryBeanClass(this.mapperFactoryBeanClass); if (StringUtils.hasText(lazyInitialization)) { scanner.setLazyInitialization(Boolean.valueOf(lazyInitialization)); } scanner.registerFilters(); // 执行扫描 scanner.scan( StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS));} Mybatis使用了Spring提供的扫描类，加上了自己需要的一些属性来对MapperScan中列出的包进行扫描，在最后一步执行扫描中完成了Mybatis的FactoryBean注入，该FactoryBean用来生成Mapper的代理对象，我们接下来看看为什么要注入FactoryBean呢？ 2 创建对应的FactoryBean首先，我们先不去看Spring-Mybatis的源码，学过Spring的都知道Spring可以通过FactoryBean的方式来注入组件，当Spring开始创建Bean对象的时，如果遇到FactoryBean接口的实现类，便会调用FactoryBean的getObject()来创建Bean对象，因此Spring容器中注入的实际是getObject()返回的对象的Bean对象。 提到这，我们自然而然可以想到当我们扫描到所有的Mapper接口，我们可以通过FactoryBean的方式来向容器中注入一个Mapper的代理对象，确实，Mybatis与Spring整合就是这么做的，现在让我们来看看源码是如何完成这一操作的。 我们进入scan()方法，主要就是执行了doScan()方法，它的第一先用Spring的包扫描功能扫描的所有的Mapper接口封装为BeanDefinition，然后该方法调用了processBeanDefinitions，将Mapper接口的BeanDefinition偷梁换柱变成FactoryBean： 123456789101112131415161718192021222324// class ClassPathMapperScannerprivate void processBeanDefinitions(Set&lt;BeanDefinitionHolder&gt; beanDefinitions) { // 传入的beanDefinitions就是所有Mapper接口的BeanDefinition GenericBeanDefinition definition; for (BeanDefinitionHolder holder : beanDefinitions) { definition = (GenericBeanDefinition) holder.getBeanDefinition(); // 获取每个BeanDefinition所对应的Mapper接口的接口名 String beanClassName = definition.getBeanClassName(); LOGGER.debug(() -&gt; &quot;Creating MapperFactoryBean with name '&quot; + holder.getBeanName() + &quot;' and '&quot; + beanClassName + &quot;' mapperInterface&quot;); // the mapper interface is the original class of the bean // but, the actual class of the bean is MapperFactoryBean // 以下两句就是将BeanDefinition的类型修改为MapperFactoryBean并把接口的类型传入了MapperFactoryBean中。 // &lt;1&gt;获取带参数的构造函数，并把Mapper接口的接口名传入(这里是不需要管Bean的类型就可以直接指定) definition.getConstructorArgumentValues().addGenericArgumentValue(beanClassName); // issue #59 // &lt;2&gt;将这个BeanDefinition的类型修改为MapperFactoryBean类型(mapperFactoryBeanClass = MapperFactoryBean.class) definition.setBeanClass(this.mapperFactoryBeanClass); definition.getPropertyValues().add(&quot;addToConfig&quot;, this.addToConfig); // 将代理对象的一些属性设置进去(例如SqlSession的类型等，省略) } 上面代码的核心部分就是&lt;1&gt;&lt;2&gt;两处，将扫描的所有Mapper接口的BeanDefinition都更改为了MapperFactoryBean类型，这样，Spring容器在创建Bean对象时就会调用getObject()方法来返回我们想要的对象(即Mapper接口的代理对象)。我们可以看看MapperFactoryBean的getObject方法： 1234@Overridepublic T getObject() throws Exception { return getSqlSession().getMapper(this.mapperInterface);} 我们终于看到了熟悉的代码，利用SqlSession来获取Mapper接口的代理对象。这样一来我们就知道了Mybatis-Spring在Spring容器初始化时如何注入Mapper接口的代理对象。但是我们仍然有一个疑问：Mapper代理对象在Spring中是单例的，我们看到Mapper代理对象是在Spring容器初始化时通过SqlSession注入的，联系我们前面单纯使用Mybatis时，一个SqlSession对应一个数据库连接，那么岂不是在多线程环境下我们一直都是使用同一个数据库连接，这怎么合理呢？可以肯定的是，Mybatis-Spring在多线程下当然使用的不是同一个数据库连接，接下来我们来看看Mybatis-Spring是怎么做到的吧。 Mybatis-Spring中的SqlSession我们上面看到了Mapper代理对象是通过getSqlSession().getMapper(this.mapperInterface)来获取的，那么我们查看一下getSqlSession()，发现其返回的是SqlSessionTemplate类型，这好像与我们单纯使用Mybatis时的SqlSession类型DefaultSqlSession不一样，SqlSessionTemplate就是Mybatis-Spring获取不同数据库连接的关键所在，我们跟踪到SqlSessionTemplate的构造函数： 1234567891011121314// class SqlSessionTemplatepublic SqlSessionTemplate(SqlSessionFactory sqlSessionFactory, ExecutorType executorType, PersistenceExceptionTranslator exceptionTranslator) { notNull(sqlSessionFactory, &quot;Property 'sqlSessionFactory' is required&quot;); notNull(executorType, &quot;Property 'executorType' is required&quot;); this.sqlSessionFactory = sqlSessionFactory; this.executorType = executorType; this.exceptionTranslator = exceptionTranslator; // 创建SqlSession的代理对象 this.sqlSessionProxy = (SqlSession) newProxyInstance(SqlSessionFactory.class.getClassLoader(), new Class[] { SqlSession.class }, new SqlSessionInterceptor());} 看到这里，原来SqlSessionTemplate中有一个SqlSession的代理对象，我们查看SqlSessionTemplate中的selectOne等操作数据库的方法也可以发现其实都是在调用SqlSession代理对象的操作数据库方法。这样我们应该继续跟踪SqlSessionInterceptor的invoke方法： 1234567891011121314151617181920212223242526272829303132333435// class SqlSessionTemplate$SqlSessionInterceptor@Overridepublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 获取一个新的SqlSession SqlSession sqlSession = getSqlSession(SqlSessionTemplate.this.sqlSessionFactory, SqlSessionTemplate.this.executorType, SqlSessionTemplate.this.exceptionTranslator); try { // 利用这个新的SqlSession来执行对应的数据库操作 Object result = method.invoke(sqlSession, args); if (!isSqlSessionTransactional(sqlSession, SqlSessionTemplate.this.sqlSessionFactory)) { // force commit even on non-dirty sessions because some databases require // a commit/rollback before calling close() sqlSession.commit(true); } return result; } catch (Throwable t) { Throwable unwrapped = unwrapThrowable(t); if (SqlSessionTemplate.this.exceptionTranslator != null &amp;&amp; unwrapped instanceof PersistenceException) { // release the connection to avoid a deadlock if the translator is no loaded. See issue #22 closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); sqlSession = null; Throwable translated = SqlSessionTemplate.this.exceptionTranslator .translateExceptionIfPossible((PersistenceException) unwrapped); if (translated != null) { unwrapped = translated; } } throw unwrapped; } finally { if (sqlSession != null) { // 关闭SqlSession closeSqlSession(sqlSession, SqlSessionTemplate.this.sqlSessionFactory); } }} 看过这个方法后就真相大白了，原来：Spring容器中的Mapper代理对象是通过SqlSessionTemplate获取的单例对象，而SqlSessionTemplate内部保存了一个SqlSession的代理对象，当Mapper对象执行数据库操作的方法时，还是与Mybatis原来一样去调用Mapper内部保存的SqlSession对象的对数据库增删改查的方法，只不过在与Spring整合后，Mapper代理对象中的SqlSession类型为SqlSessionTemplate。每次调用SqlSessionTemplate的操作数据库的方法都是调用其内部的SqlSession的代理对象的相同方法，而这个代理对象的方法每次都会先从重新生成一个DefaultSqlSession对象来执行数据库操作。这样一来就做到了SqlSession与Mapper代理对象的解耦，每次调用方法都是不同的SqlSession对象。","link":"/2020/06/02/spring-yu-mybatis-zheng-he-yuan-li-er/"},{"title":"Redis集群原理","text":"当需数据量巨大时，并发量高时，单个数据库的压力巨大，通常采用数据库分库分表的方式，同样redis提供了集群功能来实现数据分库存储，采用多台服务器来分担压力，避免单机压力过大造成宕机等故障。 1 Hash算法hash算法是利用操作key的hash值来计算该key位于哪个集群节点上，例如现在有N个redis集群，那么我们可以通过公式计算出该key位于的节点为： node=hash(key)%N 这种算法较为简单，通常如果每次都是两倍扩容的话，我们不需要全部数据进行迁移，只需要迁移50%左右的数据。但是该方式难以自由扩容，尤其是遇到在某个节点发生故障时，都会造成数据索引全被打乱，需要进行大量地数据迁移，重新映射数据与计算机节点的关系。 2 一致性Hash分区一致性Hash分区算法采用的是hash环，它对服务器节点也进行了hash并映射在hash环上，hash后对2^32取模，这样四个服务器节点也被映射在Hash环上(分布尽可能均匀)，这样一来，在进行查询或者添加key时，同样对key进行hash然后对2^32取模映射到Hash环上，该key存储在按顺时针方向到达的Hash环上第一个节点。 例如key1通过hash取模被映射在了node1与node2之间，顺时针第一个节点为node2，那么key1就存储在node2上 删除节点 当节点node3被删除后，这样key2,key3,key4,key5都将被迁移都node4去，这样一来会造成node4压力过大。 虚拟节点 上述环形哈希的缺点在于难以将所有的服务器节点均匀地分布在哈希环上造成单个节点压力过大，出现数据倾斜现象，因此就提出了虚拟节点的方式来尽量均匀地在哈希环上分配节点，就是将真实节点计算多个哈希形成多个虚拟节点并放置到哈希环上，定位算法不变，只是多了一步虚拟节点到真实节点映射的过程。 下图为添加虚拟节点后的哈希环： 当节点4挂掉后，key1, key2和key3会打到节点2的虚拟节点上(也就是存在节点2服务器上)，这样就不会造成服务器单点压力过大(每台服务器的虚拟节点可以更多，这样能是的节点在哈希环上分布更均匀)： 3 哈希槽哈希槽是redis采用的集群数据分布的方式，redis中有16384个槽，一个槽对应了一小部分空间(并不是一个key)，槽由所有的redis集群节点所分担。当客户端请求一个key时： 先打在任意一个节点上(下图假设先打在节点A上) 通过CRC16算法来计算key的哈希值 用hash值对16384取余来求取该key存储在哪个集群节点上，由于每个节点都保存了所有的哈希槽都被分配到了哪个节点上，因此直接去访问计算出来的节点即可。例如下图，请求首先打在A节点上，计算出key所处的节点应该为D节点，那么直接将请求转发到节点D上，保证最多两次命中。 增加节点与删除节点 当redis集群需要添加节点时，就会从现有的所有集群节点中各取一部分放入槽放入新的节点中(数据迁移+槽分配表更新)。","link":"/2020/05/24/redis-ji-qun/"},{"title":"CAS之LongAdder","text":"从JDK1.8开始，有提供了针对Long类型的原子累加器，为LongAdder与LongAccumulator，也针对Double类型的原子累加器，为DoubleAdder与DoubleAccumulator。jdk底层对DoubleAdder的实现是基于LongAdder的，因为两者都是占2个字节的变量。在此就以LongAdder为例。 为什么要有LongAdder？AtomicLong在高并发竞争激烈时，由于大量的线程需要不断进行CAS重试，占用CPU的计算资源，其并发性能收到较大的影响。LongAdder针对高并发场景做出了优化。 性能测试比较： 开启10个线程，每个线程对同一个long进行相加100000次，分别使用AtomicLong和LongAdder测试执行时间。 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) { AtomicLong lg = new AtomicLong(0); LongAdder adder = new LongAdder(); System.out.println(multiThreadTest(() -&gt; lg, (l) -&gt; l.incrementAndGet(), 100)); System.out.println(multiThreadTest(() -&gt; adder, (l) -&gt; l.add(1), 100)); System.out.println(lg); System.out.println(adder);}public static &lt;T&gt; Long multiThreadTest(Supplier&lt;T&gt; supplier, Consumer&lt;T&gt; consumer, int nthreads) { T supply = supplier.get(); ArrayList&lt;Thread&gt; threads = new ArrayList&lt;&gt;(nthreads); for (int i = 0; i &lt; nthreads; i++) { threads.add(new Thread(()-&gt;{ for (int j = 0; j &lt; 100000; j++) { consumer.accept(supply); } })); } Long lastTime = System.currentTimeMillis(); threads.forEach((t)-&gt;t.start()); threads.forEach((t)-&gt; { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); return System.currentTimeMillis() - lastTime;} 输出： 1234207241000000010000000 我们可以看出两个测试最后都输出10000000，线程是安全的，但是100个线程对long累加100000次，在效率上AtomicLong比LongAdder慢几倍到10倍之多。 基本原理LongAdder把一个变量拆分为多份，即把一个Long类型的变量拆分为一个Long类型的base与多个Cell，每个Cell内部也维护了一个Long类型的变量，当多个线程进行并发累加时，如果并发度底，就直接加到base上，如果并发度高，就会将加法操作分摊到Cell数组上，最后取值的时候只要base与这些Cell相加即可。 LongAdder的几个关键域： 123456789101112131415/** * Table of cells. When non-null, size is a power of 2. */transient volatile Cell[] cells; // 对应上图的各个Cell对象，一开始没有，懒加载/** * Base value, used mainly when there is no contention, but also as * a fallback during table initialization races. Updated via CAS. */transient volatile long base; // 对应上图的base/** * Spinlock (locked via CAS) used when resizing and/or creating Cells. */transient volatile int cellsBusy; // 在对cells数组进行扩容或创建时置为1，没有则为0，相当于锁 从LongAdder的sum()方法可以看出： 1234567891011public long sum() { Cell[] as = cells; Cell a; long sum = base; if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum;} 在这里我们可以看到对base变量以及各个Cell变量进行累加，当我们要获取LongAdder的值时，它便会进行累加返回结果。需要注意的是，在这里进行读取每个Cell进行累加时，并没有进行加锁的操作，这也意味着LongAdder不是强一致性，而是最终一致性。另外，base变量以及Cell中的long类型变量必须用volatile修饰，一是为了保证被修改了一定可见，二是保证long类型的写入和读取是原子的(volatile可以保证long、double类型读写操作的原子性)。 因此我们也可以看出LongAdder与AtomicLong的使用场景不同，AtomicLong适用与需要严格同步的场景，而LongAdder适合高并发修改但不需要严格同步的场景。 下面来看看LongAdder的核心方法add(long x)： 12345678910public void add(long x) { Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) { // 首先对base进行CAS修改，成功就直接返回 boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) // 取一个Cell数组中的cell进行修改，成功则返回 longAccumulate(x, null, uncontended); }} 11行的if是进行对base变量的CAS修改，如果成功的话直接返回，因为已经修改成功。注意如果创建了Cell[]数组的话就不对base进行CAS了，直接到执行if里面的代码(cells为成员变量) 5~7行主要的逻辑为： 无法取到Cell对象：Cell[]数组为空，或数组没有元素，或者选取到的数组对应索引的Cell对象没有创建就执行if中的代码，getProbe()为获取一个int数字，这个数字与线程的是相关的，同一个线程获取的数字每次都是相同的，Cell[]数组的长度为2的幂次方，因此与m进行与操作就是对m取余 能取到Cell对象：进行CAS修改操作，如果成功直接返回，失败就继续执行if代码块 longAccumulate()： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) { int h; if ((h = getProbe()) == 0) { ThreadLocalRandom.current(); // force initialization h = getProbe(); // getProbe()是获取一个与当前线程有关的一个int变量，如果没有改变每次获取都是一样的 wasUncontended = true; } boolean collide = false; // True if last slot nonempty // 死循环进行CAS操作直到成功 for (;;) { Cell[] as; Cell a; int n; long v; if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) { // Cell[]数组中有元素 if ((a = as[(n - 1) &amp; h]) == null) { // 取到数组上的索引对应的元素为空 if (cellsBusy == 0) { // cellsBusy表示是否正在创建新的Cell赋给Cell[]数组，0代表没有，1代表正在创建 Cell r = new Cell(x); // Optimistically create if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { // 创建Cell将要赋给Cell[]数组利用CAS将cellsBusy置为1 boolean created = false; try { // Recheck under lock Cell[] rs; int m, j; if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) { // 将新new出来的Cell赋给Cell[]数组 rs[j] = r; created = true; } } finally { cellsBusy = 0; // 解除标志位，可以看作锁 } if (created) break; // 如果创建好了，r新添加进去就为x，累加成功，直接返回即可 continue; // Slot is now non-empty } } collide = false; } else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; else if (n &gt;= NCPU || cells != as) collide = false; // At max size or stale else if (!collide) collide = true; else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { try { if (cells == as) { // Expand table unless stale Cell[] rs = new Cell[n &lt;&lt; 1]; for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; } } finally { cellsBusy = 0; } collide = false; continue; // Retry with expanded table } h = advanceProbe(h); // 修改与线程相关的int使得下一次能够换一个累加单元进行累加 } else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) { // 检查是否正在被创建或者已经创建好了然后加锁 boolean init = false; try { // Initialize table if (cells == as) { // 加锁后进行检查cells是否已经创建好了 Cell[] rs = new Cell[2]; // 创建一个Cell数组 rs[h &amp; 1] = new Cell(x); // 创建一个Cell并赋值为此次的累加值x cells = rs; init = true; } } finally { cellsBusy = 0; } if (init) break; // 已经创建了一个累加单元值为x，相当于已经累加了 } // cells数组正在被创建，此线程不能再去创建，就对base进行一次CAS，成功便可直接返回 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // Fall back on using base }} 在for循环中，第一层主要有3个if-else 123if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) {...} // cells数组已经被创建else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) {...} // cells数组还未被创建且未在被其他线程创建else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) {...} // 其他线程正在创建cells数组 cells数组未被创建的情况(63~80行)： 这里面主要是创建cells数组，用cellsBusy作为锁来防止多个线程同时创建 cell数组已经被创建的情况(14~62行)： 在这种情况下主要是已经有了cells数组，要在线程对应的累加单元上进行累加，我们一开始创建了cells数组，但是没有对cells数组中每个Cell进行初始化，所以当从数组中取到一个Cell想要累加时该Cell可能为空，因此我们需要初始化这个Cell(对应图中蓝色的框，具体逻辑见后面的图)。我们先来看对应位置处的Cell不为空的情况。 Cell不为空的情况： 如果对应的Cell不为空，那首先会尝试对这个Cell进行CAS来累加（40~42行），如果成功了就可以直接返回了 如果CAS累加失败，就需要进行扩容（2倍扩容），扩容后直接进入下一次循环，能够扩容的条件为： 数组的长度没有超过规定的上限NCPU（43行），NCPU与CPU数相关，一般等于CPU个数，因为我们知道CAS不断重试，最好不超过CPU数 数组没有正在被修改然后加锁成功（47行） 如果不能扩容，就改变与线程绑定的int值（61行），就是h变量，h变量发生改变，下次进入循环获得的数组索引就会发生变化，换一个累加单元进行累加。上面扩容后再进入循环也能更换一个累加单元，所以直接进入循环不需要改变h。 下面我们来看取到的Cell对象为空的情况，对应上图中蓝色的方框： 主要就是创建一个新的Cell对象放到索引位置，创建后放置需要对cells数组进行加锁 缓存行优化在Cell类的定义中，使用了一个@sun.misc.Contended的注解，该注解是JDK8之后引入的，用于CPU的缓存行优化。 缓存行的介绍 在介绍volatile时我们讲过CPU缓存架构，这里不再详细介绍。每个CPU都有L3级缓存，CPU的每个核都有L1，L2级缓存，主内存中的数据在进入CPU进行计算前会将数据拷贝到缓存中来进行缓存，但是CPU在拷贝数据进行缓存时，不会只单独拷贝那一份需要用到的数据，因为而是每次都会拷贝固定大小的内存数据进入缓存中，这个固定大小的缓存数据称为缓存行。 缓存行会包括需要的数据在内再加上相邻的数据组成固定大小的缓存行，这是由于我们再用到某个数据时，大概率后续还会用到其相邻的数据(例如数组)，因此设置一定的缓存行大小避免每次需要数据都必须去内存中又进行一次拷贝，但是缓存行的大小又不能太大，因为我们只是“大概率”会用到相邻的数据，本来缓存的大小就有限制，缓存行过大会导致拷贝太多暂时无用的数据进入缓存。在64位的x86系统中，缓存行的大小为64个字节，这是一个经验的取值。 如上图所示，主内存中有变量X，Y，Z连续排列（假设三个都是Long类型），那么当Core-1需要用到Y变量时，X，Y，Z极有可能存在于同一个缓存行中被加载到缓存当中，然后一起进入Core-1的缓存。而Core-2需要X变量，那么这个缓存行会被加载Core-2的缓存中。如果此时Core-1修改了数据Y，会导致整个缓存行(X,Y,Z)都失效，也就会往总线上发送消息，并将新的修改后的数据写回到主内存中，并通知Core-2对应的(X,Y,Z)缓存行失效，Core-2将重新从主内存中读取该缓存行。缓存行是各级缓存与内存数据交换的基本单位，无法只使得Y失效，要失效就整个缓存行失效，会导致X和Z也失效。 @sun.misc.Contended的作用 有了上面缓存行的概念，我们可以看出LongAdder中存在的优化空间，由于在高并发环境下，LongAdder的累加通过Cell[]数组来进行实现，那么也就是说并发环境下，同时会有多个线程修改Cell[]数组不同的索引处的值，对于数组而言占用的是连续的存储空间，那么同一时刻它们在缓存中可能是这样的： 如上图所示假设Cell[]数组的长度为8，加载到缓存中时，前三个元素在同一个缓存行1中，后5个元素在同一个缓存行2中，那么并发环境下Core-1正在修改了第一个元素，Core-2正在修改 第二个元素，Core-3正在修改第3个元素，Core-1修改成功后会导致缓存行1失效，那么Core-2和Core-3基于缓存一致性协议需要从内存中重新加载该缓存行数据，Core-2修改成功后Core-1和Core-3需要从内存中重新加载该缓存行，这样的效率是比较低的。 @sun.misc.Contended主要是用Long去填充每个Cell，加入每个Cell都有8个Long类型的数据(只有一个Long是用于记录数据的)，那么每个相邻两个Cell不会位于同一个缓存行中（这并不代表每个Cell就是一个缓存行），这样Cell数据被修改不会影响其他其他Cell所在的缓存行，就不需要从内存中重新加载缓存行。 在著名的开源无锁并发框架Disruptor中，有类似的行为： 123abstract class RingBufferPad { protected long p1, p2, p3, p4, p5, p6, p7; // 填充7个long型数据} @sun.misc.Contended在JDK8中被引入就是实现了上述的功能，使得某个类的大小占用8字节，使得该类的数组对象可以每个对象都不位于同一个缓存行中来避免并发修改数组时，缓存失效导致CPU需进行重新加载。","link":"/2020/09/17/CAS%E4%B9%8BLongAdder/"},{"title":"Java并发-volatile","text":"volatile在多线程编程中是使用非常之多的一个关键字，对内存的可见性与指令的有序性加以控制，它是保证多线程工作安全、可控的一把利器。 Java内存模型(JMM)JMM 即 Java Memory Model，它在Java的层面定义了主存、工作内存抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存等。 (1) 现代CPU与内存的主要架构 既然JMM是对底层硬件的抽象，我们首先来看看现代CPU与内存的主要架构。现代CPU(以x86为例)大多为多核心CPU，如下图所示： CPU具有L1、L2、L3级的缓存，其中L1和L2级缓存是在每个核心中都存在的，而L3级缓存则是一个CPU所有核心共享的. 缓存的主要功能是将主内存的数据加载进来供计算单元使用，这样在一些数据需要多次使用时不需要每次都从主存中加载，执行效率更高。 对于不同CPU的L1和L2级缓存以公有的L3缓存与主内存，它们之间存在着缓存一致性协议（例如MESI，Intel架构下的缓存一致性协议），所以它们之间的数据是同步的，即如果存储在Core-1的L1缓存中的某个数据发生了变化，如果该数据在Core-2的L2级缓存中存在，那么L2中的该数据就会失效，需要重新从主内存中加载。 但是缓存一致性协议对性能有较大的的损耗，因此CPU的设计者在每个CPU的核心上又添加了各种缓存Buffer（例如Load Buffer、Store Buffer等），这些Buffer与其他的缓存或内存是没有一致性协议的，因此可能存在一个数据在Buffer中被修改而其他的核心都无法感知到。 (2) 操作系统层面的内存模型 对于操作系统而言，既然L1、L2、L3缓存与主内存之间都是有一致性协议，那么统一看待即可，然后将每个核心看成独立的逻辑CPU，每个CPU都有自己独立的缓存（对应于Buffer），这些缓存之间没有一致性协议。 (3) Java内存模型 在Java的层面，是没有办法指定某个任务被哪个CPU所执行，只能指定某个线程来执行任务，结合JVM对内存的划分，因此可以抽象为下面的模型： 所有的变量都存储在主内存中(虚拟机内存的一部分)，对于所有线程都是共享的。 每条线程都有自己的工作内存(对应于CPU的高速缓存)，工作内存中保存的是主存中某些变量的拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。 线程之间无法直接访问对方的工作内存中的变量，线程间变量的传递均需要通过主内存来完成。 原子性volatile关键字并不能起到保证原子性的作用，只有在一种情况下，volatile会对原子性起到作用，那就是64位的long&amp;double类型数据的写入，我们考虑如下代码： 1234567891011public class Example { private long a = 0; public void setA(int i) { a = i; } public int getA() { return a; }} 以上对long类型的a变量读取与写入如果不加锁，在多线程环境下可能是有危险的，因为JVM规范没有规定对long&amp;double类型数据的操作是原子的，所以对double&amp;long类型操作的原子性取决于JVM实现，例如可能对于32位处理器而言，有些JVM的实现写入一个double类型的数据需要两步，那么会造成数据只写了一半就被读走了，或者写了一半又写了。用volatile修饰a变量可以解决这一问题，因为JVM虚拟机规范规定对volatile修饰的long和double操作必须是原子的。 可见性无法退出循环对于可见性，我们先来看下面一种情况：main 线程对 run 变量的修改对于 t 线程不可见，导致了 t 线程无法停止 1234567891011static boolean run = true;public static void main(String[] args) throws InterruptedException { Thread t = new Thread(()-&gt;{ while(run){ // .... } }); t.start(); Thread.sleep(1); run = false; // 线程t不会如预想的停下来} 上面的程序在主线程中将run设置为false后t线程仍然无法停下来的现象，其主要原因是JVM的JIT即时编译器对循环进行了优化。将run变量从主存中拷贝了一份到线程的cpu缓存中，造成run在主线程中被修改了而t1线程不知道的情况。分析过程： (1) 初始状态，t 线程刚开始从主内存读取了 run 的值到工作内存。 (2) 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中，减少对主存中 run 的访问，提高效率。 (3) 1 秒之后，main 线程修改了 run 的值，但是并未马上同步至主存，因而 t 是从自己工作内存中的高速缓存中读取这个变量的值，结果一直是旧值true 解决可见性的办法(1) volatile 使用volatile关键字修饰变量，它可以用来修饰成员变量和静态成员变量(不能修饰局部变量)，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存。 将run变量用volatile修饰后，t线程每次都是从主存中读取run变量，当主线程修改run变量后，t线程就可以结束。 原理： 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存Buffer后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在**缓存的数据写回到系统内(主存)**。 就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，被volatile修饰的数据就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 因此volatile在保证可见性上完成了如下工作： Lock前缀的指令会引起处理器缓存写回内存(不仅volatile修饰的变量，缓存中所有的拷贝变量都会写回主存)； 一个处理器的缓存回写到内存会导致其他处理器的缓存失效； 当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值(同样，是对所有的拷贝变量都刷新)。 这样就能保证每个线程都能获取到volatile修饰的变量的最新值，其实不仅仅是对volatile变量，对于volatile修饰变量写操作之前的变量的写操作同样会被刷新到主存中。 (2) synchronized/ReentrantLock 使用synchronized/ReentrantLock上锁后，上锁的代码块中，变量都是从主存中取的，JVM不会使用JIT将run拷贝到高速缓存中，因此，也能够保证变量的可见性。 volatile对属性对象的可见性​ 由前面的讨论我们可以知道，volatile修饰的成员变量具有可见性，但是上述我们只讨论了成员变量为基本数据类型，现在我们来讨论当成员变量为对象引用时的可见性问题，首先定义两个类： 1234567891011121314151617181920class TaskWrapper { Task task = new Task(); public void end() { task.ending = true; } public boolean isEnding() { return task.ending; } public void change() { task = new Task(); }}class Task { boolean ending = false; String name = &quot;da&quot;;} (1) 改变引用的值 如果我们改变引用指向的对象(引用值发送变化)，那么很容易知道该变化是对所有线程可见的，如下： 123456789101112131415161718192021222324@Slf4jpublic class Volatile { volatile TaskWrapper tsk = new TaskWrapper(); public static void main(String[] args) throws InterruptedException { Volatile vol = new Volatile(); vol.test(); } private void test() throws InterruptedException { Task bk = tsk.task; new Thread(()-&gt;{ while (tsk.task == bk) { } log.debug(&quot;任务结束&quot;); }, &quot;t1&quot;).start(); Thread.sleep(1000); tsk.change(); log.debug(&quot;change&quot;); }} 输出： 12310:37:07.042 com.zl.Visible.Volatile [t1] - 任务开始10:37:08.036 com.zl.Visible.Volatile [main] - change10:37:08.036 com.zl.Visible.Volatile [t1] - 任务结束 ​ 如何tsk没有用volatile修饰，则t1线程无法感知到tsk的task引用发送变化，则任务无法马上结束。 (2) 改变引用对象的非volatile属性 ​ volatile可以保证被修饰变量的可见性，但是如果被volatile修饰的引用的对象的属性发生了变化，例如上面程序中的TaskWrapper中的task引用，引用地址发送变化是可见的，但是task引用的对象的ending属性发生改变是否是可见的呢，注意ending、task引用均未被volatile修饰。我们测试一下： 12345678910111213141516171819202122232425@Slf4jpublic class Volatile { volatile TaskWrapper tsk = new TaskWrapper(); public static void main(String[] args) throws InterruptedException { Volatile vol = new Volatile(); vol.test(); } private void test() throws InterruptedException { Task bk = tsk.task; new Thread(()-&gt;{ log.debug(&quot;任务开始&quot;); while (!tsk.isEnding()) { } log.debug(&quot;任务结束&quot;); }, &quot;t1&quot;).start(); Thread.sleep(1000); tsk.end(); log.debug(&quot;change&quot;); }} 输出： 12310:49:21.617 com.zl.Visible.Volatile [t1] - 任务开始10:49:22.602 com.zl.Visible.Volatile [main] - change10:49:22.602 com.zl.Visible.Volatile [t1] - 任务结束 我们从结果可以看到，task引用对象发生的改变仍然是可见的，如果TaskWrapper tsk未用volatile修饰则程序不会结束。不过这一结论我无法肯定，因为在JDK提供的ConcurrentHashMap中，对链表数组使用了volatile修饰，但是对链表节点的属性也使用了volatile修饰。 因此在遇到这样的情况时，为了保险起见，还是都加上volatile修饰比较保险。 有序性由于现代CPU在执行指令时都采用流水线工作模式，会造成指令交错的问题。首先来了解什么是流水线工作。 流水线工作模式所有的程序最终都会被翻译成机器指令(二进制)，从而被cpu所执行。而cpu执行每条指令又分为几个小步骤，例如Intel的i486处理器分为五个步骤：取指(Fetch)，译码(D1, main decode)，转址(D2, translate)，执行(EX, execute)，写回(WB)，因此被称为5级流水线。 cpu完成这些动作都分别使用一个硬件单元或寄存器，为了提供指令的并行度，例如在对第一条指令取指后马上可以对第二条指令取值，而此时第一条指令可能进入了译码阶段。这样一来可以不用等到第一条指令执行结束第二条指令才开始取指，虽然执行单条指令的速度并不会变快，但是单位时间内执行的指令数变多。 流水线工作模式如下： 流水线工作模式虽然不能缩短单条指令的执行时间，能够极大的提高指令执行的吞吐量，但是并不是所有情况下都能这么完美地进行流水线工作。对于下面的指令代码，它们的功能是将两个变量的内容进行交换，就不能完美地按照流水线式工作。 123XOR a, bXOR b, aXOR a, b 第一步是第一条指令进入取指阶段； 第二步第一条指令进入译码阶段，同时第二条指令进入取指阶段； 第三步第一条指令进入转址阶段，第二条指令进入译码阶段，第三条指令进入取指阶段。 第四步会出现问题，第一条指令会进入执行阶段，而其他指令却不能继续向前移动。第二条 xor 指令需要第一条 xor 指令计算的结果a，但是直到第一条指令执行完成才会写回。所以流水线的其他指令就会在当前流水级等待直到第一条指令的执行和写回阶段完成。第二条指令会等待第一条指令完成才能进入流水线下一级，同样第三条指令也要等待第二条指令完成。 这个现象被称为流水线阻塞或者流水线气泡，即后面的指令必须等到前面的指令执行完才能继续执行步骤，而不是像之前那样完美地实现流水线式的工作模式，因此CPU可能会对指令进行重排序，如果重新排序后的指令对最后结果没有影响，那么会将不相干的几条指令连续排列以达到完美地流水线式的工作，CPU级别的重排序我们暂先不关注，主要是JVM对指令重排序也会基于上面的原因进行优化。 JVM指令重排大多数现代微处理器都会采用将指令乱序执行（out-of-order execution，简称OoOE或OOE）的方法，在条件允许的情况下，直接运行当前有能力立即执行的后续指令，避开获取下一条指令所需数据时造成的等待。通过乱序执行的技术，处理器可以大大提高执行效率。除了处理器，常见的Java运行时环境的JIT编译器也会做指令重排序操作，即生成的机器指令与字节码指令顺序不一致。 如果前后指令有数据依赖性，那么指令顺序是不会交换的 1234名称 代码示例 说明 写后读 a = 1;b = a; 写一个变量之后，再读这个位置。 写后写 a = 1;a = 2; 写一个变量之后，再写这个变量。 读后写 a = b;b = 1; 读一个变量之后，再写这个变量。 每组指令中都有写操作，这个写操作的位置是不允许变化的，否则将带来不一样的执行结果。编译器将不会对存在数据依赖性的程序指令进行重排，这里的依赖性仅仅指单线程情况下的数据依赖性；多线程并发情况下，此规则将失效。 多线程下指令重排引发的问题 1234567891011121314class ReorderExample { int a = 0; boolean flag = false; public void writer() { a = 1; // 1 flag = true; // 2 } public void reader() { if (flag) { // 3 int i = a * a; // 4 } }} 在多线程环境下，当使用同样的该对象时，由于语句1和语句2没有数据依赖关系，JVM可能将两者进行重排序，即先执行语句2再执行语句1，那么就会可能出现flag已经为true了但是a仍然为0。当先执行完语句2后，时间片用完而执行reader()函数，那么就会出现i为0的情况。 volatile禁止指令重排volatile关键字可以禁止指令重排，在如上的例子中，我们将flag用volatile修饰，那么就可以防止语句1和语句2的重排序，保证先执行语句1再执行语句2。 volatile禁止重排序是通过内存屏障的方式来实现的。为了进制编译器重排序和CPU重排序，在编译器和CPU层面都有对应的指令，也就是内存屏障。编译器的内存屏障是告诉编译器不要进行进行指令重排序，当编译完成之后，内存屏障就消失了，CPU并不会感知到编译器中的内存屏障，但是这不是我们需要关注的，我们关注于Java提供的volatile能够保证什么样的有序性。 在CPU层面有4种内存屏障（Load表示读，Store表示写）： LoadLoad：禁止读操作与读操作指令发生重排序，即如果指令是load1 LoadLoad load2，那么一定会保证load1不会重排到load2之后。 StoreStore：禁止写操作与写操作指令发生重排序，即如果指令是store1 StoreStore store2，那么一定会保证store1不会重排到store2之后 LoadStore：禁止读操作与写操作指令发生重排序，即如果指令是load LoadStore store，那么一定会保证load不会重排到store之后 StoreLoad：禁止写操作和读操作指令发生重排序，即如果指令是store StoreLoad load，那么一定会保证store不会重排到load之后 如上的禁止重排并不只是指前后一条指令，例如LoadLoad可以禁止其后面的所有写操作重排到前面。 volatile的底层原理是建立如下内存屏障： 在volatile变量的写操作前加入一个StoreStore内存屏障，保证volatile变量的写操作不会和之前的写操作发生重排序。 在volatile变量的写操作后面加入一个StoreLoad内存屏障，保证volatile变量的写操作不会和后续的读操作发生重排序。 在volatile变量的读操作后加入一个LoadLoad+LoadStore内存屏障，保证volatile变量的读操作不会和后续的写操作或读操作发生重排序。 由于这种重排序的情况很难测试出来，因此下面我们使用JCStress压测工具来进行压测以验证指令重排以及volatile的作用。关于JCStress工具的配置参考博客jcstress 高并发测试框架使用教程 1234567891011121314151617181920212223@JCStressTest@Outcome(id={&quot;1&quot;, &quot;2&quot;}, expect = Expect.ACCEPTABLE, desc = &quot;ok&quot;)@Outcome(id = {&quot;0&quot;}, expect = Expect.ACCEPTABLE_INTERESTING, desc = &quot;wrong&quot;)@Statepublic class Seq { int a = 0; boolean flag = false; @Actor public void write(I_Result r) { a = 1; flag = true; } @Actor public void read(I_Result r) { if(flag) { r.r1 = a*a; } else { r.r1 = 2; } }} 经过压力测试有如下结果显示： 该结果表示，经过压力测试有15944211个线程结果为1，有31192483个线程结果为2，而又256个线程的结果为0，这表示当flag为true时，a仍然为0，这是指令重排序导致的结果，flag=true的操作被重排到a=1之前了。 当我们给flag加上volatile修饰，再进行压测则不会出现上述的情况。在这里我个人还有一点疑问，那就是如果用volatile修饰a变量，那么会出现因重排序错误的情况吗？因为volatile只是在写操作之前加入了LoadLoad屏障，而没有在之后加入LoadLoad屏障，那么a=1和flag=true会不会发生重排序。经过压测是不会出现的，我想这个内存屏障应该是跟着变量走的，也就是不会出现： 在这里假设load2操作就是针对volatile变量的，如果Load2要和Load3重排那应该也会变成 这是不符合LoadLoad内存屏障的，因为Load3原本位于Load2之后，重排以后位于LoadLoad内存屏障之前。所以，在volatile变量之前加入LoadLoad内存屏障也可防止volatile写操作与后续的写操作发生重排。 单例懒加载设计模式在设计模式中，通常会用到单例懒加载的设计模式，即在一个应用中只创建一个该类的对象，每次使用的都是同一对象，并且该对象在第一次获取时才创建，未被使用过的类对象不会被创建。 该设计模式通常使用double-checked locking方式，即看如下代码： 12345678910111213141516171819public class Single{ private static Single sobj; private Single(){ } public void static getInstance(){ if(sobj == null){ synchronized(sobj){ if(sobj == null){ sobj = new Single(); } } } return sobj; }} 通过两次判断sobj对象是否为空，才创建该类的对象，两次判断的原因为： 如果采用一次判断，那么每当调用getInstance方法时，都会使用synchronized上锁，我们只有在创建对象时需要上锁，而当创建好对象后每次获取对象时无需上锁，因此使用两次判断可以解决该问题。 问题 上述的代码看似没有问题，其实其中隐含着问题，我们需要从字节码指令的角度才能看出问题所在 123456789101112131415161718192021220: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;3: ifnonnull 376: ldc #3 // class cn/itcast/n5/Singleton8: dup9: astore_010: monitorenter11: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Single;14: ifnonnull 2717: new #3 // class cn/itcast/n5/Single20: dup21: invokespecial #4 // Method &quot;&lt;init&gt;&quot;:()V24: putstatic #2 // Field INSTANCE:Lcn/itcast/n5/Single;27: aload_028: monitorexit29: goto 3732: astore_133: aload_034: monitorexit35: aload_136: athrow37: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Single;40: areturn 其中第17-27行为创建对象的一系列指令： 17行 new #3为创建一个实例， 20行 dup是拷贝引用， 21行 invokespecial #4为调用构造方法， 24行 putstatic为将对象的引用拷贝给static变量sobj。 然而JVM可能会对这些代码进行重排序，即可能对象引用的拷贝给obj发生在对象调用构造方法之前，这样在多线程的环境下，由于执行了对象引用的拷贝但还没有执行构造函数就切换到其他线程，而在其他线程中，判断sobj不为空，那么就会返回还未调用构造函数的对象，而该对象被使用了。 由于引用拷贝和调用构造函数会发生指令重排，因此当引用不为null时，对象可能还未在t1线程初始化完成，造成其他线程直接就开始使用该对象了，因此存在线程安全的隐患。 发生这一情况的主要原因是synchronized没有保护住全部的sobj对象，sobj在synchronized代码块外部还被使用到，如果一个变量全部位于synchronized代码块中，那么即使重排序也不会影响程序执行的结果。但现在的情况我们不能使用synchronized保护全部的sobj对象，这样会造成性能的损失。 解决 我们可以发现造成该问题的主要原因是指令重排序造成的，我们可以使用volatile禁用sobj的重排序。在给sobj变量加上volatile后，我们可以从字节码的角度看： 123456789101112131415161718192021222324-------------------------------------&gt; 加入对 INSTANCE 变量的读屏障0: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;3: ifnonnull 376: ldc #3 // class cn/itcast/n5/Singleton8: dup9: astore_010: monitorenter -----------------------&gt; 保证原子性、可见性11: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;14: ifnonnull 2717: new #3 // class cn/itcast/n5/Singleton20: dup21: invokespecial #4 // Method &quot;&lt;init&gt;&quot;:()V24: putstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;// -------------------------------------&gt; 加入对 INSTANCE 变量的写屏障27: aload_028: monitorexit ------------------------&gt; 保证原子性、可见性29: goto 3732: astore_133: aload_034: monitorexit35: aload_136: athrow37: getstatic #2 // Field INSTANCE:Lcn/itcast/n5/Singleton;40: areturn 在加入volatile后， 24行的putstatic后加入了写屏障，那么invokespecial就不可能跑到24行之后，不会造成上面的问题了。 final关键字与指令重排final关键字用于定义不可变的对象，当修饰基本数据类型时则数据内容不能发生变化，当修饰对象引用时表示该引用不能更换指向的对象，对于一个类的final域（final修饰的成员变量），final域只能初始化一次，可以在定义成员变量时直接利用=进行初始化，也可以在构造函数中初始化一次。对于final域，编译器和处理器要遵循如下两个指令重排序的规则： 在构造函数对一个final域的写入，与之后把这个被构造的对象的引用赋值给一个引用的变量，这两个操作不能重排序，即在final域的写操作后加入StoreStore内存屏障 两次对final域的读操作不能重排序，即前一次对final域的读操作必须先于后一次对final域的读操作，即在final域的读操作前加上LoadLoad内存屏障 12345678910111213141516171819202122public class Example { int i;//普通变量 final int j; static Example obj; public Example(){ i = 1; j = 2; } public static void writer(){ // 线程A先执行writer obj = new Example(); } public static void reader(){ // 线程B后执行reader() if(obj != null) { Example tets = obj;//读对象引用 int a = tets.i; int b = tets.j; // a,b是否一定为1，2？ } }} 对于如上的例子，如果没有给成员变量j加上final，那么reader()函数中的a和b不一定为1，2，原因与单例模式一样，有可能obj的引用完成了赋值但是构造函数还没有执行完成，但是给j加上了final修饰，则在后面加上了StoreStore内存屏障，那么obj的赋值一定在构造函数执行完之后才能执行，因此a，b的值一定为1，2。 final域为对象引用时 上述讲的是final域的基本类型，如果final域为引用类型，我们知道final域修饰引用变量，变量指向的对象实例不能变化，但是final引用指向的对象的内容可以变化，上面提到final域修饰的基本类型的写操作不会被重排序到构造函数之外，所以引用的赋值肯定在构造函数结束前就赋值好了，如下： 12345678910111213141516171819202122232425public class FinalReferenceTest { final int[] arrs;//final引用 static FinalReferenceTest obj; public FinalReferenceTest(){ arrs = new int[1];//1 arrs[0] = 1;//2 } public static void write0(){//A线程先执行 obj = new FinalReferenceTest();//3 } public static void write1(){//线程B obj.arrs[0] = 2;//4 } public static void reader(){//C线程 if(obj!=null){//5 int temp =obj.arrs[0];//6 } }} 上面的例子，构造函数结束时arrs引用肯定已经赋值完成，问题时arrs[0]=1这句会不会被重排序到构造函数之外，由于arrs被final修饰，arrs[0]=1不会被重排序到构造函数之外。对于引用类型，写final域的重排序规则对编译器和处理器增加了一下的约束：在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 上图中：1是对final域的写入，2是对这个final域引用的对象的成员域的写入，3是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的1不能和3重排序外，2和3也不能重排序。 JMM可以确保读线程C至少能看到写线程A在构造函数中对final引用对象的成员域的写入。即C至少能看到数组下标0的值为1。而写线程B对数组元素的写入，读线程C可能看得到，也可能看不到。JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。也就是说，就算线程B的操作4先于线程C的操作6执行，也不见得线程B的改写能对线程C时可见的，因为final不能保证可见性，要保证可见性需要用volatile或synchronized等来完成。","link":"/2020/09/11/Java%E5%B9%B6%E5%8F%91-volatile/"},{"title":"NIO","text":"NIO（JDK1.4）模型是一种同步非阻塞IO，主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector（多路复用器）。 1 Buffer1.1 基本使用Buffer的本质就是一个存放数据内存块，可以看成一个容器对象(内部含有数组)，该对象提供了一系列方法，能让我们轻松的使用内存块(数组)，缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态变化情况。 JDK中Buffer的子类如下： 首先，Buffer都具有4个重要属性： 12345// Invariants: mark &lt;= position &lt;= limit &lt;= capacityprivate int mark = -1;private int position = 0;private int limit;private int capacity; Buffer分为读模式和写模式，一次读操作或写操作都可能会导致position后移(可能即为JDK提供了不同的方法，有读操作后position后移的方法，也有读操作后position不后移的方法)： Buffer的使用： 1234567891011121314151617public class LearnBuffer { public static void main(String[] args) { IntBuffer buffer = IntBuffer.allocate(5); // postion=0, capacity=5, limit=5, mark=-1 for (int i = 0; i &lt; buffer.capacity(); i++) { buffer.put(i*2); // 每次put后position属性+1 } buffer.flip(); // 将position重置到0 buffer.position(1); // 将position置为1 buffer.limit(3); // 将limit置为3 while (buffer.hasRemaining()){ System.out.println(buffer.get()); // 每次get()都会导致postion+1 } }} 1.2 HeapBuffer和DirectByteBuffer​ HeapBuffer被称为No-DirectBuffer，这一缓冲区创建在JVM内存的堆区中，受到JVM的内存管理，创建和释放都是由JVM操作的。上面通过allocate方法创建的Buffer就是HeapBuffer。 ​ 利用HeapBuffer读取数据的过程如下： ​ Java程序向操作系统发起read()的系统调用，操作系统让CPU启动DMA来将物理磁盘中的数据读取到内核地址空间中的缓冲区，然后再将缓冲区中的内容拷贝到用户地址空间的Buffer对象中。在这过程中发生了一次从内核地址空间到用户地址空间的拷贝。由于HeapBuffer需要经过一次拷贝，其与BIO的文件操作代价相同，效率相差不多，但下面介绍的DirectByteBuffer效率更高。 ​ 针对如上HeapBuffer的一次拷贝进行优化，DirectByteBuffer是创建在堆外内存区的，即不受JVM的内存管理机制所控制，那么为什么DirectByteBuffer可以减少这一次拷贝呢？ ​ 这要归功于mmap()的系统调用，这种方式的I/O原理就是将用户缓冲区（user buffer）的内存地址和内核缓冲区（kernel buffer）的内存地址做一个映射，也就是说系统将内核地址空间的缓冲区和用户地址空间的缓冲区映射物理内存上的相同位置，这样一来就可避免了从内核空间向地址空间的拷贝消耗。 在HeapBuffer中，内核地址空间的缓冲采用的就是DirectByteBuffer，然后再把DirectBuffer中的数据拷贝到HeapBuffer中。通过跟踪ByteBuffer的源码可以查看到其read()方法调用到了IOUtil的read()方法： 123456789101112131415161718192021static int read(FileDescriptor fd, ByteBuffer dst, long position, NativeDispatcher nd) throws IOException{ if (dst.isReadOnly()) throw new IllegalArgumentException(&quot;Read-only buffer&quot;); if (dst instanceof DirectBuffer) return readIntoNativeBuffer(fd, dst, position, nd); // Substitute a native buffer ByteBuffer bb = Util.getTemporaryDirectBuffer(dst.remaining()); // 获得一个临时的DirectBuffer try { int n = readIntoNativeBuffer(fd, bb, position, nd); // 使用native方法利用DirectBuffer进行读取 bb.flip(); if (n &gt; 0) dst.put(bb); // 将DirectBuffer读取到的数据放入到ByteBuffer中 return n; } finally { Util.offerFirstTemporaryDirectBuffer(bb); }} DirectBuffer可以通过ByteBuffer.allocateDirect(int len)来进行申请。 1ByteBuffer byteBuffer = ByteBuffer.allocateDirect(1024); // 申请出来为DirectByteBuffer对象 1.3 DirectBuffer详解说明 Java中申请的DirectBuffer存在的内存区域究竟是内核地址空间还是用户地址空间呢？ ​ DirectBuffer(以DirectByteBuffer为例)其实分为两部分： 12345 Java | native |DirectByteBuffer | malloc'd[ address ] -+-&gt; [ data ] | 一部分为Java的堆内对象，DirectByteBuffer没有byte数组，但是有一个long address的属性，该属性在Buffer类中有，官方注释说明只用于DirectBuffer才有效： 12345public abstract class Buffer { // Used only by direct buffers // NOTE: hoisted here for speed in JNI GetDirectBufferAddress long address; ​ 另一部分为利用c语言的malloc申请的字节数组，该数据就是缓冲区，该缓冲区是用C语言API申请的，属于该进程，位于用户地址空间，只不过操作系统该部分内存有读写的权利，不需要经过内核地址空间的拷贝。 ​ DirectBuffer的主要缓冲区属于堆外内存，其生命周期不完全被JVM管制，因此使用需要谨慎，必须使用Full GC才能进行回收，但是Full GC的性能损耗很大，因此合理使用DirectBuffer才能有更高的效率，Netty封装了DirectBuffer比DirectBuffer更好用。 为什么DirectBuffer要在堆外申请，不能申请在堆内或者直接使用HeapBuffer进行mmap内存映射吗？ ​ JVM并不是不能直接用java HeapBuffer或java byte[]直接使用mmap映射来做IO读写，但JVM在GC过程中会移动内存，JVM移动内存的操作对操作系统是不可见的，因此必须mark此段内存不能移动，从而影响GC效率，所有采用堆外内存更为合适。 ​ Java利用HeapBuffer进行IO操作时都会使用到临时的DirectByteBuffer缓冲区。 性能说明 ​ 对于文件的读写，使用FileChannel的read或write方法无论传入的是HeapBuffer还是DirectBuffer都是会创建一个临时的DirectBuffer，所以效率是相同的。想要有更高的性能使用MappedByteBuffer就不会进行内核空间到用户空间的拷贝了。 MappedByteBuffer使用： 1234567891011public static void main(String[] args) throws IOException { FileChannel inChannel = FileChannel.open(Paths.get(&quot;pom.xml&quot;), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(&quot;pom2.xml&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); // 读取文件的缓冲空间 MappedByteBuffer mappedByteBuffer = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size()); outChannel.write(mappedByteBuffer); inChannel.close(); outChannel.close();} ​ 由于JDK没有提供直接将DirectBuffer写到文件中的方法，因此还是需要一次拷贝的。 普通NIO文件拷贝： 1234567891011public static void nioFileCopy() throws IOException { FileChannel inChannel = FileChannel.open(Paths.get(&quot;pom.xml&quot;), StandardOpenOption.READ); FileChannel outChannel = FileChannel.open(Paths.get(&quot;pom2.xml&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE); ByteBuffer buf = ByteBuffer.allocate((int) inChannel.size()); buf.flip(); outChannel.write(buf); inChannel.close(); outChannel.close();} ​ 相比MappedByyeBuffer多了一次拷贝。 关于DirectBuffer的释放 DirectBuff的释放利用的虚引用(PhantomReference)来实现的 2 ChannelNIO的通道类似于流，但有些区别如下： 通道可以同时进行读写，而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据，也可以写数据到缓冲 JDK提供的Channel类型有很多，常用的有FileChannel(文件读写通道)、DatagramChannel(UDP数据传输通道)、ServerSocketChannel 和 SocketChannel (ServerSocketChanne 类似 ServerSocket , SocketChannel 类似 Socket，TCPS数据传输)。 FileChannel类： 用于对本地文件的读写操作，主要的方法有： 1234public int read(ByteBuffer dst) //从通道读取数据并放到缓冲区中public int write(ByteBuffer src) //把缓冲区的数据写到通道中public long transferFrom(ReadableByteChannel src, long position, long count) //从目标通道中复制数据到当前通道public long transferTo(long position, long count, WritableByteChannel target) //把数据从当前通道复制给目标通道 实例–使用FileChannel实现文本的拷贝 123456789101112131415161718192021222324252627public class LearnChannel { public static void main(String[] args) throws IOException { // 创建文件对象 File file = new File(&quot;/Users/zhanglei/java/IdeaProjects/netty/src/main/java/com/tomcode/nio/LearnChannel.java&quot;); File target = new File(&quot;j.txt&quot;); // 创建流对象 FileInputStream fileInputStream = new FileInputStream(file); FileOutputStream fileOutputStream = new FileOutputStream(target); // 获取channel，channel需要从流对象中获取，流对象中具有channel属性但是为空，当调用getChannel时会创建channel对象 FileChannel inputChannel = fileInputStream.getChannel(); FileChannel outputChannel = fileOutputStream.getChannel(); // 创建缓冲区 ByteBuffer buffer = ByteBuffer.allocate(512); // 把inputchannel中的数据写到buffer中然后把buffer写到outputchannel int len = -1; while((len = inputChannel.read(buffer)) != -1){ buffer.flip(); outputChannel.write(buffer); buffer.clear(); // 必须clear()，否则postion=limit无法再读入数据，每次len=0陷入死循环 } // 流对象关闭channel就会关闭 fileInputStream.close(); fileOutputStream.close(); }} 同样，我们可以使用transferFrom就可以直接完成拷贝而不需要使用缓冲区了(其实底层也是利用了缓冲区)。 1outputChannel.transferFrom(inputStream); 使用Channel和Buffer的注意事项 ByteBuffer 支持类型化的put 和 get, put放入的是什么数据类型，get就应该使用相应的数据类型来取出，否则可能有BufferUnderflow-Exception 异常。(putInt–getInt，putChar–getChar) NIO 还提供了 MappedByteBuffer， 可以让文件直接在内存（堆外的内存）中进行修改，效率很高。 前面我们讲的读写操作，都是通过一个Buffer 完成的，NIO 还支持 通过多个Buffer (即 Buffer 数组) 完成读写操作，即 Scattering 和 Gathering 3 SelectorSelector选择器，作用是用于管理多个Channel，使用Selector实现IO多路复用，通常一个线程有一个Selector，而一个Selector对应多个Channel负责I/O，其工作的主要步骤： (1) 在服务器启动时，创建ServerSocketChannel并利用SelectionKey register(Selector sel, int ops)方法注册到Selector中，每个channel在一个Selector中对应一个的SelectionKey。 (2) 在循环中调用Selector的int select()方法来判断是Selector中是否有Channel需要处理(返回值为需要处理的channel数量)，注意select()方法是阻塞的，想要非阻塞可以调用select(int timeout)或selectNow()。 (3) 每当一个客户端需要连接服务器时，Selector的select方法会返回1，此时表明有channel发生了事件需要处理，那么就通过Selector的selectKeys()方法获取到所有事件的SelectionKey，可以通过SelectionKey判断其对应的是否为ServerSocketChannel，如果是则调用其accept()方法(不会阻塞，因为已经判断出有客户端要连接)。 (4) 通过ServerSocketChannel的accept方法都能获取到一个SocketChannel，将这个SocketChannel注册到Selector中。 (5) 回到(2)的循环，去判断各个channel是否有事件发生，有的话通过SocketChannel和ServerSocketChannel分开处理，ServerSocketChannel有事件就获取SocketChannel注册到Selector，SocketChannel有时间就读写。 实例–使用Selector来实现服务端： server端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class SelectorLearn { public static void main(String[] args) throws IOException { // 创建ServerSocketChannel ServerSocketChannel server = ServerSocketChannel.open(); server.socket().bind(new InetSocketAddress(8888)); // 创建Selector Selector selector = Selector.open(); // 设置Channel为非阻塞的 server.configureBlocking(false); // 将server注册到selector，为ACCEPT操作，ServerSocketChannel才为该方式 server.register(selector, SelectionKey.OP_ACCEPT); while (true) { if(selector.select(1000) == 0){ // 等待获取200ms，没有事件 System.out.println(&quot;1s没有事件&quot;); continue; } System.out.println(&quot;event!&quot;); // 获取并遍历有事件发生的SelectionKey Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while(iterator.hasNext()){ SelectionKey key = iterator.next(); if(key.isAcceptable()){ // 证明是ServerSocketChannel，获取对应的SocketChannel SocketChannel socket = server.accept(); socket.configureBlocking(false); // 向selector注册socket，为读操作事件(因为建立连接不一定马上有数据传输) socket.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(1024)); } if(key.isReadable()){ // 证明是SocketChannel SocketChannel socket = (SocketChannel) key.channel(); ByteBuffer buf = (ByteBuffer) key.attachment(); socket.read(buf); String content = new String(buf.array()); System.out.println(&quot;收到:&quot; + content); } // 处理必须从集合中移除，否则会重复处理 iterator.remove(); } } }} 说明： 一个Selector可以注册多个Channel，也可以注册不同种类的Channel（SocketChannel/ServerSocketChannel），每个Channel在注册到某个Selector上时会生成一个SelectionKey对象，里面保存了Channel，Selector以后选择的就是SelectionKey对象，SelectionKey与Channel一一对应。 当调用了Selector的selectKeys方法后，如果此时ServerSocketChannel有多个连接请求，在调用accept后也只会连接一个，然后再循环时因为还有连接未处理则ServerSocketChannel还是有事件，接着就可以处理下一个连接。那么还未被accept的连接都会存储在操作系统的一个连接队列中等待应用程序处理。 Selector： 1234567selector.select(); //阻塞selector.select(1000); //阻塞1000毫秒，在1000毫秒后返回selector.wakeup(); //唤醒selectorselector.selectNow(); //不阻塞，立马返还selector.selectedKeys(); // 当前有事件发生的SelectionKeyselector.keys(); // selector中注册的所有SelectionKey SelectionKey： 123456789101112int OP_ACCEPT：有新的网络连接可以 accept，值为 16int OP_CONNECT：代表连接已经建立，值为 8int OP_READ：代表读操作，值为 1 int OP_WRITE：代表写操作，值为 4 public abstract Selector selector(); //得到与之关联的 Selector 对象public abstract SelectableChannel channel(); //得到与之关联的通道public final Object attachment(); //得到与之关联的共享数据public abstract SelectionKey interestOps(int ops); //设置或改变监听事件public final boolean isAcceptable(); //是否可以 acceptpublic final boolean isReadable(); //是否可以读public final boolean isWritable(); //是否可以写 ServerSocketChannel： ServerSocketChannel 在服务器端监听新的客户端 Socket 连接 12345public static ServerSocketChannel open(); // 得到一个 ServerSocketChannel 通道public final ServerSocketChannel bind(SocketAddress local); // 设置服务器端端口号public final SelectableChannel configureBlocking(boolean block); // 设置阻塞或非阻塞模式，取值 false 表示采用非阻塞模式public SocketChannel accept(); // 接受一个连接，返回代表这个连接的通道对象public final SelectionKey register(Selector sel, int ops); // 注册一个选择器并设置监听事件 SocketChannel： SocketChannel，网络 IO 通道，具体负责进行读写操作。NIO 把缓冲区的数据写入通道，或者把通道里的数据读到缓冲区。 12345678public static SocketChannel open();//得到一个 SocketChannel 通道public final SelectableChannel configureBlocking(boolean block);//设置阻塞或非阻塞模式，取值 false 表示采用非阻塞模式public boolean connect(SocketAddress remote);//连接服务器public boolean finishConnect();//如果上面的方法连接失败，接下来就要通过该方法完成连接操作public int write(ByteBuffer src);//往通道里写数据public int read(ByteBuffer dst);//从通道里读数据public final SelectionKey register(Selector sel, int ops, Object att);//注册一个选择器并设置监听事件，最后一个参数可以设置共享数据public final void close();//关闭通道","link":"/2020/08/31/NIO/"},{"title":"Nacos源码-服务注册流程","text":"Nacos一个重要的作用就是用作微服务的注册中心，各个微服务向Nacos注册，并且从Nacos拉取自己所需要的其他微服务，因此学习一下Nacos的服务注册流程。 客户端的服务发现与注册Nacos的服务注册采用的是HTTP请求，通过官网的描述，我们可以直接通过一个Http请求来注册我们的服务： 1curl -X POST 'http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=nacos.naming.serviceName&amp;ip=20.18.7.10&amp;port=8080' 通过一个post请求，我们就可以将服务注册到Nacos上，但是，不推荐直接发起Http请求来注册服务，因为注册服务的过程远远比单纯发起一个HTTP请求复杂，Nacos提供了与服务端交互的客户端，位于源码中的nacos-client模块。在Spring Cloud中，Nacos作为注册模块采用的就是nacos-client ，我们从Spring Cloud中入手来了解Nacos如何在项目启动时完成服务的注册。 SpringCloud只是向外开发了一套自动注册的标准，而自动注册的功能是需要开发者去提供了，Nacos、Eureka等注册中心，都是针对了SpringCloud做了适配，实现自动注册，因此我们的目光不能只放在SpringCloud上了。对于SpringBoot、SpirngCloud而言，都是通过注解实现自动配置，大多数组件的注入都是通过XXXAutoConfiguration来实现，因此我们查找一下是否有关于Nacos的AutoConfiguration，经过搜索，确实有一个叫NacosDiscoveryAutoConfiguration，看到这个名字，我们就可以推断，这个类就是用于Nacos服务发现的自动配置： 通过上面的代码我们可以知道，Nacos自动配置类生效依赖于ServiceRegistryAutoConfiguration和AutoServiceRegistrationAutoConfiguration两个配置类的生效，这两个类都是Spring Cloud提供的，也就是说这两个类是SpringCloud提供的服务发现与注册的标准，只有这两个配置类生效，才允许进行服务注册与发现，只要导入了Spring Cloud依赖，那么这两个类将通过SPI自动注入到容器中，这两个类配置在spring-cloud-commons的项目下spring.factories文件下： 也就是说当我们引入spring-cloud-alibaba-nacos-discovery的依赖时，同时也会引入spring-cloud-commons，会自动向容器中注册这两个类，那么Nacos的自动配置类也能够生效。我们在回到NacosDiscoveryAutoConfiguration中，该配置类向容器中注入了三个Bean对象，分别为： NacosServiceRegistry：该Bean是注册中心的客户端，用于与注册中心Nacos交互，例如注册服务，拉取服务、心跳续约等，该类实现了SpringCloud提供的ServiceRegistry接口。 NacosRegistration：该Bean是从application.yml/properties配置文件中加载当前微服务的一些信息，封装为Nacos需要的服务注册的信息。该类实现了SpringCloud提供的Registration与ServiceInstance接口 NacosAutoServiceRegistration：该Bean实现了服务的自动注册与发现，利用NacosServiceRegistry与NacosRegistration将当前的微服务注册到Naocs上。该类继承了SpringCloud提供的AbstractAutoServiceRegistration类 前两个Bean对象都很好理解，自动注册的代码主要在NacosAutoServiceRegistration中实现。 SpringCloud针对服务的自动注册也提供了一套标准，那就是AbstractAutoServiceRegistration： 特别注意的是，该类实现了ApplicationListener&lt;WebServerInitializedEvent&gt;，实现了该类的类，如果注入到容器中，那么在Web容器初始化结束后，自动调用其接口的void onApplicationEvent(E event);方法。我们也可以估计到，服务的自动注册与发现就是通过该方法实现的，查看AbstractAutoServiceRegistration的该方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445// AbstractAutoServiceRegistration@Overridepublic void onApplicationEvent(WebServerInitializedEvent event) { bind(event);}public void bind(WebServerInitializedEvent event) { ApplicationContext context = event.getApplicationContext(); if (context instanceof ConfigurableWebServerApplicationContext) { if (&quot;management&quot;.equals(((ConfigurableWebServerApplicationContext) context) .getServerNamespace())) { return; } } this.port.compareAndSet(0, event.getWebServer().getPort()); this.start();}public void start() { if (!isEnabled()) { if (logger.isDebugEnabled()) { logger.debug(&quot;Discovery Lifecycle disabled. Not starting&quot;); } return; } // only initialize if nonSecurePort is greater than 0 and it isn't already running // because of containerPortInitializer below if (!this.running.get()) { this.context.publishEvent( new InstancePreRegisteredEvent(this, getRegistration())); // 向容器中发布即将服务注册的事件 register(); // 完成服务注册 if (shouldRegisterManagement()) { registerManagement(); } this.context.publishEvent( new InstanceRegisteredEvent&lt;&gt;(this, getConfiguration())); // 向容器中发布服务注册完成的事件 this.running.compareAndSet(false, true); }}protected void register() { this.serviceRegistry.register(getRegistration());} 我们可以看到onApplicationEvent方法的调用链，一直到start()方法，在该方法中，在服务注册的前后都向Spring容器中发布了服务注册前/后的事件，register()方法是向注册中心注册微服务，而有调用了serviceRegistry的register(R registration)方法，该方法便是将服务的服务的注册信息注册到注册中心。 我们需要注意，在Nacos的自动配置类中，向容器中自动注入了AbstractAutoServiceRegistration的子类NacosAutoServiceRegistration，而NacosAutoServiceRegistration在初始化的时候，传入了NacosServiceRegistry和NacosRegistration。这样就非常的清晰明了，在调用下面这句话时： 1this.serviceRegistry.register(getRegistration()); serviceRegistry即为NacosServiceRegistry对象，getRegistration()放回的就是NacosRegistration 经过验证： 在AbstractAutoServiceRegistration中，getRegistration()方法是一个抽象方法，该方法将由其子类实现完成服务注册，我们使用的是Nacos，在实现中，返回的就是在初始化时传入到AbstractAutoServiceRegistration中的NacosRegistration。 现在我们就可以来看NacosServiceRegistry的registry()方法： 12345678910111213141516171819202122@Overridepublic void register(Registration registration) { if (StringUtils.isEmpty(registration.getServiceId())) { log.warn(&quot;No service to register for nacos client...&quot;); return; } String serviceId = registration.getServiceId(); Instance instance = getNacosInstanceFromRegistration(registration); // 转化为Nacos的Instance类 try { namingService.registerInstance(serviceId, instance); // 注册到Nacos log.info(&quot;nacos registry, {} {}:{} register finished&quot;, serviceId, instance.getIp(), instance.getPort()); } catch (Exception e) { log.error(&quot;nacos registry, {} register failed...{},&quot;, serviceId, registration.toString(), e); }} 上述代码中通过namingService.registerInstance(serviceId, instance);完成服务注册，namingService是nacos-client提供的与服务端互交的客户端对象，主要用于给Nacos服务端发起Http请求并且如果是临时节点将保持心跳。 服务端服务注册Nacos服务端本身也是一个Springboot项目，向Nacos服务端发起Http请求就能注册服务，因此我们需要找到Controller中能够接收服务注册的某个方法，我们通过客户端的代码可以看到注册服务的url地址是/nacos/v1/ns/instance，因此我们在相关的Controller中找到该url的方法，位于nacos-namming模块下的InstanceController的register方法： 1234567891011121314@CanDistro@PostMapping@Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)public String register(HttpServletRequest request) throws Exception { final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); final String namespaceId = WebUtils .optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); final Instance instance = parseInstance(request); serviceManager.registerInstance(namespaceId, serviceName, instance); return &quot;ok&quot;;} serviceManager用于管理所有的Service，在阅读源码前，我们有必要先了解一下ServiceManager的组成： 12345678910111213141516171819// ServiceManager中保存了Map&lt;String, Map&lt;String, Service&gt;&gt; serviceMap; // namespace:(serviceName:Service)// 对于每个Service中保存了Map&lt;String, Cluster&gt; clusterMap; // clusterName:Cluster// 每个Cluster中保存了Set&lt;Instance&gt; persistentInstances; // 持久节点Set&lt;Instance&gt; ephemeralInstances; // 临时节点// ServiceManager保存了ConsistencyService consistencyService;// ConsistencyService保存了一个Datastoreprivate final DataStore dataStore;// dataStore保存了Map&lt;String, Datum&gt; dataMap;// Datum保存了public T value; // 一般情况下，Datum的泛型为List&lt;Instance&gt;,前面的Map的key为Service的名称 这些数据的关系描述： 每个ServiceManager中保存了多个Namespace，不同Namespace下的Serivce可以重名 每个Namespace下保存了多个Service，即一个微服务 每个Service下保存了多个Cluster，例如北京的组成一个集群，深圳的组成一个集群 每个Cluster下保存了多个Instance，即多个微服务的实例 ServiceManager中还保存了一个对象ConsistencyService，该对象中保存了一个dataMap，即实例ID：实例，即所有的实例，用于同步数据。 回到注册服务的Controller，registerInstance()代码如下： 12345678910111213public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException { // 创建空的service createEmptyService(namespaceId, serviceName, instance.isEphemeral()); // 获取到创建的Service Service service = getService(namespaceId, serviceName); if (service == null) { throw new NacosException(NacosException.INVALID_PARAM, &quot;service not found, namespace: &quot; + namespaceId + &quot;, service: &quot; + serviceName); } // 添加实例 addInstance(namespaceId, serviceName, instance.isEphemeral(), instance);} registerInstance主要分为2部，即创建一个空的Service与向Service中添加实例 createEmptyService 创建空的Service(当Service不存在时才创建)，该方法主要会调用到createServiceIfAbsent： 123456789101112131415161718192021222324252627// serviceManagerpublic void createServiceIfAbsent(String namespaceId, String serviceName, boolean local, Cluster cluster) throws NacosException { Service service = getService(namespaceId, serviceName); // 先看serviceMap中有没有该Service if (service == null) { // 没有则创建Service Loggers.SRV_LOG.info(&quot;creating empty service {}:{}&quot;, namespaceId, serviceName); service = new Service(); service.setName(serviceName); service.setNamespaceId(namespaceId); service.setGroupName(NamingUtils.getGroupName(serviceName)); // now validate the service. if failed, exception will be thrown service.setLastModifiedMillis(System.currentTimeMillis()); service.recalculateChecksum(); if (cluster != null) { cluster.setService(service); service.getClusterMap().put(cluster.getName(), cluster); } service.validate(); // 将Service存储到serviceMap中并且初始化 putServiceAndInit(service); // 持久化 if (!local) { addOrReplaceService(service); } }} 接下来到putServiceAndInit中： 1234567891011// serviceManagerprivate void putServiceAndInit(Service service) throws NacosException { putService(service); // 向serviceMap中添加service service.init(); // 初始化service // 同步器监听 consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), true), service); consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), false), service); Loggers.SRV_LOG.info(&quot;[NEW-SERVICE] {}&quot;, service.toJson());} 该方法先向serviceMap中添加了service，这部分比较简单，后续init了service，最后设置了consistencyService的监听，关于同步我们后续再说，看一看service的init()： 12345678910// Servicepublic void init() { // 向HealthCheck的执行器中提交检查健康的任务 HealthCheckReactor.scheduleCheck(clientBeatCheckTask); // 把集群内保存的Service都设置为当前的Service，一般情况下刚刚创建的Service的clusterMap没有集群 for (Map.Entry&lt;String, Cluster&gt; entry : clusterMap.entrySet()) { entry.getValue().setService(this); entry.getValue().init(); }} 初始化主要是提交一个对服务进行健康检查的任务，每隔一段时间，都会检查该服务中所有实例是否定期上报健康心跳，如果没有心跳，则先保留一段时间，如果还未上报，则踢出。 addInstance 创建了空的Service后，就将注册的实例添加到Service中，如果原来就存在该Service，就直接添加实例： 12345678910111213141516171819// serviceManagerpublic void addInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips) throws NacosException { // 根据注册信息生成InastanceList的key，即保存一个Service中所有Instance的key，保存在consistencyService中 String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral); Service service = getService(namespaceId, serviceName); synchronized (service) { // 求得新加入Instance后的Instance列表 List&lt;Instance&gt; instanceList = addIpAddresses(service, ephemeral, ips); Instances instances = new Instances(); instances.setInstanceList(instanceList); // 将该服务对应的所有Insatance存储到consistencyService一份，并且通知serviceMap更新 consistencyService.put(key, instances); }} 该方法主要也是两部分，一个是更新Instance列表，另一个是将Instance列表存到consistencyService一份 首先看生成更新后Instance列表，即addIpAddresses方法，会调用到updateIpAddresses方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// serviceManagerpublic List&lt;Instance&gt; updateIpAddresses(Service service, String action, boolean ephemeral, Instance... ips) throws NacosException { // 从consistencyService获取所有的Instance Datum datum = consistencyService .get(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), ephemeral)); // 从service中获取所有的Instance List&lt;Instance&gt; currentIPs = service.allIPs(ephemeral); Map&lt;String, Instance&gt; currentInstances = new HashMap&lt;&gt;(currentIPs.size()); Set&lt;String&gt; currentInstanceIds = Sets.newHashSet(); // 拷贝到一个临时的Map中 for (Instance instance : currentIPs) { currentInstances.put(instance.toIpAddr(), instance); currentInstanceIds.add(instance.getInstanceId()); } Map&lt;String, Instance&gt; instanceMap; if (datum != null) { // 更新datum中所有实例的健康状态，并返回datum中的所有实例为instanceMap instanceMap = setValid(((Instances) datum.value).getInstanceList(), currentInstances); } else { instanceMap = new HashMap&lt;&gt;(ips.length); } for (Instance instance : ips) { if (!service.getClusterMap().containsKey(instance.getClusterName())) { // 如果没有service属于的集群就创建一个集群 Cluster cluster = new Cluster(instance.getClusterName(), service); cluster.init(); // 将instance添加到集群中 service.getClusterMap().put(instance.getClusterName(), cluster); Loggers.SRV_LOG .warn(&quot;cluster: {} not found, ip: {}, will create new cluster with default configuration.&quot;, instance.getClusterName(), instance.toJson()); } if (UtilsAndCommons.UPDATE_INSTANCE_ACTION_REMOVE.equals(action)) { instanceMap.remove(instance.getDatumKey()); } else { // 添加到临时的Map中 instance.setInstanceId(instance.generateInstanceId(currentInstanceIds)); instanceMap.put(instance.getDatumKey(), instance); } } if (instanceMap.size() &lt;= 0 &amp;&amp; UtilsAndCommons.UPDATE_INSTANCE_ACTION_ADD.equals(action)) { throw new IllegalArgumentException( &quot;ip list can not be empty, service: &quot; + service.getName() + &quot;, ip list: &quot; + JacksonUtils .toJson(instanceMap.values())); } // 返回更新后的Instance列表，注意，此时还未更新service的cluster与consistencyService return new ArrayList&lt;&gt;(instanceMap.values());} 上述方法返回了加入新的Instance后的所有Instance列表，它是基于consistencyService中存储的Instance为基准进行更新的，经过该方法，如果需要添加的Instance的集群是不存在的，则新建一个Cluster。 上述方法返回后，然后将更新后的Instance列表更新至各个map当中，addInstance中： 1consistencyService.put(key, instances); 在一般的情况下，consistencyService为DistroConsistencyServiceImpl类的对象，该类是ConsistencyService的实现类，这个接口对于数据同步非常重要，后续再分析。 1234567891011121314151617181920212223public void put(String key, Record value) throws NacosException { onPut(key, value); taskDispatcher.addTask(key);}public void onPut(String key, Record value) { // 将某个service的所有Instances更新到consistencyService的dataStore if (KeyBuilder.matchEphemeralInstanceListKey(key)) { Datum&lt;Instances&gt; datum = new Datum&lt;&gt;(); datum.value = (Instances) value; datum.key = key; datum.timestamp.incrementAndGet(); dataStore.put(key, datum); } // 判断service对应的实例列表是否添加了监听，我们在前面createEmptyService中添加了监听 if (!listeners.containsKey(key)) { return; } // 添加数据发生变化的事件 notifier.addTask(key, ApplyAction.CHANGE);} 这一方法主要是更新dataStore中的Instances列表，并且添加一个数据变化的事件到一个Queue中，在Nacos服务端会有线程不停的判断是否有事件，有事件就会取出去触发监听者，其中本地的serviceMap中的Cluster监听到该事件会同步数据到Cluster中的Instances集合中，即完成了服务注册的流程。","link":"/2020/10/30/Nacos%E6%BA%90%E7%A0%81-%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E6%B5%81%E7%A8%8B/"},{"title":"Netty核心组件-ChannelFuture","text":"Netty的特点就是异步非阻塞的网络框架，在Netty中，几乎所有的IO操作都是异步执行的，我们调用IO操作的方法后，方法会返回一个Future类型的对象(一般为ChannelFuture)，ChannelFuture继承于JDK的Future对象，对Future进行了扩充。 JDK中的Future​ 从JDK1.5开始官方提供了Callable和Future接口，通过这两个接口，可以使得父线程在子线程执行完后得到任务执行的结果。 ​ 当一个操作比较耗时，而后面将要执行的几个任务与这个操作的结果无关，此时我们可以考虑使用异步执行，这与前端js中的ajax是相同的原理。在执行该函数时，我们马上返回一个对象，将耗时的操作放在其他线程执行，这样我们在父线程中就可以进行其他的操作，真正的数据可以等到我们需要它的时候再从函数的返回对象中获取出来。 Callable与RunnableJDK的线程池中可以提交两种类型的接口，即Callable与Runnable。 ​ java.lang.Runnable是JDK早期提供的线程相关的类，当创建一个线程时或者想线程池中提交一个任务时，需要将Runnable接口的对象传递进去，那么在线程分到时间片时就会自动的调用Runnable中唯一的run方法，该方法没有返回值。 123public interface Runnable { public abstract void run();} ​ ​ 而java.util.concurrent.Callable是JDK后续提供的，它也是一个接口，同样向线程池中提交一个任务时，也可传递以个Callable对象(自己创建线程时不能传递Callable对象，因为Thread没有提供Callable的构造函数)，Callable接口有一个方法call()，在线程分配到时间片时，会自动调用call()方法，与Runnbale不同的是，call()方法是有返回值的。 123public interface Callable&lt;V&gt; { V call() throws Exception;} FutureJDK中实现异步操作需要Callable配合Future使用，Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 12345678public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); // 取消任务 boolean isCancelled(); // 判断任务是否取消 boolean isDone(); // 任务是否完成 V get() throws InterruptedException, ExecutionException; // 阻塞获取任务的结果 V get(long timeout, TimeUnit unit) // 带超时的获取任务结果 throws InterruptedException, ExecutionException, TimeoutException;} 那么如何通过Callable与Future来实现异步操作呢？在JDK提供的线程池ExecutorService中我们可以看到submit方法有不同的重载版本 123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task); 这意味着我们想线程池中提交一个Callable方法可以得到一个Future对象，在未来的某个地方我们可以调用Future对象的get()方法来获取到该任务返回的结果。 12345678910111213141516171819202122232425@Slf4jpublic class SchedulePool { public static void main(String[] args) throws ExecutionException, InterruptedException { ExecutorService executorService = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors()*2); log.debug(&quot;submit other task&quot;); Future&lt;Integer&gt; hello = executorService.submit(() -&gt; { try { sleep(1500); } catch (InterruptedException e) { e.printStackTrace(); } log.debug(&quot;hello&quot;); return 2; }); log.debug(&quot;main task start&quot;); Thread.sleep(1000); log.debug(&quot;main task end&quot;); Integer i = hello.get(); log.debug(&quot;{}&quot;,i); executorService.shutdown(); }} 输出： 1234510:35:57.249 com.zl.threadpool.SchedulePool [main] - submit other task10:35:57.284 com.zl.threadpool.SchedulePool [main] - main task start10:35:58.289 com.zl.threadpool.SchedulePool [main] - main task end10:35:58.789 com.zl.threadpool.SchedulePool [pool-1-thread-1] - hello10:35:58.789 com.zl.threadpool.SchedulePool [main] - 2 ​ 从打印结果我们可以看到提交任务后我们马上拿到一个Future对象(此时任务还未执行完返回)，我们接着执行了打印操作，然后通过Future对象的get方法阻塞获取了先前提交任务的返回结果，直到任务完成后才拿到了结果打印。 ​ 本来两个任务需要1s+1.5s=2.5s才能够完成，现在只需要1.5s就能够完成。 ​ 提交Runnable对象就无法拿到返回的结果，不过也会返回一个Future对象，可以用于判断任务是否完成，即调用Future的get方法返回的是null，但是可以通过Future的isDone方法判断run方法是否执行完成。 FutureTask​ 不通过线程池提交任务，想要通过Thread类来实现异步调用后返回结果可以使用FutureTask类，FutureTask类其实也是实现了Runable接口，和Runable创建方法类似，此外，FutureTask还实现了Future接口，可通过FutureTask获取执行结果。 ​ FutureTask的构造函数必须传入Callable对象，因此我们可以从FutureTask中get到Callable的执行结果。 123456789101112131415161718public class CreateThread_FutureTask { public static void main(String[] args) throws ExecutionException, InterruptedException { FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot;执行了&quot;); return 1; } }); Thread thread = new Thread(task, &quot;thread1&quot;); thread.start(); Integer integer = task.get(); // 阻塞，等待task任务的返回结果 System.out.println(integer); // 打印1 }} Future的缺点只能用以下方式获取结果： V get()阻塞等待 轮询boolean isDone(); 有限等待V get(long timeout, TimeUnit unit) 执行状态只有两种： boolean isDone(); boolean isCancelled(); 问题： 接口中只有isDone()方法判断一个异步操作是否完成，但是对于完成的定义过于模糊，JDK文档指出正常终止、抛出异常、用户取消都会使isDone()方法返回真。在我们的使用中，我们极有可能是对这三种情况分别处理，而JDK这样的设计不能满足我们的需求。 对于一个异步操作，我们更关心的是这个异步操作触发或者结束后能否再执行一系列动作。比如说，我们浏览网页时点击一个按钮后实现用户登录。在javascript中，处理代码如下： 123$(&quot;#login&quot;).click(function(){ login(); }); Netty中的Future​ 鉴于JDK提供的Future对象的缺点，Netty对JDK的Future进行了扩展，同样也命名为Future，主要方法如下： 123456789101112131415// 异步操作完成且正常终止boolean isSuccess();// 异步操作是否可以取消boolean isCancellable();// 异步操作失败的原因Throwable cause();// 添加一个监听者，异步操作完成时回调，类比javascript的回调函数Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener);Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener);// 阻塞直到异步操作完成Future&lt;V&gt; await() throws InterruptedException;// 同上，但异步操作失败时抛出异常Future&lt;V&gt; sync() throws InterruptedException;// 非阻塞地返回异步结果，如果尚未完成返回nullV getNow(); 从Future对象中可以获取任务执行的状态： 未执行完成时，isDone返回false，其他的自然返回false。而当任务完成后，isDone为true，但是完成的状态可能是成功完成了，也可能是发生了异常，还可能是被取消对应于右边三个状态。 12345678910111213141516* +---------------------------+* | Completed successfully |* +---------------------------+* +----&gt; isDone() = true |* +--------------------------+ | | isSuccess() = true |* | Uncompleted | | +===========================+* +--------------------------+ | | Completed with failure |* | isDone() = false | | +---------------------------+* | isSuccess() = false |----+----&gt; isDone() = true |* | isCancelled() = false | | | cause() = non-null |* | cause() = null | | +===========================+* +--------------------------+ | | Completed by cancellation |* | +---------------------------+* +----&gt; isDone() = true |* | isCancelled() = true |* +---------------------------+ 在JDK中，我们从Future中获取的数据是从Callable接口的call方法返回值获取的，JDK的异步实现方式是Future+Callable。而在Netty中，并没有使用Callable接口，而是自己提供了Promise接口继承Future接口提供数据。 123456789101112public interface Promise&lt;V&gt; extends Future&lt;V&gt; { // 标记异步操作结果为成功，如果已被设置（不管成功还是失败）则抛出异常IllegalStateException Promise&lt;V&gt; setSuccess(V result); // 同上，只是结果已被设置时返回False boolean trySuccess(V result); // 设置失败 Promise&lt;V&gt; setFailure(Throwable cause); boolean tryFailure(Throwable cause); // 设置不可取消 boolean setUncancellable();} 需要注意的是，setSucess与setFailure只能被调用一次，任何一个方法被调用过了都不能再调用了，再次调用会抛出异常，两个方法会通知添加到其内部的Listener执行对应的行为。 GenericFutureListener GenericFutureListener是Future对象的监听者，在Future对象完成任务后，回调其中的operationComplete方法。 123456789public interface GenericFutureListener&lt;F extends Future&lt;?&gt;&gt; extends EventListener { /** * Invoked when the operation associated with the {@link Future} has been completed. * * @param future the source {@link Future} which called this callback */ void operationComplete(F future) throws Exception;} 关于Netty异步调用的部分类结构图如下: ​ AbstractFuture 该抽象类实现了两个get()方法，阻塞等待获取异步执行的结果，下面给出其中一个，另外一个是带超时的get。 123456789101112131415public abstract class AbstractFuture&lt;V&gt; implements Future&lt;V&gt; { @Override public V get() throws InterruptedException, ExecutionException { await(); // 阻塞等待唤醒 Throwable cause = cause(); // 获取是否有异常 if (cause == null) { return getNow(); // 无异常，直接返回结果，有可能还未执行完(被打断的情况) } if (cause instanceof CancellationException) { throw (CancellationException) cause; } throw new ExecutionException(cause); } ChannelFuture ChannelFuture主要添加了两个方法 123456public interface ChannelFuture extends Future&lt;Void&gt; { // 返回关联此Future对象的channel Channel channel(); // 该Future是否有返回数据 boolean isVoid(); DefaultPromise DefaultPromise实现了大多的Promise接口和Future接口的方法： 1234567891011121314151617181920212223242526272829303132333435363738@Overridepublic Promise&lt;V&gt; setSuccess(V result) { if (setSuccess0(result)) { // 设置任务执行成功，并将结果放入 notifyListeners(); // 通知监听者任务执行完成，做出相应动作 return this; } throw new IllegalStateException(&quot;complete already: &quot; + this);}@Overridepublic Promise&lt;V&gt; setFailure(Throwable cause) { if (setFailure0(cause)) { // 设置任务执行失败，并将原因放入 notifyListeners(); // 通知监听者任务完成，做出相应的动作 return this; } throw new IllegalStateException(&quot;complete already: &quot; + this, cause);}@Overridepublic boolean isSuccess() { Object result = this.result; // 执行结果 return result != null &amp;&amp; result != UNCANCELLABLE &amp;&amp; !(result instanceof CauseHolder);}@Overridepublic Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) { checkNotNull(listener, &quot;listener&quot;); synchronized (this) { addListener0(listener); // 添加监听者 } if (isDone()) { notifyListeners(); // 如果任务是完成了的，就通知所有的Listener } return this;} 让我们看一下通知监听者的细节： 1234567891011121314151617181920212223private void notifyListeners() { EventExecutor executor = executor(); // 获取executor()执行线程，在构造函数中传入 if (executor.inEventLoop()) { // 判断当前线程是否为executor final InternalThreadLocalMap threadLocals = InternalThreadLocalMap.get(); final int stackDepth = threadLocals.futureListenerStackDepth(); if (stackDepth &lt; MAX_LISTENER_STACK_DEPTH) { threadLocals.setFutureListenerStackDepth(stackDepth + 1); try { notifyListenersNow(); // 通知执行operationComplete } finally { threadLocals.setFutureListenerStackDepth(stackDepth); } return; } } safeExecute(executor, new Runnable() { @Override public void run() { notifyListenersNow(); } });} 首先，获取到该类中保存的executor，即执行任务的线程，该executor一定是eventLoop中的线程。跟着使用executor.inEventLoop()判断当前线程是否是excutor线程，是的的话直接执行通知监听者，不是的话则使用excutor线程执行通知监听者operationComplete方法。 ChannelFuture的使用在服务端我们使用ChannelFuture： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class HServer { public static void main(String[] args) throws InterruptedException { EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap bootstrap = new ServerBootstrap(); HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); set.remove(1); try { bootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(&quot;http&quot;, new HttpServerCodec()); pipeline.addLast(&quot;httpA&quot;, new HttpObjectAggregator(5*1024*1024)); pipeline.addLast(&quot;myHandler&quot;, new SimpleChannelInboundHandler&lt;HttpObject&gt;() { @Override protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception { // 设置响应内容 ByteBuf content = Unpooled.copiedBuffer(&quot;hello，我是服务器&quot;, CharsetUtil.UTF_8); DefaultFullHttpResponse re = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content); re.headers().add(HttpHeaderNames.CONTENT_TYPE, &quot;text/plain;charset=utf-8&quot;) .add(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes()); // 写出响应 ChannelFuture channelFuture = ctx.write(re); // 添加写出后的监听器，写出成功后，即invoke后执行 channelFuture.addListener((future)-&gt;{ if(future.isSuccess()) { System.out.println(&quot;成功&quot;); } else { System.out.println(&quot;失败&quot;); } }); } }); } }); ChannelFuture sync = bootstrap.bind(8888).sync(); sync.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } }} 如上程序实现服务端可以接受Http请求然后回复客户端，调用ctx.write(re)方法不会马上马上把消息写出给客户端，而是放在缓冲中，等到缓冲区满了或者调用invoke()方法后才会写出。在后面添加的监听器需要在invoke真正写出后才会执行。 注意： 如果把ctx.write(re)变成ctx.writeAndFlush(re)，那么执行完ctx.writeAndFlush(re)数据就已经被写出了，那么执行addListener会马上执行回调。","link":"/2020/09/08/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-ChannelFuture/"},{"title":"Netty核心组件-EventLoopGroup","text":"Netty高性能架构–线程模型：Netty之所以性能很高，除了依赖于Nio的特性外，还实现了一套高效的线程模型。 Netty线程模型传统线程模型​ 即阻塞IO模型，一个网络连接对应一个线程。 模型特点： 采用阻塞IO模式获取输入的数据 每个连接都需要独立的线程完成数据的输入，业务处理，数据返回 模型缺点： 当并发过多，创建大量线程会造成资源的大量占用 连接建立后，很可能一直阻塞在等待读和写的状态 Reactor/Dispatcher模型特点： 基于IO复用模型 ​ 多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。 基于线程池复用线程资源 ​ 不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。 说明： Reactor 模式，通过一个或多个输入同时传递给服务处理器的模式(基于事件驱动) 服务器端程序处理传入的多个请求,并将它们同步分派到相应的处理线程， 因此Reactor模式也叫 Dispatcher模式 Reactor 模式使用IO复用监听事件, 收到事件后，分发给某个线程(进程), 这点就是网络服务器高并发处理关键 (1) 单Reactor单线程 ​ 只有单个线程，该线程里有一个Reactor来负责接收连接，接收到连接后统一还是用这个线程来进行处理 ​ 优点：简单，没有多线程，没有进程通信​ 缺点：性能，无法发挥多核的极致，一个handler卡死，导致当前进程无法使用，IO和CPU不匹配​ 场景：客户端有限，业务处理快，比如redis，因为redis的功能非常简单，就是从内存中获取一个键值对，没有文件IO等复杂操作，单次请求处理时间很短，避免了多线程上下文切换的消耗，性能比多线程更高。 ​ ​ 在我们之前的1.2.3的程序代码中，同样是基于该模型的，Selector负责接收请求，如果有事件发生就会通过这个线程来处理响应的请求。如果是ServerSocketChannel发生事件，调用accept()建立连接，如果是SocketChannel就进行响应的处理。 (2) 单Reactor多线程模型 说明： Reactor 对象通过select 监控客户端请求 事件, 收到事件后，通过dispatch进行分发 如果是请求建立连接，则通过Acceptor的accept方法建立连接，然后创建一个Handler对象来负责完成对应的客户端的后续请求处理 如果不是连接请求，则由reactor分发调用连接对应的handler 来处理 handler 只负责响应事件，不做具体的业务处理, 通过read 读取数据后，会分发给后面的worker线程池的某个线程处理业务 worker 线程池会分配独立线程完成真正的业务，并将结果返回给client 优点：可以充分的利用多核cpu 的处理能力缺点：多线程数据共享和访问比较复杂， reactor 处理所有的事件的监听和响应，在单线程运行， 在高并发场景容易出现性能瓶颈. (3) 主从Reactor多线程 说明： 一个(或多个)Reactor监听客户端的请求，当请求到来时，如果是建立连接的请求，则在本线程的Acceptor完成accept，再将连接分配给子线程Reactor 如果是其他请求，则转到子线程的Reactor中进行分发处理，子线程Reactor分发后再交由线程池处理业务。 Reactor子线程可以有多个，同样主线程Reactor也可以有多个 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。优点：父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。Netty主要使用的就是该模型缺点：编程复杂度较高 Netty线程模型Netty使用的就是主从Reactor多线程模型，在服务器端，定义了两个线程池BossGroup和Worker Group： BossGroup对应了Reactor主线程(可以有多个，但是一般都为1个)，每一个Reactor主线程都循环的进行1.select选择—》2.处理连接请求，建立连接并将连接注册到WorkerGroup中-》3.处理一些任务 Worker Group对应了Worker线程池，每一个线程也都是一个Selector来监听有哪些注册到自己上的客户端有读时间发生，同样循环进行1.select选择-》2.处理所有读写事件并执行对应业务-》3.执行一些其他任务 下面编写一个Netty通讯的程序来配合解释： 服务端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class NettyServer { public static void main(String[] args) throws InterruptedException { // 创建循环事件组，线程池，原理图中的BossGroup，用于监听用户的请求 // 若不指定线程数量，会默认设置为当前机器的逻辑处理器✖2 EventLoopGroup eventExecutors = new NioEventLoopGroup(1); // 创建工作线程组，原理图中的WorkerGroup // 若不指定线程数量，会默认设置为当前机器的逻辑处理器✖2 EventLoopGroup workExecutors = new NioEventLoopGroup(); try{ // 服务端配置 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(eventExecutors, workExecutors) // 将两个Group加入 .channel(NioServerSocketChannel.class) // 指定channel的类型，注意这不是java NIO下的，是Netty提供的 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列的连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ServerHandler()); // 每个注册进来的channel都添加一个处理器，可以添加多个 } }); // 设置子处理器，当接受到读请求是会执行处理器中的方法。当是客户端请求连接时不会走该处理器，而是注册到workExecutors中 // 绑定端口 ChannelFuture sync = bootstrap.bind(8888).sync(); // 将来在接收到关闭事件是关闭通道，closeFuture本身是异步调用，加上sync同步等待返回结果 sync.channel().closeFuture().sync(); } finally { // 关闭线程池 eventExecutors.shutdownGracefully(); workExecutors.shutdownGracefully(); } }}public class ServerHandler extends ChannelInboundHandlerAdapter { /** * 当有读取事件发生会触发该方法 * ChannelHandlerContext为一个上下文对象，内部包含了pipeline、channel等 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; System.out.println(&quot;客户端发送的消息为:&quot; + buf.toString(CharsetUtil.UTF_8)); System.out.println(&quot;客户端的地址为:&quot; + ctx.channel().remoteAddress()); } /** * 当读取完毕后会触发该方法 */ @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { System.out.println(&quot;接收到客户端请求&quot;); ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;客户端你好,(*^▽^*)&quot;, CharsetUtil.UTF_8)); }} 客户端： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class NettyClient { public static void main(String[] args) throws InterruptedException { // 创建一个时间循环组 EventLoopGroup eventExecutors = new NioEventLoopGroup(); try { // 客户端创建BootStrap对象来初始化 Bootstrap bootstrap = new Bootstrap(); // 设置相关参数 bootstrap.group(eventExecutors) // 设置时间循环组 .channel(NioSocketChannel.class) // 设置客户端通道的种类 .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ClientHandler()); // 添加一个处理器 } }); ChannelFuture sync = bootstrap.connect(&quot;0.0.0.0&quot;, 8888).sync(); sync.channel().closeFuture(); } finally { // 关闭线程池 eventExecutors.shutdownGracefully(); } }}public class ClientHandler extends ChannelInboundHandlerAdapter { /** * 当通道触发就会触发该方法 */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(&quot;client: &quot; + ctx); ctx.writeAndFlush(Unpooled.copiedBuffer(&quot;这是客户端，(*^▽^*)&quot;, CharsetUtil.UTF_8)); } /** * 当有读取事件发生会触发该方法 */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //super.channelRead(ctx, msg); ByteBuf buf = (ByteBuf) msg; System.out.println(&quot;服务器回复:&quot; + buf.toString(CharsetUtil.UTF_8)); System.out.println(ctx.channel().remoteAddress()); }} Netty线程模型说明： 对于服务端，创建了两个线程组，bossGroup与workerGroup： bossGroup对应主从Reactor模型中的的mainReactor，用于接收客户端的连接，我们应该传入参数1，表示只建立一个线程。在Netty中，执行ServerBootsrap的bind方法会绑定端口得到一个SeverSocketChannel对象，之后会把该对象放置在bossGroup一个EventLoop（一般为一个线程）中，注册到该线程的Selector上来监听有没有连接事件，如果有连接请求，就得到SocketChannel注册到workerGroup上，后续的业务交给了workerGroup的线程，总体来说接收请求的过程很简单，单线程也能有较高的吞吐量，不需要采用多线程引入线程切换的开销，并且Selector操作也不是线程安全的。bossGroup可以初始化多个EventLoop（一般为一个线程），但是bind一个端口只会生成一个EventLoop，因此我们一般初始化为1个线程。网上对于bossGroup可以给多个线程的理由是如果我们需要绑定多个端口，就可以初始化多个线程比较合理。 workerGroup 对应 Reactor 模型的 subReactor ，用于进行 SocketChannel 的数据读写。对于 EventLoopGroup ，如果未传递方法参数 nThreads ，表示使用 CPU线程数*2 个 Reactor 。这个也符合我们上面提到的，通常，subReactor 的个数为CPU逻辑处理器个数*2，每个 subReactor 独占一个线程来处理。 在上图虚线框中，有一个用户自定义的业务线程池，虽然Netty提供了workerGroup线程池有多个线程同时工作，但是更多的情况下线程池中的每个线程都是用于多个Channel网络I/O的，而每个channel对应于一个客户端的连接，如果在channel中有读取数据库等I/O操作，会造成channel的阻塞，如果某一个客户端向服务端发送了多个请求，第一个请求没执行完就一直阻塞不会接收到第二个请求，因此在有长时间I/O操作的情况下，我们把这些业务交给一个自定义的线程池更好，执行完业务后，调用channel的write方法Netty会将业务线程切换到workerGroup线程进行网络I/O。 EventLoopGroupEventLoop相关类图： EventLoop为一个线程池，通常与一个Selector绑定，但是在Netty中都是将EventLoop作为单个线程，即NioEventLoop，NioEventLoop负责了该线程的各个注册在Selector上channel的请求处理，EventLoop还有其他的实现类，但是基本上都是SingleThreadEventLoop抽象类的子类，其余的几乎不怎么使用，在这里我们只分析NioEventLoop。 EventLoopGroup可以管理了多个EventLoop。 EventLoopGroup用于管理多个EventLoop，该接口有以下方法： 12345678910111213141516171819202122232425public interface EventLoopGroup extends EventExecutorGroup { /** * Return the next {@link EventLoop} to use */ @Override EventLoop next(); /** * Register a {@link Channel} with this {@link EventLoop}. The returned {@link ChannelFuture} * will get notified once the registration was complete. */ ChannelFuture register(Channel channel); /** * Register a {@link Channel} with this {@link EventLoop} using a {@link ChannelFuture}. The passed * {@link ChannelFuture} will get notified once the registration was complete and also will get returned. */ ChannelFuture register(ChannelPromise promise); /** * Register a {@link Channel} with this {@link EventLoop}. The passed {@link ChannelFuture} * will get notified once the registration was complete and also will get returned. * * @deprecated Use {@link #register(ChannelPromise)} instead. */ @Deprecated ChannelFuture register(Channel channel, ChannelPromise promise);} 主要就是next方法与register方法： next()：获取一个EventLoop，如果有多个EventLoop，可以定义获取的策略。 register(Channel)：将Channel注册在EventLoopGroup中，即绑定在一个Selector上。 EventLoopGroup的初始化从我们之前的分析，我们在创建NioEventLoopGroup时有：NioEventLoopGroup workerGroup = new NioEventLoopGroup(8)，我们传入的8为线程数量。我们向上找构造函数，AbstractEventExecutorGroup没有定义构造，MultithreadEventExecutorGroup定义了构造： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// class MultithreadEventExecutorGroup/** * Create a new instance. * * @param nThreads the number of threads that will be used by this instance.线程组的线程数 * @param executor the Executor to use, or {@code null} if the default should be used.可以自己传入一个线程池 * @param chooserFactory the {@link EventExecutorChooserFactory} to use. * @param args arguments which will passed to each {@link #newChild(Executor, Object...)} call */protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) { if (nThreads &lt;= 0) { throw new IllegalArgumentException(String.format(&quot;nThreads: %d (expected: &gt; 0)&quot;, nThreads)); } // 如果没有传入线程池，就默认创建一个线程池 if (executor == null) { executor = new ThreadPerTaskExecutor(newDefaultThreadFactory()); } // 与线程数量相同的EventLoop children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) { boolean success = false; try { // 创建EventLoop对象的数组，NioEventLoop children[i] = newChild(executor, args); success = true; } catch (Exception e) { // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); } finally { if (!success) { for (int j = 0; j &lt; i; j ++) { children[j].shutdownGracefully(); } for (int j = 0; j &lt; i; j ++) { EventExecutor e = children[j]; try { while (!e.isTerminated()) { e.awaitTermination(Integer.MAX_VALUE, TimeUnit.SECONDS); } } catch (InterruptedException interrupted) { // Let the caller handle the interruption. Thread.currentThread().interrupt(); break; } } } } } // EventLoop的选择器 chooser = chooserFactory.newChooser(children); // 监听EventLoop关闭事件 final FutureListener&lt;Object&gt; terminationListener = new FutureListener&lt;Object&gt;() { @Override public void operationComplete(Future&lt;Object&gt; future) throws Exception { if (terminatedChildren.incrementAndGet() == children.length) { terminationFuture.setSuccess(null); } } }; for (EventExecutor e: children) { e.terminationFuture().addListener(terminationListener); } Set&lt;EventExecutor&gt; childrenSet = new LinkedHashSet&lt;EventExecutor&gt;(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet);} 由上面代码可以看出EventLoopGroup在初始化时： 1 - 用户可以自定义线程池，如果没有自定义线程池那就创建一个指定线程数的线程池 2 - 创建与指定线程数相同数量的EventExecutor（即EventLoop） 3 - 创建一个EventLoop的选择器，在需要提供EventLoop时选择EventLoopGroup中的一个EventLoop 4 - 添加每个EventLoop关闭事件的监听器 EventLoopGroup的初始化就这些，在这里面主要有EventLoop的初始化，我们放到后面再讲。 EventLoopGroup接口的方法我们再来看看EventLoopGroup接口定义的两类方法： 1234567891011// 该方法在MultithreadEventExecutorGroup中定义@Overridepublic EventExecutor next() { return chooser.next();} // 该方法在MultithreadEventLoopGroup中定义@Overridepublic ChannelFuture register(Channel channel) { return next().register(channel);} 可以看到register的逻辑为通过chooser选择器从EventLoopGroup中选出一个EventLoop来进行注册。下面为一个选择器的类 12345678910111213private static final class GenericEventExecutorChooser implements EventExecutorChooser { private final AtomicInteger idx = new AtomicInteger(); private final EventExecutor[] executors; GenericEventExecutorChooser(EventExecutor[] executors) { this.executors = executors; } @Override public EventExecutor next() { return executors[Math.abs(idx.getAndIncrement() % executors.length)]; // 直接用递增的id去对EventLoop的数量取余得到下标 }} 上述的选择器就是使用了一个轮询的复杂均衡策略。 后续将继续介绍EventLoop。","link":"/2020/09/09/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-EventLoopGroup/"},{"title":"Netty核心组件-EventLoop与BootStrap","text":"上一次我们讲到了EventLoopGroup，EventLoop的初始化跳过了，现在来深入研究EventLoop组件，EventLoop是Netty非常重要的组件，它是网络请求处理的核心，通过Selector不断循环监听Channel的事件，处理相应的请求。 EventLoop EventLoop初始化之前我们讲到了MultithreadEventExecutorGroup类中EventLoopGroup的初始化，其中出现了下面两句话： 1234// 与线程数量相同的EventLoopchildren = new EventExecutor[nThreads];// 创建EventLoop对象的数组，NioEventLoopchildren[i] = newChild(executor, args); 这就是EventLoopGroup中初始化其中的EventLoop，其中newChild为一个抽象方法，该方法被子类NioEventLoopGroup实现： 1234567// class NioEventLoopGroup@Overrideprotected EventLoop newChild(Executor executor, Object... args) throws Exception { EventLoopTaskQueueFactory queueFactory = args.length == 4 ? (EventLoopTaskQueueFactory) args[3] : null; return new NioEventLoop(this, executor, (SelectorProvider) args[0], ((SelectStrategyFactory) args[1]).newSelectStrategy(), (RejectedExecutionHandler) args[2], queueFactory);} 我们在结合EventLoop的构造函数看一下： 1234567891011121314151617NioEventLoop(NioEventLoopGroup parent, Executor executor, SelectorProvider selectorProvider, SelectStrategy strategy, RejectedExecutionHandler rejectedExecutionHandler, EventLoopTaskQueueFactory queueFactory) { super(parent, executor, false, newTaskQueue(queueFactory), newTaskQueue(queueFactory), rejectedExecutionHandler); if (selectorProvider == null) { throw new NullPointerException(&quot;selectorProvider&quot;); } if (strategy == null) { throw new NullPointerException(&quot;selectStrategy&quot;); } provider = selectorProvider; final SelectorTuple selectorTuple = openSelector(); // 使用SelectorProvider对象生成一个Selector对象 selector = selectorTuple.selector; unwrappedSelector = selectorTuple.unwrappedSelector; selectStrategy = strategy;} 可以明显的看出： NioEventLoop中保存了自己属于哪个事件循环组，即NioEventLoopGroup. NioEventLoop中保存了一个线程池executor，这个线程池是NioEventLoopGroup在初始化时创建的线程池，也就是说这个线程池被其中的所有NioEventLoop共享. NioEventLoop中保存了一个SelectorProvider，用于产生Selector选择器对象，同样也保存了选择器对象selector NioEventLoop中保存了一个SelectStrategy，用于定义选择策略的，即判断是否有事件发生。我们主要用的NioEventLoop使用的是Nio提供的Selector的selectNow方法，Netty中还提供了EpollEventLoop使用的是自己实现的native方法来进行select，不同的select方式效率不同，不过Nio的select的效率也很高。 NioEventLoop父类的重要方法接下来我们来看看NioEventLoop的父类中有哪些比较重要的方法。 (1) inEventLoop 该方法是一个比较重要的方法，在父类SingleThreadEventExecutor中实现，该方法的主要功能是判断当前线程是否为对应EventLoop的线程。在Netty中，channel的读写操作都是在其对应的EventLoop的线程中完成的，channel每次进行读写操作，都先会检查是否在对应EventLoop线程中执行的，如果不是，将会提交给对应的EventLoop线程来执行，该方法就是用于判断当前线程是否在channel对应的EventLoop的线程中。 1234@Overridepublic boolean inEventLoop(Thread thread) { return thread == this.thread;} (2) addTask/removeTask/hasTask… 该方法是给EventLoop中添加任务，在父类SingleThreadEventExecutor中实现。就像之前的Netty架构图中，EventLoop中具有一个任务队列TaskQueue，在EventLoop线程循环中，除了执行select然后处理读写事件之外，还会执行TaskQueue中的任务，这些方法就是给TaskQueue中添加任务等对任务队列进行操作。 12345678910protected void addTask(Runnable task) { if (task == null) { throw new NullPointerException(&quot;task&quot;); } // 添加任务到队列 if (!offerTask(task)) { // 添加失败，则拒绝任务 reject(task); }} (3) register register(Channel channel)方法是将Channel注册到该EventLoop上，也就是把Channel注册到对应的Selector上 1234@Overridepublic ChannelFuture register(Channel channel) { return register(new DefaultChannelPromise(channel, this));} NioEventLoop的运行原理run()方法NioEventLoop为事件循环，其中的run方法一旦运行起来就一直循环，来看看run方法的源代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Overrideprotected void run() { for (;;) { // 死循环，一直监听Selector上的channel是否有读写事件 try { try { switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) { case SelectStrategy.CONTINUE: // 不会出现该情况 continue; case SelectStrategy.BUSY_WAIT: // fall-through to SELECT since the busy-wait is not supported with NIO case SelectStrategy.SELECT: select(wakenUp.getAndSet(false)); // &lt;1&gt; 阻塞/循环判断是否有事件发生，有事件发生则返回 // 是否需要唤醒Selector if (wakenUp.get()) { selector.wakeup(); } // fall through default: } } catch (IOException e) { // If we receive an IOException here its because the Selector is messed up. Let's rebuild // the selector and retry. https://github.com/netty/netty/issues/8566 rebuildSelector0(); // 重建一个Selector，将原来Selector上的Channel都注册到新的Selector上，关闭原来的Channel handleLoopException(e); continue; } cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; if (ioRatio == 100) { try { processSelectedKeys(); // &lt;2&gt; 处理所有的被选择的Key，即有事件发生的channel } finally { // Ensure we always run tasks. runAllTasks(); // &lt;3&gt; 执行所有任务队列中的任务 } } else { // 同时处理所有有事件发生的channel，然后执行任务队列中的任务，但是执行任务有时间限制，不能执行太久 final long ioStartTime = System.nanoTime(); try { processSelectedKeys(); } finally { // Ensure we always run tasks. final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); } } } catch (Throwable t) { handleLoopException(t); } // Always handle shutdown even if the loop processing threw an exception. try { if (isShuttingDown()) { closeAll(); if (confirmShutdown()) { return; } } } catch (Throwable t) { handleLoopException(t); } }} 从上述的源码中我们可以看出，事件循环的流程： &lt;1&gt;通过select方法判断是否有事件发生，没有事件发生时，该方法会处于阻塞状态。在该方法中还处理了JDK的NIO存在空轮询的bug，后续再介绍。 &lt;2&gt;当已经监听到有事件发生，处理所有的SelectedKeys，完成对应channel的读写事件 &lt;3&gt;执行任务队列中的任务（可能是所有任务，也可能是部分） select(boolean)方法首先，JDK提供的NIO具有一个比较致命的bug，我们知道Selector监听事件发生有int select()、int selectNow()、int select(long timeout)三种方法： select()：阻塞监听是否有事件发生，如果没有事件发生，该方法会一直阻塞 selectNow()：判断是否有事件发生，该方法不会阻塞，会马上返回结果，没有事件发生就返回0 select(long timeout)：带超时的阻塞监听是否有事件发生，如果没有事件发生，该方法首先会阻塞，超过指定事件后会自动唤醒，返回0。 在Linux平台下，select()会出现没有事件发生但是还是会直接返回0，而不是进入阻塞状态，然后去processKeys但是没有key，任务队列也没有任务需要执行，这样的情况下会一直发生空轮询，导致CPU占用100%，对性能造成严重的损耗，Netty针对该bug进行了处理，就在NioEventLoop下的select(boolean)方法中： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100private void select(boolean oldWakenUp) throws IOException { Selector selector = this.selector; try { int selectCnt = 0; // 轮询计数器 // 计算轮询超时的时间 long currentTimeNanos = System.nanoTime(); long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); long normalizedDeadlineNanos = selectDeadLineNanos - initialNanoTime(); if (nextWakeupTime != normalizedDeadlineNanos) { nextWakeupTime = normalizedDeadlineNanos; } // 循环判断是否有事件发生，尽管Selector的select()方法是阻塞的，但是在Linux下会有bug可能不阻塞，所以用循环 for (;;) { long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; // 如果空轮询超时，则退出循环 if (timeoutMillis &lt;= 0) { if (selectCnt == 0) { selector.selectNow(); selectCnt = 1; } break; } // If a task was submitted when wakenUp value was true, the task didn't get a chance to call // Selector#wakeup. So we need to check task queue again before executing select operation. // If we don't, the task might be pended until select operation was timed out. // It might be pended until idle timeout if IdleStateHandler existed in pipeline. // 如果任务队列中有任务需要执行了，那么就把Selector的唤醒标志置位true并退出循环去执行任务 if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) { selector.selectNow(); selectCnt = 1; break; } // 带超时的select(long timeout)方法监听是否有事件发生 int selectedKeys = selector.select(timeoutMillis); selectCnt ++; // 如果有事件发生了selectedKeys!=0， // 或者调用select(boolean)方法前唤醒标志为true， // 或者目前的唤醒标志位为true， // 或者任务队列有任务， // 或者有周期执行的任务。 // 以上这些情况都退出此次监听 if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) { // - Selected something, // - waken up by user, or // - the task queue has a pending task. // - a scheduled task is ready for processing break; } // 如果线程被打断，退出循环 if (Thread.interrupted()) { // Thread was interrupted so reset selected keys and break so we not run into a busy loop. // As this is most likely a bug in the handler of the user or it's client library we will // also log it. // // See https://github.com/netty/netty/issues/2426 if (logger.isDebugEnabled()) { logger.debug(&quot;Selector.select() returned prematurely because &quot; + &quot;Thread.currentThread().interrupt() was called. Use &quot; + &quot;NioEventLoop.shutdownGracefully() to shutdown the NioEventLoop.&quot;); } selectCnt = 1; break; } // 判断是否超时 long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) { // timeoutMillis elapsed without anything selected. selectCnt = 1; } else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) { // 在指定时间内(因为超时会退出循环重新计时)超过空轮询的次数，该Selector出现了bug，重建Selector // The code exists in an extra method to ensure the method is not too big to inline as this // branch is not very likely to get hit very frequently. selector = selectRebuildSelector(selectCnt); selectCnt = 1; break; } currentTimeNanos = time; } if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS) { if (logger.isDebugEnabled()) { logger.debug(&quot;Selector.select() returned prematurely {} times in a row for Selector {}.&quot;, selectCnt - 1, selector); } } } catch (CancelledKeyException e) { if (logger.isDebugEnabled()) { logger.debug(CancelledKeyException.class.getSimpleName() + &quot; raised by a Selector {} - JDK bug?&quot;, selector, e); } // Harmless exception - log anyway }} 第 4 行：获得 select 操作的计数器。主要用于记录 Selector 空轮询次数，所以每次在正在轮询完成( 例如：轮询超时 )，则重置 selectCnt 为 1 。 第 8 行：计算 select 操作的截止时间，单位：纳秒。 #delayNanos(currentTimeNanos) 方法返回的为下一个定时任务距离现在的时间，如果不存在定时任务，则默认返回 1000 ms 。 死循环调用Selector的select(long timeout)方法，直到满足下面的情况才退出循环： 循环时间超时，18行 任务队列中有任务需要执行或者有周期任务执行，31行与46行 有channel发生了对应的读写事件，46行 被唤醒，wakeup为true，或调用select(boolean)之前传入的就是true，46行 线程被打断，一般不允许打断，打断了是出现bug或者错误使用，54行 在指定时间内发生了很多次空轮询，该Selector出现了bug，重建Selector后退出循环，74行~81行 processSelectedKey方法void processSelectedKey(SelectionKey k, AbstractNioChannel ch) 该方法是处理每一个有事件发生的channel，在run()方法中调用processSelectedKeys方法会对所有发生事件的key调用到该方法来： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) { final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); if (!k.isValid()) { final EventLoop eventLoop; try { eventLoop = ch.eventLoop(); } catch (Throwable ignored) { // If the channel implementation throws an exception because there is no event loop, we ignore this // because we are only trying to determine if ch is registered to this event loop and thus has authority // to close ch. return; } // 这个channel的EventLoop不是当前的EventLoop或该channel没有对应的EventLoop if (eventLoop != this || eventLoop == null) { return; } // 关闭该通道，因为对应的k也不存在了 unsafe.close(unsafe.voidPromise()); return; } try { int readyOps = k.readyOps(); // 获取该key发生了什么样的事件 // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise // the NIO JDK channel implementation may throw a NotYetConnectedException. if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) { // 断开连接操作 // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); } // Process OP_WRITE first as we may be able to write some queued buffers and so free memory. if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) { // 写出操作 // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write ch.unsafe().forceFlush(); } // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) { // 读取操作 unsafe.read(); } } catch (CancelledKeyException ignored) { unsafe.close(unsafe.voidPromise()); }} 在这里，主要是走读取操作，即48行，对于服务端而言，无论是请求连接还是读取数据都是走这里。 BootStrapNetty中的BootStrap类主要是用于进行一些初始化设置，主要有SeverBootStrap和BootStrap两个类，分别用于服务端与客户端的初始化设置，以服务端的ServerBootStrap为例： 123456789101112131415161718192021222324252627282930313233343536public class NServer { public static void main(String[] args) throws InterruptedException { // 创建循环事件组，线程池，原理图中的BossGroup，用于监听用户的请求 // 若不指定线程数量，会默认设置为当前机器的逻辑处理器✖2 EventLoopGroup eventExecutors = new NioEventLoopGroup(1); // 创建工作线程组，原理图中的WorkerGroup // 若不指定线程数量，会默认设置为当前机器的逻辑处理器✖2 EventLoopGroup workExecutors = new NioEventLoopGroup(); try{ // 服务端配置 ServerBootstrap bootstrap = new ServerBootstrap(); bootstrap.group(eventExecutors, workExecutors) // 将两个Group加入 .channel(NioServerSocketChannel.class) // 指定channel的类型，注意这不是java NIO下的，是Netty提供的 .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列的连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new ServerHandler()); // 每个注册进来的channel都添加一个处理器，可以添加多个 } }); // 设置子处理器，当接受到读请求是会执行处理器中的方法。当是客户端请求连接时不会走该处理器，而是注册到workExecutors中 // 绑定端口 ChannelFuture sync = bootstrap.bind(8888).sync(); // 将来在接收到关闭事件是关闭通道，closeFuture本身是异步调用，加上sync同步等待返回结果 sync.channel().closeFuture().sync(); } finally { // 关闭线程池 eventExecutors.shutdownGracefully(); workExecutors.shutdownGracefully(); } }} 我们可以看到Netty服务端的启动都是由ServerBootStrap进行配置的，在执行bootstrap.bind(8888).sync();服务端正式启动起来。 主要配置方法(1) group()方法 该方法用于指定事件循环组，传入了我们初始化好的bossGroup与workerGroup两个NioEventLoopGroup。 (2) channel()方法 用于指定服务端接收连接请求的channel类型，对应于NIO中的ServerSocketChannel，是Netty包装过的，一下为NIO对应的一些channel的类型。 其中我们常用的就是NioServerSocketChannel用于tcp协议(对应于NIO的ServerSocketChannel)，而NioDatagramChannel对应于UDP协议(对应于NIO的DatagramChannel)。 (3) option()/childOption()方法 用于配置TCP连接的参数，option()配置SeverSocketChannel的TCP参数，childOption()配置SocketChannel的TCP参数，具体的配置参数在Netty中的ChannelOption配置中有部分说明。 (4) handler()/childHandler()方法 用于配置channel的处理器，hanlder()用于配置ServerSocketChannel的Handler，childHandler()用于配置socketChannel的Handler。 bind()启动服务器在经过配置后，调用bind()将启动服务器，开启两个EventLoopGroup中的eventLoop，调用bind()方法会调用到如下方法AbstractBootstrap的doBind方法： 1234567891011121314151617181920212223242526272829303132333435363738// class AbstractBootstrapprivate ChannelFuture doBind(final SocketAddress localAddress) { // &lt;1&gt;创建并初始化ServerSocketChannel final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) { return regFuture; } if (regFuture.isDone()) { // At this point we know that the registration was complete and successful. ChannelPromise promise = channel.newPromise(); // &lt;2&gt;绑定好了后，处理绑定完成的出站事件 doBind0(regFuture, channel, localAddress, promise); return promise; } else { // Registration future is almost always fulfilled already, but just in case it's not. final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); regFuture.addListener(new ChannelFutureListener() { @Override public void operationComplete(ChannelFuture future) throws Exception { Throwable cause = future.cause(); if (cause != null) { // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an // IllegalStateException once we try to access the EventLoop of the Channel. promise.setFailure(cause); } else { // Registration was successful, so set the correct executor to use. // See https://github.com/netty/netty/issues/2586 promise.registered(); doBind0(regFuture, channel, localAddress, promise); } } }); return promise; }} 主要执行了两个步骤： &lt;1&gt;创建并初始化ServerSocketChannel：包括对象的创建、先前配置参数的初始化、Handler链的初始化以及将channel注册到bossGroup等。 &lt;2&gt;绑定好了后，处理绑定完成的出站事件 初始化主要与&lt;1&gt;相关，进入initAndRegister()方法： 123456789101112131415161718192021222324252627282930313233343536373839final ChannelFuture initAndRegister() { Channel channel = null; try { // &lt;1&gt;通过工厂创建一个ServerSocketChannel channel = channelFactory.newChannel(); // &lt;2&gt;初始化channel init(channel); } catch (Throwable t) { if (channel != null) { // channel can be null if newChannel crashed (eg SocketException(&quot;too many open files&quot;)) channel.unsafe().closeForcibly(); // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(channel, GlobalEventExecutor.INSTANCE).setFailure(t); } // as the Channel is not registered yet we need to force the usage of the GlobalEventExecutor return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); } // &lt;3&gt;将channel注册到boosGroup上 ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) { if (channel.isRegistered()) { channel.close(); } else { channel.unsafe().closeForcibly(); } } // If we are here and the promise is not failed, it's one of the following cases: // 1) If we attempted registration from the event loop, the registration has been completed at this point. // i.e. It's safe to attempt bind() or connect() now because the channel has been registered. // 2) If we attempted registration from the other thread, the registration request has been successfully // added to the event loop's task queue for later execution. // i.e. It's safe to attempt bind() or connect() now: // because bind() or connect() will be executed *after* the scheduled registration task is executed // because register(), bind(), and connect() are all bound to the same thread. return regFuture;} &lt;1&gt; 通过工厂创建一个ServerSocketChannel，channelFactory会根据之前配置的channel类型为NioServerSocketChannel生成该类的channel对象 &lt;2&gt; 初始化channel，设置配置参数，并将Handler加入channel的pipeline中，其中固定会加入一个用于处理连接请求的处理器，用于将接收到SocketChannel注册到workerGroup上的eventLoop上： 12345678910111213141516171819202122232425262728293031323334void init(Channel channel) { setChannelOptions(channel, options0().entrySet().toArray(newOptionArray(0)), logger); setAttributes(channel, attrs0().entrySet().toArray(newAttrArray(0))); ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; // 配置参数 final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); p.addLast(new ChannelInitializer&lt;Channel&gt;() { @Override public void initChannel(final Channel ch) { final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); // 添加用户自定义的Handler if (handler != null) { pipeline.addLast(handler); } // 添加ServerBootstrapAcceptor的处理器，该处理器用于将接收到的连接请求封装为SocketChannel注册到workerGroup上 ch.eventLoop().execute(new Runnable() { @Override public void run() { pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); } }); } });} &lt;3&gt; 将channel注册到bossGroup，是通过Channel接口中的unsafe接口的方法的void register(EventLoop eventLoop, ChannelPromise promise)","link":"/2020/09/10/Netty%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-EventLoop%E4%B8%8EBootStrap/"},{"title":"缓存与分布式锁","text":"在项目中，为加快某个接口的访问速度，增大吞吐量，如果我们检查出该接口访问速度慢是因为数据库操作比较耗时的情况下，一个重要的方式就是将数据放入缓存，缓存是基于内存的，操作的速度远快于Mysql等关系型数据库。 哪些数据适合放入缓存中： 对及时性、数据一致性要求不高的数据 访问量大但是更新频率不高的数据 例如在电商系统中，商品的分类信息、商品列表等获取都是非常耗时的，但是这些数据都是不常更新的数据，适合加入缓存。 下面给出了一个查询商品分类的接口： controller层： 12345@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); // 查询三级分类 return R.ok().put(&quot;data&quot;, entities);} service层： 1234567891011121314151617181920212223242526@Overridepublic List&lt;CategoryEntity&gt; listWithTree() { List&lt;CategoryEntity&gt; list = baseMapper.selectList(null); // baseMapper为父类注入的，一次性查出所有的分类数据 List&lt;CategoryEntity&gt; roots = list.stream().filter(m -&gt; m.getParentCid().equals(0L)).collect(Collectors.toList()); // 查询所有的一级分类 roots.stream().forEach( (m)-&gt;m.setChildren(list.stream().filter(s-&gt;s.getParentCid().equals(m.getCatId())) .sorted((m1, m2)-&gt; (m1.getSort()==null? 0:m1.getSort()) - (m2.getSort()==null? 0:m2.getSort())) .map((s)-&gt; { setChildren(list, s); return s; }) .collect(Collectors.toList()))); // 采用深度优先遍历构建分类树 return roots;}private void setChildren(List&lt;CategoryEntity&gt; nodes, CategoryEntity node) { node.setChildren(nodes.stream().filter(m-&gt;m.getParentCid().equals(node.getCatId())) .sorted((m1, m2)-&gt; (m1.getSort()==null? 0:m1.getSort()) - (m2.getSort()==null? 0:m2.getSort())) .map((s)-&gt; { setChildren(nodes, s); return s; }) .collect(Collectors.toList()));} Service层构建分类树是比较耗时的，而且对于商品的分类，一般来说是修改比较少的，这些数据适合放入缓存中来加快访问速度。 使用缓存读取数据 在查询数据时，我们首先去缓存中查找数据，如果需要查询的数据存在，就可以直接查处数据了，如果不存在(第一次查询或缓存过期)，那么我们就去数据库中查询该数据然后将结果放入缓存中，这样第二次来查该数据时缓存中就会存在该数据了。 本地缓存在单机应用下，我们可以采用本地缓存的方式来在内存中存储数据，例如我们可以自定义HashMap来实现缓存的功能，也能够通过Mybatis开启二级缓存功能来对数据进行缓存，但不推荐使用Mybatis的二级缓存，Mybatis的缓存有效范围是基于namespace的，可以自己定义namespace，当在一个namespace下执行查询操作就直接从namespace的缓存中查找，如果在一个namespace下执行了增删改的操作就会清除缓存，因此开销比较大，而且如果一个操作涉及了多个namespace就不安全，不如直接使用HashMap来的高效灵活，只是要注意缓存的更新。 但是在集群或分布式环境下，本地缓存就不再适用，因为本地缓存是每台机器所独自拥有的。如果两台机器(进程)都有对应的本地缓存，但是一台机器把数据库的数据修改了，那么只会更新本台机器的本地缓存，另外一台机器还在使用旧的缓存，这样数据一致性太差。 我们可以看到，如果有三台商品服务的集群，每个商品服务都缓存了当前商品分类的数据。现在对商品的分类进行了修改，修改请求被负载均衡到了商品服务的1号机器，由1号机器向数据库发出修改的请求，然后再把修改后的结果放入1号机器的缓存中，但是并不能修改2号与3号机器的缓存。 当新的查询请求过来，被负载均衡到2号和3号机器，那么会直接查询到缓存中的旧数据然后返回。以后只有负载均衡到1号机器上或者等到缓存过期才能查出最新数据，在缓存过期前被负载均衡到到2号和3号机器上的请求都只能查到旧的数据。 分布式缓存为了解决本地缓存存在的数据一致性问题，我们应该集中管理缓存，将所有的缓存都放入到缓存中间件中，每个业务服务器查询缓存都到缓存中间件的服务器中进行查询，这样一来，某个业务服务器修改了缓存，其他的所有业务服务器都能够获取到最新的数据。 可以作为缓存中间件的开源产品有很多，目前最为常用的就是Redis，下面我们采用redis作为缓存中间件来进行分布式缓存。 使用Redis改造查询分类树在controller层中： 123456789101112131415161718192021@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { // 缓存中不存在 List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); // 将数据放入缓存中，过期时间为2天 return R.ok().put(&quot;data&quot;, entities); } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities);} 采用spring提供的RedisTemplate对redis缓存进行操作，我们完成了采用redis作为缓存中间件来解决本地缓存存在的问题，但是分布式缓存不仅仅这么简单，上面的代码虽然解决了数据一致性的问题，系统吞吐量也挺高，但其中隐藏了缓存击穿、缓存穿透与缓存雪崩等问题。 缓存穿透、击穿与雪崩缓存穿透 缓存穿透是指查询一个不存在的数据，如果缓存和数据库中都不存在某个数据，如果我们从数据库中查出了null值，但是我们不将null放入缓存中，这将导致每次请求都会去查询数据库中不存在的那个数据，如果并发量太大，将会压垮数据库，造成缓存穿透。因此，我们需要将null存入缓存中。 缓存击穿 缓存击穿是指某个缓存数据过期了，但是此时的访问并发量非常大，这时候会并发查询数据库，这样一来会压垮数据库，造成缓存击穿。解决缓存击穿的方案就是采用分布式锁，如果多个线程同时查询数据库，只放行一个请求去查询数据库，查询后放入缓存，其他的线程就能够从缓存中查询了，类似于单例模式。 缓存雪崩 缓存击穿是指缓存中间件中缓存了非常多的数据，由于每个缓存数据都设置了过期时间，这些数据都同时过期，这时需要高并发的去查询数据库，同样也会压垮数据库。解决缓存雪崩的一个方法就是将数据的过期时间设置为在原来的基础上加上随机数，这样可以降低同时过期的概率，但是不能完全解决缓存雪崩的问题。 缓存穿透的问题很好解决，下面我们来讨论一下分布式锁解决缓存击穿问题。 分布式锁Java中的Synchronized或ReentrantLock等JUC并发包都是本地锁，其作用范围是单个Java进程，也就是说，JDK提供的锁只能锁住当前的Java进程，防止单个进程中对共享资源进行同时操作而产生的安全问题。这种方式对于解决缓存击穿的问题也是足够的，因为这些本地锁保证了一个进程只向服务器发送一个查询对应表的请求，请求数量较少，不会压垮数据库。 但是更好的方式是采用分布式锁，分布式锁可以保证所有线程只有一个线程能够操作缓存和数据库(这里只是指某一个请求，不影响其他请求)。分布式锁目前主流可以使用Redis或zookeeper实现，两者实现分布式锁的原理有所区别，Redis的性能更高，而zookeeper的可靠性更高，我们这里还是采用redis来实现分布式锁。 redis实现分布式锁redis实现分布式锁的原理并不复杂，只需要利用一个setnx的命令即可，在redis中setnx命令作用是向redis中存入一个key-value，如果这个key不存在，那么就可以设置成功返回true，如果这个key存在了，那么就不能设置失败返回false。 因此利用redis实现分布式锁的思路是：在分布式环境下访问共享资源时，各个线程利用setnx命令向redis中存入同一个key(value不太重要)，如果能够设置成功，说明获取到了分布式锁，一个线程设置成功后，其他线程必定会设置失败返回false(因为redis操作内存数据是单线程的)，返回false的线程需要等到获取到锁的线程释放锁之后才能获得锁。 业务改造： 1234567891011121314151617181920212223242526272829303132333435@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { while (!opsForValue.setIfAbsent(&quot;category-lock&quot;, &quot;true&quot;)) { // 上锁 Thread.sleep(200); } try { // 再查询一次 category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); return R.ok().put(&quot;data&quot;, entities); } } finally { // 已经有了缓存，释放锁 if(opsForValue.get(&quot;category-lock&quot;) != null) { // 此方法不安全，判断和删锁不是原子操作 redisTemplate.delete(&quot;category-lock&quot;); } } } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities));} 上述代码初步实现了一个分布式锁，与单例模式类似，采用double-check的方式来进行数据库的查询以及缓存数据的添加，在完成业务后释放锁让其他线程能够获取到锁继续执行代码。未获取到所的线程简单采用短暂睡眠+自旋的方式进行重复尝试。 这份代码并不完善，还需要进一步改进来提高锁的可靠性。 redis分布式锁的改进(1) 宕机后锁无法释放 上述分布式锁的代码存在很多不可靠的因素，这些因素多是由于机器故障造成的，试想一下，某个线程在向redis中设置了key获取到了分布式锁后，还没有释放锁结果机器宕机了，那么将会造成这把分布式锁永远无法释放，没有线程可以访问到缓存的这个数据，进而没有线程能够跳出自旋去查询数据。这种情况虽然发生的概率不是很高，但是一旦发生是致命的。 一个改进的方法就是给锁加上过期时间，如果一台机器宕机了，那么这个锁过了时间就会自动的失效，并且，我们需要将设置key与设置过期时间作为原子操作，如果不是原子操作，那么机器在设置了key之后就宕机了，没有设置过期时间，那么也会存在锁无法释放的问题。redis想要实现两个命令的原子操作只需要传送lua脚本即可，在RedisTemplate中封装了setnx与expire的原子操作，直接使用即可。 (2) 业务执行时间过长 虽然我们设置了锁的过期时间能够解决锁无法释放的问题，但引入了一个新的问题，那就是业务执行过长会导致本来还不应该释放锁但是锁已经自动失效了，一旦业务还未完成就释放锁，其他线程就能够进进行加锁，当最开始的线程执行完毕释放锁时，释放的就是其他线程所加的锁，这样一来就非常的混乱。解决这一问题的方法就是给每个线程的锁设置一个唯一的uuid作为value存在redis中，在释放锁的时候判断是否是自己加的锁，是自己加的才释放。 uuid的方法只是解决了不释放别人的锁，仍然没有解决的业务执行时间过长而锁提前失效的问题，我们可以简单的把锁失效的时间变长，因为一般不会允许某个业务执行时间太长，但是更安全的做法是自动给锁续期，我们需要新开一个守护线程来检测业务是否还在进行，如果还在，自动给锁进行续期。 下面的代码没有给锁进行自动续期，采用锁过期时间设置稍长的方式： 1234567891011121314151617181920212223242526272829303132333435363738@RequestMapping(&quot;/list/tree&quot;)public R list() throws InterruptedException { ValueOperations&lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { String uuid = UUID.randomUUID().toString(); while (!opsForValue.setIfAbsent(&quot;category-lock&quot;, uuid, Duration.ofSeconds(15))) { // 上锁 Thread.sleep(200); } try { // 再查询一次 category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); return R.ok().put(&quot;data&quot;, entities); } } finally { // 已经有了缓存，释放锁 /*if(uuid.equals(opsForValue.get(&quot;category-lock&quot;))) { // 此方法不安全，判断和删锁不是原子操作 redisTemplate.delete(&quot;category-lock&quot;); }*/ // 采用lua脚本保证原子性 String script = &quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end&quot;; redisTemplate.execute(new DefaultRedisScript&lt;&gt;(script, Long.class), Arrays.asList(&quot;category-lock&quot;), uuid); } } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities).put(&quot;port&quot;, environment.getProperty(&quot;local.server.port&quot;));} 采用redisson封装的分布式锁redisson是利用java编写的一个基于redis的开源的分布式锁框架，redisson利用AQS对分布式锁进行了高度的封装，使得我们在用分布式锁时就像在使用jdk的JUC包一样，redisson提供RedissonLock来实现分布式锁，它的使用与ReentrantLock类似： 12345678910111213141516171819202122232425262728293031@RequestMapping(&quot;/list/tree/redisson&quot;)public R listRedisson() { &lt;String, String&gt; opsForValue = redisTemplate.opsForValue(); // 查询缓存中是否有数据 String category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { RLock lock = redisson.getLock(&quot;category-lock&quot;); // 获得锁对象，需要传入锁的名称，根据名称来判断是不是同一把锁 lock.lock(); try { // 再查询一次 category = opsForValue.get(&quot;category-tree&quot;); if(category == null) { List&lt;CategoryEntity&gt; entities = categoryService.listWithTree(); System.out.println(&quot;查询了数据库&quot;); category = JSON.toJSONString(entities); opsForValue.set(&quot;category-tree&quot;, category, Duration.ofHours(2)); return R.ok().put(&quot;data&quot;, entities); } } finally { lock.unlock(); } } // 有缓存，直接返回查询到的缓存值 List&lt;CategoryEntity&gt; entities = JSON.parseObject(category, List.class); System.out.println(&quot;缓存命中&quot;); return R.ok().put(&quot;data&quot;, entities);} Reddison实现的分布式锁与之前讲的原理类似，它底层会自动给锁进行续期。","link":"/2020/07/01/huan-cun-yu-fen-bu-shi-suo/"},{"title":"类加载器","text":"类加载器是 Java 语言的动态性的重要组件，也是 Java 语言流行的重要原因之一。它使得 Java 类可以被动态加载到 Java 虚拟机中并执行。 1 作用 类加载器在JVM启动时进行加载，负责从文件或网络中加载.class文件。 类加载器只负责符合规范的class文件，至于该文件是否能够运行，由执行引擎来决定。 类的信息加载后，类的元数据(包含常量池、属性表、方法表、类变量等)存放于内存空间中的方法区，生成的Class对象实例存储在堆区，除了类的信息外，方法区还会保存一些。 2 过程类加载过程：加载-验证-准备-解析-初始化 加载阶段： 通过类的全限定类名获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转化为运行时数据结构(class的元数据，包含常量池、属性表、方法表、类变量等)存储在方法区。 在内存中生成一个java.lang.Class对象，作为方法区这个类的各种数据访问的入口，**Class对象存在于堆区，其中的很多属性存在于方法区**。 验证阶段： 确保字节码文件符号虚拟机的规范要求，保证类正确被加载，不危害虚拟机的安全。 四种验证方式：文件格式验证(例如文件开头都是CA FE BA BE)，元数据验证，字节码验证，符号引用验证。 准备阶段： 为类变量(即static修饰的变量)分配内存并为变量设置默认初始值，对象为null，数值基本类型为0。 这里分配内存不包括final修饰的变量，常量在编译时期就已经分配了。 这里不会为类实例变量(即类成员，不同static修饰)分配内存初始化，类变量(static)会分配在方法区，而实例变量(无static)会随着对象一起分配到堆中。 注意： 1private static int a = 1; 即使是如上的代码，在准备阶段a只会赋值为0，只有到后面的类初始化阶段才会被赋值为1。 解析阶段： 将常量池内的符号引用转换为直接引用的过程，即将符号转化为实际对象的地址。 事实上，解析操作往往会伴随着JVM在执行完初始化之后再执行。 符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java 虚拟机规范》的Class文件格式中。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的CONSTANT Class info、 CONSTANT Fieldref info、CONSTANT Methodref info等 。 初始化阶段： 初始化阶段是调用类构造器方法&lt;clinit&gt;()的过程，注意必须要有static变量或者static代码才会有该方法，用于初始化类的静态变量。 static{}代码块就是&lt;clinit&gt;()的一部分，该类构造器方法&lt;clinit&gt;()不是类的构造方法(函数)，此方法不需要人为定义。 注意：类被加载不一定会初始化 3 类加载器分类JVM的类加载器主要分为引导类加载器和自定义类加载器，一般不同的类加载器负责不同的类加载的路径。 引导类加载器为Bootstrap Class Loader，该类是由c/c++语言编写的，用于启动。而其他的都属于自定义类加载器，包括Extension Class Loarder、System Class Loarder以及用户自定义的一些类加载器，注意，自定义类加载器都继承于抽象类Classloader，而各个类加载器之间没有继承关系。即System Class Loarder不是Extension Class Loarder子类，下图仅仅表示某种类加载器是由哪个类加载器加载的。 用户自定义的类是由系统类加载器(AppClassLoader)加载的，而java的核心类库是由引导类加载器加载的。 上图不反应继承关系，下图是ClassLoader类的继承关系。 Bootstrap类加载器 （1）这个类加载使用C/C+ +语言实现的，嵌套在JVM内部。 （2）它用来加载Java的核心库(JAVA_ HOME/jre/ lib/rt.jar、resources. jar或sun . boot.class .path路径下的内容) ,用于提供JVM自身需要的类。 （3）并不继承自java. lang. ClassLoader，没有父加载器。加载扩展类和应用程序类加载器，并指定为他们的父类加载器。 （4）出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类 Extension类加载器 （1）Java语言编写，由sun . misc. Launcher$ExtClassLoader实现。 （2）派生于ClassLoader类 （3）父类加载器为启动类加载器 （4）从java. ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre/lib/ext子目录(扩展目录)下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。 应用程序类加载器(系统类加载器，AppClassLoader类) （1）java语言编写，由sun . misc. Launcher$AppClassLoader实现 （2）派生于ClassLoader类 （3）父加载器为扩展类加载器（不是父类的意思） （4）它负责加载环境变量classpath或系统属性java.class.path 指定路径“下的类库该类加载是程序中默认的类加载器，一般来说，Java应用的类(我们写在classpath下的类)都是由它来完成加载 （5）通过ClassLoader# getSystemClassLoader ()方法可以获取到该类加载器 用户自定义的加载类 继承ClassLoader抽象类，重写findClass方法。可能种种原因，例如由于我们需要加载的类不在classpath下、也不在Bootstrap和Extension类加载器所加载的路径下，我们需要自定义类加载器来加载类。 4 类被加载的条件类加载的条件： 当类被主动使用时，类会被加载进内存，主动使用包括： ​ （1）创建类的实例 ​ （2）访问某个类或接口的静态变量，或者对该静态变量赋值 ​ （3）调用类的静态方法 ​ （4）反射(比如: Class. forName (“com. atguigu. Test”) ) ​ （5）初始化一一个类的子类 ​ （6）Java虚拟机启动时被标明为启动类的类 ​ （7）JDK 7开始提供的动态语言支持:java. lang. invoke . MethodHandle实例的解析结果REF_ getStatic、REF_ putStatic、REF_ invokeStatic句柄 对应的类没有初始化，则初始化 除了以上的主动使用，其余都为被动使用，被动使用不会引起类的加载初始化。 类加载的时机： 不管使用什么样的类加载器，类都是在第一次被用到时，动态加载到JVM的。这句话有两层含义： Java程序在运行时并不一定被完整加载，只有当发现该类还没有加载时，才去本地或远程查找类的.class文件并验证和加载（赖加载）； 当程序创建了第一个对类的静态成员的引用（如类的静态变量、静态方法、构造方法——构造方法也是静态的）时，才会加载该类。Java的这个特性叫做：动态加载。 例如： 12345678910111213141516public class ClD { public static void main(String[] args) throws ClassNotFoundException { System.out.println(&quot;asd&quot;); A a = new A(); // 执行这句话时，首先判断类A是否加载，未加载则先加载 A a2 = new A(); // 类A已经加载过了，无需再加载 }}public class A { static { System.out.println(&quot;A&quot;); }} 5 类加载的规则：双亲委派机制（1）如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行; （2）如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达项层的启动类加载器; （3）如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。 这一逻辑我们可以在ClassLoader中的源码中看到： ClassLoader类中的loadClass是类加载的核心代码 1234567891011121314151617181920212223242526272829303132333435363738protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException{ synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded // 该类是否被加载过，加载过了直接返回 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { // 判断是否有父加载器 c = parent.loadClass(name, false); // 委托父加载器加载 } else { c = findBootstrapClassOrNull(name); // 无父加载器，代表父加载器为Bootstrap加载器，委托Bootstrap加载器加载 } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // 父加载器不能加载该类，由自己加载 // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; }} 例如，我们在自己项目中自定义了一个java.lang.String，当我们new String对象时，我们创建的是java原生API的String类型还是自定义的String类型呢？根据双亲委派模型，此时加载的还是java原生API而并没有加载自定义的java.lang.String(注意包名也相同)，其原因是原生API的java.lang.String是被引导类加载器加载的，而用户自己定义的类是由系统类加载器加载的，所以java.lang.String在父加载器中已经加载了，子加载器无需再进行加载。 双亲委派机制的优势： 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次。 其次是考虑到安全因素，java核心api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改。 6 自定义类加载器在ClassLoader类文件注释中给了一个最简单的自定义类加载器的示例，按照示例，只需要获取class文件的byte[]数组然后通过ClassLoader中的defineClass方法即可获取Class对象，重写findClass方法即可，ClassLoader中已经实现了双亲委派机制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class TomcodeClassLoader extends ClassLoader { // 验证 public static void main(String[] args) throws ClassNotFoundException { TomcodeClassLoader classLoader = new TomcodeClassLoader(); Class&lt;?&gt; aClass = classLoader.loadClass(&quot;classloader.A&quot;); System.out.println(aClass.getClassLoader()); } private static final String PRE_FIX = &quot;/Volumes/data/&quot;; // 要加载的类所在的目录 public TomcodeClassLoader() { super(); } @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { try { byte[] b = loadClassData(name); return defineClass(name, b, 0, b.length); } catch (IOException e) { e.printStackTrace(); return null; } } private byte[] loadClassData(String name) throws IOException { String[] split = name.split(&quot;\\\\.&quot;); StringBuilder sb = new StringBuilder(PRE_FIX); for(int i = 0; i &lt; split.length-1; i++) { sb.append(split[i]); sb.append('/'); } String fullpath = sb.append(split[split.length - 1] + &quot;.class&quot;).toString(); FileInputStream is = null; ByteArrayOutputStream bo = null; try { is = new FileInputStream(fullpath); byte[] b = new byte[1024]; bo = new ByteArrayOutputStream(); int len = -1; while ((len = is.read(b)) != -1) { bo.write(b, 0, len); } return bo.toByteArray(); } finally { if(is != null) { is.close(); } if(bo != null) { bo.close(); } } }} 首先，我们将类A的文件放在当前类路径，在指定的/Volumes/data/下放入classloader/A.class，由于双亲委派机制，类A会由AppClassLoader加载 1sun.misc.Launcher$AppClassLoader@18b4aac2 当我们删除当前类路径下的类A文件，则类A由自定义的TomcodeClassLoader加载 1classloader.TomcodeClassLoader@1d44bcfa 7 类加载器的命名空间 每个类加载器都有自己的命名空间，类加载器的命名空间是由自身以及所有父加载器所加载出来的全类名组成。 由于双亲委派机制，父子加载器之间不会出现相同的全类名，但是同等级的类加载器之间可以出现相同的全类名，并且互相是感受不到的，也就是说Class对象不同。 子加载器加载的类可以感知到父加载器所加载的类，反之则不行。例如自定义一个类，我们是不能在String类中使用的，因为String类是由Bootstrap加载器加载的，而自定义类是AppClassLoader加载的。我们可以在自定义类中使用String类。 1234567891011121314151617181920212223242526272829303132public class ClD { public static void main(String[] args) throws Exception { TomcodeClassLoader classLoader = new TomcodeClassLoader(); Class&lt;?&gt; aClass = classLoader.loadClass(&quot;classloader.B&quot;); TomcodeClassLoader classLoader2 = new TomcodeClassLoader(); Class&lt;?&gt; bClass1 = classLoader2.loadClass(&quot;classloader.B&quot;); System.out.println(aClass.getClassLoader()); System.out.println(bClass1.getClassLoader()); System.out.println(aClass == bClass1); Object o = aClass.newInstance(); Object o1 = bClass1.newInstance(); bClass1.getMethod(&quot;setB&quot;, Object.class).invoke(o1, o); }}public class B { private B b; public B() { } public void setB(Object b) { this.b = (B) b; }} 输出： 123456789101112classloader.TomcodeClassLoader@1d44bcfaclassloader.TomcodeClassLoader@6f94fa3efalseException in thread &quot;main&quot; java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at classloader.ClD.main(ClD.java:23)Caused by: java.lang.ClassCastException: classloader.B cannot be cast to classloader.B at classloader.B.setB(B.java:11) ... 5 more 首先，两个Class对象都是由TomcodeClassLoader进行加载的，但是不是同一个ClassLoader对象，两个TomcodeClassLoader是同等级的，因此两个加载出来的Class对象是不同的 其次，两个Class对象是无法互相感知到，从结果可以看出，两个不同Class对象创建的实例不能进行强转 8 打破双亲委派机制打破双亲委派机制的一个重要场景就是数据库连接驱动，数据库连接驱动采用的SPI机制来加载数据库驱动。SPI简单来说使用过配置文件的方式来动态加载接口的实现类，拿到配置文件中的实现类，通过反射加载类，具体暂不展开阐述，SPI就可以用来打破双亲委派机制。首先我们来看看获取数据库连接的代码： 1234public static void main(String[] args) throws ClassNotFoundException, SQLException { Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;); Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/newmall&quot;);} 代码非常简单，但是一句Class.forName(“com.mysql.cj.jdbc.Driver”);就打破了双亲委派机制，加载了Mysql驱动。 Class.forName(“com.mysql.cj.jdbc.Driver”)加载Mysql驱动，则将执行该类的静态代码块： 1234567static { try { java.sql.DriverManager.registerDriver(new Driver()); } catch (SQLException E) { throw new RuntimeException(&quot;Can't register driver!&quot;); }} 该静态代码块使用了DriverManager，则加载该类，注意DriverManager是java.sql下的，由Bootsrap加载器所加载，DriverManager中的静态代码块执行，在静态代码块中加载了Mysql的驱动。 注意，此时DriverManager是由Bootsrap加载器加载，这意味着，DriverManager中只能使用由Bootsrap加载器加载的类，而我们知道，数据库驱动属于第三方提供的，肯定不是由Bootsrap加载器加载，因此此时需要打破双亲委派机制，采用的就是SPI机制。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static { loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);}private static void loadInitialDrivers() { String drivers; try { drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() { public String run() { return System.getProperty(&quot;jdbc.drivers&quot;); } }); } catch (Exception ex) { drivers = null; } AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { // SPI加载驱动类 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try{ while(driversIterator.hasNext()) { driversIterator.next(); } } catch(Throwable t) { // Do nothing } return null; } }); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) { return; } String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) { try { println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); } catch (Exception ex) { println(&quot;DriverManager.Initialize: load failed: &quot; + ex); } }} 我们可以看到在loadInitialDrivers方法中使用SPI加载META-INF/services中配置文件中配置的Driver接口的实现类，我们看ServiceLoader.load方法： 1234public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) { ClassLoader cl = Thread.currentThread().getContextClassLoader(); // 获取当前线程的ClassLoader return ServiceLoader.load(service, cl);} 这里是打破双亲委派机制的关键，我们从当前线程中获取到了ClassLoader对象，这个ClassLoader对象不是加载加载DriverManager的Bootstrap ClassLoader，而是AppClassLoader，我们使用AppClassLoader便可以加载第三方提供的驱动jar包。 而Java提供了Class.forName(String name, boolean initialize, ClassLoader loader)方法，可以指定加载该类的类加载器，便可以在DriverManager内加载第三方Mysql驱动了，打破了双亲委派机制。","link":"/2020/07/24/lei-jia-zai-qi/"}],"tags":[{"name":"多线程","slug":"多线程","link":"/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"nacos","slug":"nacos","link":"/tags/nacos/"},{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"JAVA","slug":"JAVA","link":"/tags/JAVA/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"mybatis","slug":"mybatis","link":"/tags/mybatis/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"},{"name":"redis","slug":"redis","link":"/tags/redis/"}],"categories":[{"name":"Java多线程","slug":"Java多线程","link":"/categories/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"分布式","slug":"分布式","link":"/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"JAVA","slug":"JAVA","link":"/categories/JAVA/"},{"name":"SSM","slug":"SSM","link":"/categories/SSM/"},{"name":"JVM","slug":"JVM","link":"/categories/JVM/"}]}